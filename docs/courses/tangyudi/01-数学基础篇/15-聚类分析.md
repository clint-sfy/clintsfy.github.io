---
title: 聚类分析
author: 阿源
date: 2023/06/15 12:00
categories:
 - 机器学习理论基础
tags:
 - 机器学习
 - 数学基础
---
# 聚类分析
## 15. 聚类分析

### 1. 层次聚类概述

```
层次聚类(Hierarchical Clustering)是聚类算法的一种，通过计算不同类别数据点间的相似度来创建一棵有层次的嵌套聚类树。在聚类树中，不同类别的原始数据点是树的最低层，树的顶层是一个聚类的根节点。创建聚类树有自下而上合并和自上而下分裂两种方法。

作为一家公司的人力资源部经理，你可以把所有的雇员组织成较大的簇，如主管、经理和职员；然后你可以进一步划分为较小的簇，例如，职员簇可以进一步划分为子簇：高级职员，一般职员和实习人员。所有的这些簇形成了层次结构，可以很容易地对各层次上的数据进行汇总或者特征化。
```

![](https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/聚类1.png)

```
直观来看，上图中展示的数据划分为2个簇或4个簇都是合理的，甚至，如果上面每一个圈的内部包含的是大量数据形成的数据集，那么也许分成16个簇才是所需要的。

论数据集应该聚类成多少个簇，通常是在讨论我们在什么尺度上关注这个数据集。层次聚类算法相比划分聚类算法的优点之一是可以在不同的尺度上（层次）展示数据集的聚类情况。

基于层次的聚类算法（Hierarchical Clustering）可以是凝聚的（Agglomerative）或者分裂的（Divisive），取决于层次的划分是“自底向上”还是“自顶向下”
```

### 2. 层次聚类流程

```
自底向上的合并算法
层次聚类的合并算法通过计算两类数据点间的相似性，对所有数据点中最为相似的两个数据点进行组合，并反复迭代这一过程。简单的说层次聚类的合并算法是通过计算每一个类别的数据点与所有数据点之间的距离来确定它们之间的相似性，距离越小，相似度越高。并将距离最近的两个数据点或类别进行组合，生成聚类树。

相似度的计算
层次聚类使用欧式距离来计算不同类别数据点间的距离（相似度）。
```

![](https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/聚类2.png)

![](https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/聚类3.png)

```
两个组合数据点间的距离
计算两个组合数据点间距离的方法有三种，分别为Single Linkage，Complete Linkage和Average Linkage。在开始计算之前，我们先来介绍下这三种计算方法以及各自的优缺点。

Single Linkage：方法是将两个组合数据点中距离最近的两个数据点间的距离作为这两个组合数据点的距离。这种方法容易受到极端值的影响。两个很相似的组合数据点可能由于其中的某个极端的数据点距离较近而组合在一起。

Complete Linkage：Complete Linkage的计算方法与Single Linkage相反，将两个组合数据点中距离最远的两个数据点间的距离作为这两个组合数据点的距离。Complete Linkage的问题也与Single Linkage相反，两个不相似的组合数据点可能由于其中的极端值距离较远而无法组合在一起。

Average Linkage：Average Linkage的计算方法是计算两个组合数据点中的每个数据点与其他所有数据点的距离。将所有距离的均值作为两个组合数据点间的距离。这种方法计算量比较大，但结果比前两种方法更合理。

我们使用Average Linkage计算组合数据点间的距离。下面是计算组合数据点(A,F)到(B,C)的距离，这里分别计算了(A,F)和(B,C)两两间距离的均值。
```

![](https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/聚类4.png)

### 3. 层次聚类实例

```python
import pandas as pd

seeds_df = pd.read_csv('./datasets/seeds-less-rows.csv')
seeds_df.head()

seeds_df.grain_variety.value_counts()  
varieties = list(seeds_df.pop('grain_variety'))

samples = seeds_df.values
samples
array([[ 14.88  ,  14.57  ,   0.8811,   5.554 ,   3.333 ,   1.018 ,   4.956 ],
       
#距离计算的 还有树状图
from scipy.cluster.hierarchy import linkage, dendrogram
import matplotlib.pyplot as plt

#进行层次聚类
mergings = linkage(samples, method='complete')
#树状图结果
fig = plt.figure(figsize=(10,6))
dendrogram(mergings,
           labels=varieties,
           leaf_rotation=90,
           leaf_font_size=6,
)
plt.show()
  
```

![](https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/聚类5.png)

```python
#得到标签结果
#maximum height自己指定
from scipy.cluster.hierarchy import fcluster
labels = fcluster(mergings, 6, criterion='distance')

df = pd.DataFrame({'labels': labels, 'varieties': varieties})
ct = pd.crosstab(df['labels'], df['varieties'])
ct
```

```python
# 不同距离的选择会产生不同的结果
import pandas as pd

scores_df = pd.read_csv('./datasets/eurovision-2016-televoting.csv', index_col=0)
country_names = list(scores_df.index)
scores_df.head()

#缺失值填充，没有的就先按满分算吧
scores_df = scores_df.fillna(12)
from sklearn.preprocessing import normalize
samples = normalize(scores_df.values)
samples
array([[ 0.09449112,  0.56694671,  0.        , ...,  0.        ,
         0.28347335,  0.        ],
       
from scipy.cluster.hierarchy import linkage, dendrogram
import matplotlib.pyplot as plt

mergings = linkage(samples, method='single')
fig = plt.figure(figsize=(10,6))
dendrogram(mergings,
           labels=country_names,
           leaf_rotation=90,
           leaf_font_size=6,
)
plt.show()
```

![](https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/聚类6.png)

```python
mergings = linkage(samples, method='complete')
fig = plt.figure(figsize=(10,6))
dendrogram(mergings,
           labels=country_names,
           leaf_rotation=90,
           leaf_font_size=6,
)
plt.show()
```

![](https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/聚类7.png)

### 4. Kmeans概述



### 5. Kmeans工作流程



### 6. Kmeans可视化展示



### 7. DBSCAN聚类算法



### 8. DBSCAN工作流程



### 9. DBSCAN可视化展示



### 10. 多种聚类算法概述



### 11. 案例 聚类
