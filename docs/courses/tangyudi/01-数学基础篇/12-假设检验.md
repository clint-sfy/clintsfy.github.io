---
title: 假设检验
author: 阿源
date: 2023/06/12 12:00
categories:
 - 机器学习理论基础
tags:
 - 机器学习
 - 数学基础
---
# 假设检验
## 12. 假设检验

### 1. 基本思想

- 什么是假设：对总体参数（均值，比例等）的具体数值所作的陈述。比如，我认为新的配方的药效要比原来的更好。
- 什么是假设检验：先对总体的参数提出某种假设，然后利用样本的信息判断假设是否成立的过程。比如，上面的假设我是要接受还是拒绝呢。

- 推广新的教育方案后，教学效果是否有所提高
- 醉驾判定为刑事犯罪后是否会使得交通事故减少
- 男生和女生在选文理科时是否存在性别因素影响

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验1.png)



```
显著性水平：

一个概率值，原假设为真时，拒绝原假设的概率，表示为 alpha 常用取值为0.01, 0.05, 0.10
一个公司要来招聘了，本来实际有200个人准备混一混，但是公司希望只有5%的人是浑水摸鱼进来的，所以可能会有200*0.05=4个人混进来，所谓显著性水平α，就是你允许最多有多大比例浑水摸鱼的通过你的测试。
```

```
假设检验的步骤：

提出假设
确定适当的检验统计量
规定显著性水平
计算检验统计量的值
做出统计决策
```

```
原假设与备择建设：

待检验的假设又叫原假设，也可以叫零假设，表示为H0。（零假设其实就是表示原假设一般都是说没有差异，没有改变。。。）
与原假设对比的假设叫做备择假设，表示为H1
一般在比较的时候，主要有等于，大于，小于
```

```
检验统计量：

计算检验的统计量
根据给定的显著性水平，查表得出相应的临界值
将检验统计量的值与显著性水平的临界值进行比较
得出拒绝或不拒绝原假设的结论
```

```
检验中常说的小概率：
在一次试验中，一个几乎不可能发生的事件发生的概率
在一次试验中小概率事件一旦发生，我们就有理由拒绝原假设
小概率由我们事先确定
```

### 2. 左右侧检验与双侧检验

```
P值：
是一个概率值
如果原假设为真，P-值是抽样分布中大于或小于样本统计量的概率
左侧检验时，P-值为曲线上方小于等于检验统计量部分的面积
右侧检验时，P-值为曲线上方大于等于检验统计量部分的面积
```

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验2.png)

```
当关键词有不得少于/低于的时候用左侧，比如灯泡的使用寿命不得少于/低于700小时时
当关键词有不得多于/高于的时候用右侧，比如次品率不得多于/高于5%时
```

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验3.png)

```
    单侧检验指按分布的一侧计算显著性水平概率的检验。用于检验大于、小于、高于、低于、优于、劣于等有确定性大小关系的假设检验问题。这类问题的确定是有一定的理论依据的。假设检验写作：μ1<μ2或μ1>μ2。

    双侧检验指按分布两端计算显著性水平概率的检验， 应用于理论上不能确定两个总体一个一定比另一个大或小的假设检验。一般假设检验写作H1：μ1≠μ2。
```

```
检验结果：
单侧检验
若p值 > α, 不拒绝 H0
若p值 < α, 拒绝 H0

双侧检验
若p-值 > α/2, 不拒绝 H0
若p-值 < α/2, 拒绝 H0
```

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验4.png)

### 3. Z检验基本原理

- 当总体标准差已知,样本量较大时用标准正态分布的理论来推断差异发生的概率，从而比较两个平均数的差异是否显著
- 标准正态变换后Ｚ的界值

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验5.png)

### 4. Z检验实例

研究正常人与高血压患者胆固醇含量(mg%)的资料如下,试比较两组血清胆固醇含量有无差别。

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验6.png)

   某机床厂加工一种零件，根据经验知道，该厂加工零件的椭圆度近似服从正态分布，其总体均值为μ=0.081mm，总体标准差为σ= 0.025 。今换一种新机床进行加工，抽取n=200个零件进行检验，得到的椭圆度为0.076mm。试问新机床加工零件的椭圆度的均值与以前有无显著差异？（α＝0.05）

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验7.png)

​      根据过去大量资料，某厂生产的灯泡的使用寿命服从正态分布N~(1020，100^2)。现从最近生产的一批产品中随机抽取16只，测得样本平均寿命为1080小时。试在0.05的显著性水平下判断这批产品的使用寿命是否有显著提高？(α＝0.05)

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验8.png)

### 5. T检验基本原理

```
根据研究设计,t检验有三种形式：
单个样本的t检验：
用来比较一组数据的平均值和一个数值有无差异。例如，你选取了5个人，测定了他们的身高，要看这五个人的身高平均值是否高于、低于还是等于1.70m，就需要用这个检验方法。

配对样本均数t检验(非独立两样本均数t检验)
用来看一组样本在处理前后的平均值有无差异。比如，你选取了5个人，分别在饭前和饭后测量了他们的体重，想检测吃饭对他们的体重有无影响，就需要用这个t检验。

两个独立样本均数t检验
用来看两组数据的平均值有无差异。比如，你选取了5男5女，想看男女之间身高有无差异，这样，男的一组，女的一组，这两个组之间的身高平均值的大小比较可用这种方法。
```

```
单个样本t检验

又称单样本均数t检验(one sample t test),适用于样本均数与已知总体均数μ0的比较,目的是检验样本均数所代表的总体均数μ是否与已知总体均数μ0有差别。
已知总体均数μ0一般为标准值、理论值或经大量观察得到的较稳定的指标值。
应用条件，总体标准α未知的小样本资料,且服从正态分布。
```

```
配对样本均数t检验：
简称配对t检验(paired t test),又称非独立两样本均数t检验,适用于配对设计计量资料均数的比较。
配对设计(paired design)是将受试对象按某些特征相近的原则配成对子，每对中的两个个体随机地给予两种处理。
```

```
配对样本均数t检验原理：
配对设计的资料具有对子内数据一一对应的特征,研究者应关心是对子的效应差值而不是各自的效应值。

进行配对t检验时，首选应计算各对数据间的差值d，将d作为变量计算均数。

配对样本t检验的基本原理是假设两种处理的效应相同，理论上差值d的总体均数μd 为0，现有的不等于0差值样本均数可以来自μd = 0的总体,也可以来μd ≠ 0的总体。

可将该检验理解为差值样本均数与已知总体均数μd（μd = 0）比较的单样本t检验,其检验统计量为：
```

### 6. T检验实例

有12名接种卡介苗的儿童，8周后用两批不同的结核菌素，一批是标准结核菌素，一批是新制结核菌素，分别注射在儿童的前臂，两种结核菌素的皮肤浸润反应平均直径(mm)如表所示，问两种结核菌素的反应性有无差别。

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验9.png)

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验10.png)

```
两独立样本t检验
两独立样本t 检验(two independent sample t-test)，又称成组 t 检验。

适用于完全随机设计的两样本均数的比较,其目的是检验两样本所来自总体的均数是否相等。

完全随机设计是将受试对象随机地分配到两组中，每组患者分别接受不同的处理，分析比较处理的效应。

两独立样本t检验要求两样本所代表的总体服从正态分布N(μ1，σ^2)和N(μ2，σ^2)，且两总体方差σ1^2、σ2^2相等,即方差齐性。若两总体方差不等需要先进行变换

两独立样本t检验原理
两独立样本t检验的检验假设是两总体均数相等,即H0：μ1=μ2，也可表述为μ1－μ2=0,这里可将两样本均数的差值看成一个变量样本,则在H0条件下两独立样本均数t检验可视为样本与已知总体均数μ1－μ2=0的单样本t检验, 统计量计算公式为：
```

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验11.png)



### 7. T检验应用条件

- 两组计量资料小样本比较
- 样本对总体有较好代表性，对比组间有较好组间均衡性——随机抽样和随机分组
- 样本来自正态分布总体，配对t检验要求差值服从正态分布，大样本时，用z检验，且正态性要求可以放宽
- 两独立样本均数t检验要求方差齐性——两组总体方差相等或两样本方差间无显著性

### 8. 卡方检验

用于检验两个（或多个）率或构成比之间差别是否有统计学意义，配对卡方检验检验配对计数资料的差异是否有统计学意义。

### 卡方检验(Chi-square test)

用于检验两个（或多个）率或构成比之间差别是否有统计学意义，配对卡方检验检验配对计数资料的差异是否有统计学意义。

检验实际频数(A)和理论频数(T)的差别是否由抽样误差所引起的。也就是由样本率（或样本构成比）来推断总体率或构成比。

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验12.png)

ARC是位于R行C列交叉处的实际频数， TRC是位于R行C列交叉处的理论频数。 （ ARC - TRC ）反映实际频数与理论频数的差距，除以TRC 为的是考虑相对差距。所以，χ^2 值反映了实际频数与理论频数的吻合程度， χ^2 值大，说明实际频数与理论频数的差距大。 χ^2 值的大小除了与实际频数和理论频数的差的大小有关外，还与它们的行、列数有关。即自由度的大小。

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验13.png)

某药品检验所随机抽取574名成年人，研究抗生素的耐药性（资料如表8-11）。问两种人群的耐药率是否一致？

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验14.png)

### 9. 假设检验中的两类错误

```
第一类错误（弃真错误）：
原假设为真时拒绝原假设
第一类错误的概率为α

第二类错误（取伪错误）：
原假设为假时接受原假设
第二类错误的概率为β
```

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验15.png)

```
一个公司有员工3000 人（研究的总体） ，为了检验公司员工工资统计报表的真实性，研究者作了 50 人的大样本随机抽样调查，人均收入的调查结果是： X （样本均值）=871 元；S（标准差）=21 元 问能否认为统计报表中人均收入μ0=880 元的数据是真实的？（显著性水平α=0.05 ）

原假设 H0：调查数据 871 元与报表数据 880 元之间没有显著性差异，公司员工工资均值的真实情况为880 元；
假设 H1：调查数据和报表数据之间有显著性的差异，公司员工工资均值的真实情况不是880 元。
α 错误出现原因：
我们只抽了一个样本，而个别的样本可能是特殊的，不管你的抽样多么符合科学抽样的要求。理论上讲，在 3000 个员工中随机抽取 50 人作为调查样本，有很多种构成样本的可能性，相当于 3000 选 50，这个数目是很大的。这样，在理论上就有存在很多个样本平均数。也就是说，由于小概率事件的出现，我们把本来真实的原假设拒绝了。这就是 α 错误出现的原因。

β 错误出现原因：
第二个问题是，统计检验的逻辑犯了从结论推断前提的错误。命题 B 是由命题 A 经演绎推论出来的，或写作符号 A→B，命题 C 是我们在检验中所依据操作法则。如果A 是真的，且我们从 A 到 B 的演绎推论如果也是正确的，那么B 可能是真实的。相反，如果结果 B是真实的，那么就不能得出A 必定是真实的结论。这就是 β错误出现的原因。

α 错误概率计算：
由实际推断原理引起的，即“小概率事件不会发生”的假定所引起的，所以有理由将所有小概率事件发生的概率之和或者即显著性水平（α=0.05）看作α错误发生的概率，换言之，α错误发生的概率为检验所选择的显著性水平。如果是单侧检验，弃真错误的概率则为 α/2。

β错误的概率计算：
犯β错误的概率的计算是比较复杂的，由于β错误的出现原因是属于逻辑上的，所以在总体参数不知道的情况下是无法计算它出现概率的大小的。 我们在以上例子的基础上进一步设计：这个公司职员的实际工资不是880 元，而是是 870 元，原假设为伪，仍然假设实际工资是880元。这样我们就可以在总体均值为 870 元和 880元两种情况下， 分别作出两条正态分布曲线 （A线和 B 线）

犯 β错误的概率大小就是相对正态曲线A 而言，图 1 中阴影部分的面积： ZX1=1.41 ；ZX2=5.59
查标准正态分布表可知，β=Φ（ZX2）-Φ（ZX1）=0.0793 结果表明，如果总体的真值为 870 元，而虚无假设为880元的话，那么，平均而言每100 次抽样中，将约有8次把真实情况当作880 元被接受，即犯β错误的概率大小是0.0793。

犯第一类错误的危害较大，由于报告了本来不存在的现象，则因此现象而衍生出的后续研究、应用的危害将是不可估量的。想对而言，第二类错误的危害则相对较小，因为研究者如果对自己的假设很有信心，可能会重新设计实验，再次来过，直到得到自己满意的结果（但是如果对本就错误的观点坚持的话，可能会演变成第一类错误）。
```

### 10. 案例：假设检验

```python
import pandas as pd
import pylab
import math
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np
from scipy.stats import norm
import scipy.stats
import warnings
warnings.filterwarnings("ignore")


df = pd.read_csv('normtemp.txt',sep='   ',names = ['Temperature','Gender','Heart Rate'])
```

要保证数据为正态分布

```python
observed_temperatures = df['Temperature'].sort_values()
bin_val = np.arange(start= observed_temperatures.min(), stop= observed_temperatures.max(), step = .05)
mu, std = np.mean(observed_temperatures), np.std(observed_temperatures)


p = norm.pdf(observed_temperatures, mu, std)


plt.hist(observed_temperatures,bins = bin_val, normed=True, stacked=True)
plt.plot(observed_temperatures, p, color = 'red')
plt.xticks(np.arange(95.75,101.25,0.25),rotation=90)
plt.xlabel('Human Body Temperature Distributions')
plt.xlabel('human body temperature')
plt.show()

print('Average (Mu): '+ str(mu) + ' / ' 'Standard Deviation: '+str(std))
```

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验16.png)

```python
x = observed_temperatures

#Shapiro-Wilk Test: https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test
shapiro_test, shapiro_p = scipy.stats.shapiro(x)
print("Shapiro-Wilk Stat:",shapiro_test, " Shapiro-Wilk p-Value:", shapiro_p)

k2, p = scipy.stats.normaltest(observed_temperatures)
print('p:',p) # p值大于0.05 可以接受假设 符合正态分布


#Another method to determining normality is through Quantile-Quantile Plots.
scipy.stats.probplot(observed_temperatures, dist="norm", plot=pylab)
pylab.show()
```

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验17.png)

```python
def ecdf(data):
    #Compute ECDF
    n = len(data)
    x = np.sort(data)
    y = np.arange(1, n+1) / n
    return x, y

# Compute empirical mean and standard deviation

# Number of samples
n = len(df['Temperature']) 

# Sample mean
mu = np.mean(df['Temperature']) 

# Sample standard deviation
std = np.std(df['Temperature']) 

print('Mean temperature: ', mu, 'with standard deviation of +/-', std)

#Random sampling of the data based off of the mean of the data.
normalized_sample = np.random.normal(mu, std, size=10000)
x_temperature, y_temperature = ecdf(df['Temperature'])
normalized_x, normalized_y = ecdf(normalized_sample)

# Plot the ECDFs
fig = plt.figure(figsize=(8, 5))
plt.plot(normalized_x, normalized_y)
plt.plot(x_temperature, y_temperature, marker='.', linestyle='none')
plt.ylabel('ECDF')
plt.xlabel('Temperature')
plt.legend(('Normal Distribution', 'Sample data'))
```

![](https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/math/假设检验18.png)

有学者提出98.6是人类的平均体温，我们该这样认为吗？
在这里我们选择t检验，因为我们只能计算样本的标准差

```python

from scipy import stats
# T检验
CW_mu = 98.6
stats.ttest_1samp(df['Temperature'], CW_mu, axis=0)
Ttest_1sampResult(statistic=-5.4548232923640771, pvalue=2.4106320415610081e-07)
# T-Stat -5.454 p-value近乎0了. 我们该拒绝这样的假设
```

男性和女性的体温有明显差异吗
两独立样本t检验 H0: 没有明显差异 H1: 有明显差异

```python

female_temp = df.Temperature[df.Gender == 2]
male_temp = df.Temperature[df.Gender == 1]
mean_female_temp = np.mean(female_temp)
mean_male_temp = np.mean(male_temp)
print('Average female body temperature = ' + str(mean_female_temp))
print('Average male body temperature = ' + str(mean_male_temp))

# Compute independent t-test  独立的
stats.ttest_ind(female_temp, male_temp, axis=0)
Average female body temperature = 98.39384615384616
Average male body temperature = 98.1046153846154
Ttest_indResult(statistic=2.2854345381654984, pvalue=0.02393188312240236)
# 由于P值=0.024 < 0.05，我们需要拒绝原假设，我们有%95的自信认为是有差异的！
```

### 11. 案例： 卡方检验

白人和黑人在求职路上会有种族的歧视吗？

```python
data = pd.io.stata.read_stata('us_job_market_discrimination.dta')
blacks = data[data.race == 'b']
whites = data[data.race == 'w']
```

```
卡方检验
白人获得职位
白人被拒绝
黑人获得职位
黑人被拒绝

假设检验
H0：种族对求职结果没有显著影响
H1：种族对求职结果有影响
```

```python
blacks_called = len(blacks[blacks['call'] == True])
blacks_not_called = len(blacks[blacks['call'] == False])
whites_called = len(whites[whites['call'] == True])
whites_not_called = len(whites[whites['call'] == False])
observed = pd.DataFrame({'blacks': {'called': blacks_called, 'not_called': blacks_not_called},
                         'whites': {'called' : whites_called, 'not_called' : whites_not_called}})

num_called_back = blacks_called + whites_called
num_not_called = blacks_not_called + whites_not_called

# 得到期望的比率
rate_of_callbacks = num_called_back / (num_not_called + num_called_back)
expected_called = len(data)  * rate_of_callbacks
expected_not_called = len(data)  * (1 - rate_of_callbacks)

import scipy.stats as stats
observed_frequencies = [blacks_not_called, whites_not_called, whites_called, blacks_called]
expected_frequencies = [expected_not_called/2, expected_not_called/2, expected_called/2, expected_called/2]

stats.chisquare(f_obs = observed_frequencies,
                f_exp = expected_frequencies)
Power_divergenceResult(statistic=16.879050414270221, pvalue=0.00074839594410972638)
# 看起来种族歧视是存在的！
```
