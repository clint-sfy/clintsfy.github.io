import{_ as t}from"./chunks/ArticleMetadata.59a467b2.js";import{_ as c,v as l,b as r,t as y,O as A,F as p,L as i,R as C,M as D,C as F,B}from"./chunks/framework.5cbdba25.js";import"./chunks/md5.02486a14.js";const q=JSON.parse('{"title":"线性回归","description":"","frontmatter":{"title":"线性回归","author":"阿源","date":"2023/07/01 12:00","categories":["机器学习快速入门"],"tags":["机器学习"]},"headers":[],"relativePath":"courses/tangyudi/02-机器学习篇/01-线性回归.md","filePath":"courses/tangyudi/02-机器学习篇/01-线性回归.md","lastUpdated":1695348718000}'),E={name:"courses/tangyudi/02-机器学习篇/01-线性回归.md"},d=p("h1",{id:"线性回归",tabindex:"-1"},[i("线性回归 "),p("a",{class:"header-anchor",href:"#线性回归","aria-label":'Permalink to "线性回归"'},"​")],-1),_=C(`<h2 id="_1-线性回归原理推导" tabindex="-1">1. 线性回归原理推导 <a class="header-anchor" href="#_1-线性回归原理推导" aria-label="Permalink to &quot;1. 线性回归原理推导&quot;">​</a></h2><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/ML/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%921.png" alt=""></p><h2 id="_2-线性回归代码实现" tabindex="-1">2. 线性回归代码实现 <a class="header-anchor" href="#_2-线性回归代码实现" aria-label="Permalink to &quot;2. 线性回归代码实现&quot;">​</a></h2><h3 id="通用代码" tabindex="-1">通用代码 <a class="header-anchor" href="#通用代码" aria-label="Permalink to &quot;通用代码&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> numpy </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> np</span></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> utils.features </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> prepare_for_training</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">class</span><span style="color:#ADBAC7;"> </span><span style="color:#F69D50;">LinearRegression</span><span style="color:#ADBAC7;">:</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">__init__</span><span style="color:#ADBAC7;">(self,data,labels,polynomial_degree </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,sinusoid_degree </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,normalize_data</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">True</span><span style="color:#ADBAC7;">):</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#96D0FF;">        1.对数据进行预处理操作</span></span>
<span class="line"><span style="color:#96D0FF;">        2.先得到所有的特征个数</span></span>
<span class="line"><span style="color:#96D0FF;">        3.初始化参数矩阵</span></span>
<span class="line"><span style="color:#96D0FF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#ADBAC7;">        (data_processed,</span></span>
<span class="line"><span style="color:#ADBAC7;">         features_mean, </span></span>
<span class="line"><span style="color:#ADBAC7;">         features_deviation) </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> prepare_for_training(data, polynomial_degree, sinusoid_degree,</span><span style="color:#F69D50;">normalize_data</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">True</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#768390;"># print(data_processed)</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> data_processed  </span><span style="color:#768390;"># 预处理完的数据</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.labels </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> labels  </span><span style="color:#768390;"># 标签</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.features_mean </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> features_mean  </span><span style="color:#768390;">#</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.features_deviation </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> features_deviation</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.polynomial_degree </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> polynomial_degree</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.sinusoid_degree </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> sinusoid_degree</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.normalize_data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> normalize_data</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span></span>
<span class="line"><span style="color:#ADBAC7;">        num_features </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.data.shape[</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.zeros((num_features,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#768390;"># train(学习率  迭代次数)</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">train</span><span style="color:#ADBAC7;">(self,alpha,num_iterations </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">500</span><span style="color:#ADBAC7;">):</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#96D0FF;">                    训练模块，执行梯度下降</span></span>
<span class="line"><span style="color:#96D0FF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#ADBAC7;">        cost_history </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.gradient_descent(alpha,num_iterations)</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">return</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.theta,cost_history</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#768390;"># 实现小批量梯度下降法</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">gradient_descent</span><span style="color:#ADBAC7;">(self,alpha,num_iterations):</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#96D0FF;">                    实际迭代模块，会迭代num_iterations次</span></span>
<span class="line"><span style="color:#96D0FF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#ADBAC7;">        cost_history </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> []</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> _ </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(num_iterations):</span></span>
<span class="line"><span style="color:#ADBAC7;">            </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.gradient_step(alpha)</span></span>
<span class="line"><span style="color:#ADBAC7;">            cost_history.append(</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.cost_function(</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.data,</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.labels))</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">return</span><span style="color:#ADBAC7;"> cost_history</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#768390;"># 实现小批量梯度下降法 具体步骤</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">gradient_step</span><span style="color:#ADBAC7;">(self,alpha):    </span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#96D0FF;">                    梯度下降参数更新计算方法，注意是矩阵运算</span></span>
<span class="line"><span style="color:#96D0FF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#768390;"># 样本的个数</span></span>
<span class="line"><span style="color:#ADBAC7;">        num_examples </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.data.shape[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#768390;"># 预测值 predictions = np.dot(data,theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">        prediction </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression.hypothesis(</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.data,</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#768390;"># 残差 = 预测值 - 真实值</span></span>
<span class="line"><span style="color:#ADBAC7;">        delta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> prediction </span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.labels</span></span>
<span class="line"><span style="color:#ADBAC7;">        theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.theta</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#768390;"># 更新theta 小批量梯度下降法</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#768390;"># 公式直接带进去</span></span>
<span class="line"><span style="color:#ADBAC7;">        theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> theta </span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;"> alpha</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">(</span><span style="color:#6CB6FF;">1</span><span style="color:#F47067;">/</span><span style="color:#ADBAC7;">num_examples)</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">(np.dot(delta.T,</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.data)).T</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> theta</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">cost_function</span><span style="color:#ADBAC7;">(self,data,labels):</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#96D0FF;">                    损失计算方法</span></span>
<span class="line"><span style="color:#96D0FF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#768390;"># 该函数会计算模型预测值和实际值之间的平均误差的平方和，然后将其除以样本数量得到平均误差值作为损失值。</span></span>
<span class="line"><span style="color:#ADBAC7;">        num_examples </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> data.shape[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">        delta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression.hypothesis(</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.data,</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.theta) </span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;"> labels</span></span>
<span class="line"><span style="color:#ADBAC7;">        cost </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> (</span><span style="color:#6CB6FF;">1</span><span style="color:#F47067;">/</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">)</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">np.dot(delta.T,delta)</span><span style="color:#F47067;">/</span><span style="color:#ADBAC7;">num_examples</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">return</span><span style="color:#ADBAC7;"> cost[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">][</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#DCBDFB;">@</span><span style="color:#6CB6FF;">staticmethod</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">hypothesis</span><span style="color:#ADBAC7;">(data,theta):   </span></span>
<span class="line"><span style="color:#ADBAC7;">        predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.dot(data,theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">return</span><span style="color:#ADBAC7;"> predictions</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#768390;"># 得到当前的损失</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">get_cost</span><span style="color:#ADBAC7;">(self,data,labels):  </span></span>
<span class="line"><span style="color:#ADBAC7;">        data_processed </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> prepare_for_training(data,</span></span>
<span class="line"><span style="color:#ADBAC7;">         </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.polynomial_degree,</span></span>
<span class="line"><span style="color:#ADBAC7;">         </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.sinusoid_degree,</span></span>
<span class="line"><span style="color:#ADBAC7;">         </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.normalize_data</span></span>
<span class="line"><span style="color:#ADBAC7;">         )[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">return</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.cost_function(data_processed,labels)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">predict</span><span style="color:#ADBAC7;">(self,data):</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#96D0FF;">                    用训练的参数模型，与预测得到回归值结果</span></span>
<span class="line"><span style="color:#96D0FF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#ADBAC7;">        data_processed </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> prepare_for_training(data,</span></span>
<span class="line"><span style="color:#ADBAC7;">         </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.polynomial_degree,</span></span>
<span class="line"><span style="color:#ADBAC7;">         </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.sinusoid_degree,</span></span>
<span class="line"><span style="color:#ADBAC7;">         </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.normalize_data</span></span>
<span class="line"><span style="color:#ADBAC7;">         )[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">         </span></span>
<span class="line"><span style="color:#ADBAC7;">        predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression.hypothesis(data_processed,</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">return</span><span style="color:#ADBAC7;"> predictions</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> numpy </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> np</span></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> utils.features </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> prepare_for_training</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">LinearRegression</span><span style="color:#24292E;">:</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">(self,data,labels,polynomial_degree </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,sinusoid_degree </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,normalize_data</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">        1.对数据进行预处理操作</span></span>
<span class="line"><span style="color:#032F62;">        2.先得到所有的特征个数</span></span>
<span class="line"><span style="color:#032F62;">        3.初始化参数矩阵</span></span>
<span class="line"><span style="color:#032F62;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">        (data_processed,</span></span>
<span class="line"><span style="color:#24292E;">         features_mean, </span></span>
<span class="line"><span style="color:#24292E;">         features_deviation) </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> prepare_for_training(data, polynomial_degree, sinusoid_degree,</span><span style="color:#E36209;">normalize_data</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># print(data_processed)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data_processed  </span><span style="color:#6A737D;"># 预处理完的数据</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.labels </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> labels  </span><span style="color:#6A737D;"># 标签</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.features_mean </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> features_mean  </span><span style="color:#6A737D;">#</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.features_deviation </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> features_deviation</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.polynomial_degree </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> polynomial_degree</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.sinusoid_degree </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> sinusoid_degree</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.normalize_data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> normalize_data</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"><span style="color:#24292E;">        num_features </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data.shape[</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.zeros((num_features,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># train(学习率  迭代次数)</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">train</span><span style="color:#24292E;">(self,alpha,num_iterations </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">500</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">                    训练模块，执行梯度下降</span></span>
<span class="line"><span style="color:#032F62;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">        cost_history </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.gradient_descent(alpha,num_iterations)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.theta,cost_history</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 实现小批量梯度下降法</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">gradient_descent</span><span style="color:#24292E;">(self,alpha,num_iterations):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">                    实际迭代模块，会迭代num_iterations次</span></span>
<span class="line"><span style="color:#032F62;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">        cost_history </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> []</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> _ </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(num_iterations):</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.gradient_step(alpha)</span></span>
<span class="line"><span style="color:#24292E;">            cost_history.append(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.cost_function(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data,</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.labels))</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> cost_history</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 实现小批量梯度下降法 具体步骤</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">gradient_step</span><span style="color:#24292E;">(self,alpha):    </span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">                    梯度下降参数更新计算方法，注意是矩阵运算</span></span>
<span class="line"><span style="color:#032F62;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 样本的个数</span></span>
<span class="line"><span style="color:#24292E;">        num_examples </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data.shape[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 预测值 predictions = np.dot(data,theta)</span></span>
<span class="line"><span style="color:#24292E;">        prediction </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression.hypothesis(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data,</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.theta)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 残差 = 预测值 - 真实值</span></span>
<span class="line"><span style="color:#24292E;">        delta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> prediction </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.labels</span></span>
<span class="line"><span style="color:#24292E;">        theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.theta</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 更新theta 小批量梯度下降法</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 公式直接带进去</span></span>
<span class="line"><span style="color:#24292E;">        theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> theta </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> alpha</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">1</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">num_examples)</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">(np.dot(delta.T,</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data)).T</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> theta</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">cost_function</span><span style="color:#24292E;">(self,data,labels):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">                    损失计算方法</span></span>
<span class="line"><span style="color:#032F62;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 该函数会计算模型预测值和实际值之间的平均误差的平方和，然后将其除以样本数量得到平均误差值作为损失值。</span></span>
<span class="line"><span style="color:#24292E;">        num_examples </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data.shape[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">        delta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression.hypothesis(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data,</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.theta) </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> labels</span></span>
<span class="line"><span style="color:#24292E;">        cost </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> (</span><span style="color:#005CC5;">1</span><span style="color:#D73A49;">/</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">)</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">np.dot(delta.T,delta)</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">num_examples</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> cost[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">][</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6F42C1;">@</span><span style="color:#005CC5;">staticmethod</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">hypothesis</span><span style="color:#24292E;">(data,theta):   </span></span>
<span class="line"><span style="color:#24292E;">        predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.dot(data,theta)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> predictions</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 得到当前的损失</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">get_cost</span><span style="color:#24292E;">(self,data,labels):  </span></span>
<span class="line"><span style="color:#24292E;">        data_processed </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> prepare_for_training(data,</span></span>
<span class="line"><span style="color:#24292E;">         </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.polynomial_degree,</span></span>
<span class="line"><span style="color:#24292E;">         </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.sinusoid_degree,</span></span>
<span class="line"><span style="color:#24292E;">         </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.normalize_data</span></span>
<span class="line"><span style="color:#24292E;">         )[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.cost_function(data_processed,labels)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">predict</span><span style="color:#24292E;">(self,data):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">                    用训练的参数模型，与预测得到回归值结果</span></span>
<span class="line"><span style="color:#032F62;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">        data_processed </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> prepare_for_training(data,</span></span>
<span class="line"><span style="color:#24292E;">         </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.polynomial_degree,</span></span>
<span class="line"><span style="color:#24292E;">         </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.sinusoid_degree,</span></span>
<span class="line"><span style="color:#24292E;">         </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.normalize_data</span></span>
<span class="line"><span style="color:#24292E;">         )[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">         </span></span>
<span class="line"><span style="color:#24292E;">        predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression.hypothesis(data_processed,</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.theta)</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> predictions</span></span></code></pre></div><h3 id="线性回归-1" tabindex="-1">线性回归 <a class="header-anchor" href="#线性回归-1" aria-label="Permalink to &quot;线性回归&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> numpy </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> np</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> pandas </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> pd</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> matplotlib.pyplot </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> linear_regression </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> LinearRegression</span></span>
<span class="line"></span>
<span class="line"><span style="color:#768390;"># 根据gdp 去预测幸福指数</span></span>
<span class="line"><span style="color:#ADBAC7;">data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> pd.read_csv(</span><span style="color:#96D0FF;">&#39;../data/world-happiness-report-2017.csv&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#768390;"># 得到训练和测试数据</span></span>
<span class="line"><span style="color:#ADBAC7;">train_data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> data.sample(</span><span style="color:#F69D50;">frac</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.8</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">test_data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> data.drop(train_data.index)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">input_param_name </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;Economy..GDP.per.Capita.&#39;</span></span>
<span class="line"><span style="color:#ADBAC7;">output_param_name </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;Happiness.Score&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#768390;"># 这里要注意！传数组进去！二维矩阵</span></span>
<span class="line"><span style="color:#ADBAC7;">x_train </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> train_data[[input_param_name]].values</span></span>
<span class="line"><span style="color:#ADBAC7;">y_train </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> train_data[[output_param_name]].values</span></span>
<span class="line"></span>
<span class="line"><span style="color:#768390;"># 这里是一维的</span></span>
<span class="line"><span style="color:#ADBAC7;">x_test </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> test_data[input_param_name].values</span></span>
<span class="line"><span style="color:#ADBAC7;">y_test </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> test_data[output_param_name].values</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.scatter(x_train,y_train,</span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;Train data&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.scatter(x_test,y_test,</span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;test data&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.xlabel(input_param_name)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.ylabel(output_param_name)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.title(</span><span style="color:#96D0FF;">&#39;Happy&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.legend()</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#768390;"># 开始训练回归模型</span></span>
<span class="line"><span style="color:#ADBAC7;">num_iterations </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">500</span></span>
<span class="line"><span style="color:#ADBAC7;">learning_rate </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.01</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">linear_regression </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression(x_train,y_train)</span></span>
<span class="line"><span style="color:#ADBAC7;">(theta,cost_history) </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> linear_regression.train(learning_rate,num_iterations)</span></span>
<span class="line"><span style="color:#768390;"># cost_history 是一个损失函数的列表</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (</span><span style="color:#96D0FF;">&#39;开始时的损失：&#39;</span><span style="color:#ADBAC7;">,cost_history[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (</span><span style="color:#96D0FF;">&#39;训练后的损失：&#39;</span><span style="color:#ADBAC7;">,cost_history[</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(</span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(num_iterations),cost_history)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.xlabel(</span><span style="color:#96D0FF;">&#39;Iter&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.ylabel(</span><span style="color:#96D0FF;">&#39;cost&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.title(</span><span style="color:#96D0FF;">&#39;GD&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">predictions_num </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">100</span></span>
<span class="line"><span style="color:#768390;"># 生成一个指定间隔序列 记得要变成一个二维数组 （，100）-&gt;（100,1）</span></span>
<span class="line"><span style="color:#ADBAC7;">x_predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.linspace(x_train.min(),x_train.max(),predictions_num).reshape(predictions_num,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">y_predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> linear_regression.predict(x_predictions)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.scatter(x_train,y_train,</span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;Train data&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.scatter(x_test,y_test,</span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;test data&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(x_predictions,y_predictions,</span><span style="color:#96D0FF;">&#39;r&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">label</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;Prediction&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.xlabel(input_param_name)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.ylabel(output_param_name)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.title(</span><span style="color:#96D0FF;">&#39;Happy&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.legend()</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> numpy </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> np</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> pandas </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> pd</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> matplotlib.pyplot </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> linear_regression </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> LinearRegression</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 根据gdp 去预测幸福指数</span></span>
<span class="line"><span style="color:#24292E;">data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> pd.read_csv(</span><span style="color:#032F62;">&#39;../data/world-happiness-report-2017.csv&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 得到训练和测试数据</span></span>
<span class="line"><span style="color:#24292E;">train_data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data.sample(</span><span style="color:#E36209;">frac</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.8</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">test_data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data.drop(train_data.index)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">input_param_name </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;Economy..GDP.per.Capita.&#39;</span></span>
<span class="line"><span style="color:#24292E;">output_param_name </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;Happiness.Score&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 这里要注意！传数组进去！二维矩阵</span></span>
<span class="line"><span style="color:#24292E;">x_train </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> train_data[[input_param_name]].values</span></span>
<span class="line"><span style="color:#24292E;">y_train </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> train_data[[output_param_name]].values</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 这里是一维的</span></span>
<span class="line"><span style="color:#24292E;">x_test </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> test_data[input_param_name].values</span></span>
<span class="line"><span style="color:#24292E;">y_test </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> test_data[output_param_name].values</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.scatter(x_train,y_train,</span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Train data&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.scatter(x_test,y_test,</span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;test data&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.xlabel(input_param_name)</span></span>
<span class="line"><span style="color:#24292E;">plt.ylabel(output_param_name)</span></span>
<span class="line"><span style="color:#24292E;">plt.title(</span><span style="color:#032F62;">&#39;Happy&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.legend()</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 开始训练回归模型</span></span>
<span class="line"><span style="color:#24292E;">num_iterations </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">500</span></span>
<span class="line"><span style="color:#24292E;">learning_rate </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.01</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">linear_regression </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression(x_train,y_train)</span></span>
<span class="line"><span style="color:#24292E;">(theta,cost_history) </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> linear_regression.train(learning_rate,num_iterations)</span></span>
<span class="line"><span style="color:#6A737D;"># cost_history 是一个损失函数的列表</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (</span><span style="color:#032F62;">&#39;开始时的损失：&#39;</span><span style="color:#24292E;">,cost_history[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (</span><span style="color:#032F62;">&#39;训练后的损失：&#39;</span><span style="color:#24292E;">,cost_history[</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.plot(</span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(num_iterations),cost_history)</span></span>
<span class="line"><span style="color:#24292E;">plt.xlabel(</span><span style="color:#032F62;">&#39;Iter&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.ylabel(</span><span style="color:#032F62;">&#39;cost&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.title(</span><span style="color:#032F62;">&#39;GD&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">predictions_num </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">100</span></span>
<span class="line"><span style="color:#6A737D;"># 生成一个指定间隔序列 记得要变成一个二维数组 （，100）-&gt;（100,1）</span></span>
<span class="line"><span style="color:#24292E;">x_predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.linspace(x_train.min(),x_train.max(),predictions_num).reshape(predictions_num,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">y_predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> linear_regression.predict(x_predictions)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.scatter(x_train,y_train,</span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Train data&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.scatter(x_test,y_test,</span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;test data&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(x_predictions,y_predictions,</span><span style="color:#032F62;">&#39;r&#39;</span><span style="color:#24292E;">,</span><span style="color:#E36209;">label</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;Prediction&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.xlabel(input_param_name)</span></span>
<span class="line"><span style="color:#24292E;">plt.ylabel(output_param_name)</span></span>
<span class="line"><span style="color:#24292E;">plt.title(</span><span style="color:#032F62;">&#39;Happy&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.legend()</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><h3 id="多特征回归模型" tabindex="-1">多特征回归模型 <a class="header-anchor" href="#多特征回归模型" aria-label="Permalink to &quot;多特征回归模型&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> numpy </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> np</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> pandas </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> pd</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> matplotlib.pyplot </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> plt</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> plotly</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> plotly.graph_objs </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> go</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plotly.offline.init_notebook_mode()</span></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> linear_regression </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> LinearRegression</span></span>
<span class="line"><span style="color:#768390;"># 多特征回归模型</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> pd.read_csv(</span><span style="color:#96D0FF;">&#39;../data/world-happiness-report-2017.csv&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">train_data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> data.sample(</span><span style="color:#F69D50;">frac</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">0.8</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">test_data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> data.drop(train_data.index)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">input_param_name_1 </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;Economy..GDP.per.Capita.&#39;</span></span>
<span class="line"><span style="color:#ADBAC7;">input_param_name_2 </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;Freedom&#39;</span></span>
<span class="line"><span style="color:#ADBAC7;">output_param_name </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;Happiness.Score&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x_train </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> train_data[[input_param_name_1, input_param_name_2]].values</span></span>
<span class="line"><span style="color:#ADBAC7;">y_train </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> train_data[[output_param_name]].values</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x_test </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> test_data[[input_param_name_1, input_param_name_2]].values</span></span>
<span class="line"><span style="color:#ADBAC7;">y_test </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> test_data[[output_param_name]].values</span></span>
<span class="line"></span>
<span class="line"><span style="color:#768390;"># Configure the plot with training dataset.</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_training_trace </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> go.Scatter3d(</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">x</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">x_train[:, </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">].flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">y</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">x_train[:, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">].flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">z</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">y_train.flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">name</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;Training Set&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">mode</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;markers&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">marker</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">{</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;size&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;opacity&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;line&#39;</span><span style="color:#ADBAC7;">: {</span></span>
<span class="line"><span style="color:#ADBAC7;">            </span><span style="color:#96D0FF;">&#39;color&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#96D0FF;">&#39;rgb(255, 255, 255)&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">            </span><span style="color:#96D0FF;">&#39;width&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">1</span></span>
<span class="line"><span style="color:#ADBAC7;">        },</span></span>
<span class="line"><span style="color:#ADBAC7;">    }</span></span>
<span class="line"><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plot_test_trace </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> go.Scatter3d(</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">x</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">x_test[:, </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">].flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">y</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">x_test[:, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">].flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">z</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">y_test.flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">name</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;Test Set&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">mode</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;markers&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">marker</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">{</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;size&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;opacity&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;line&#39;</span><span style="color:#ADBAC7;">: {</span></span>
<span class="line"><span style="color:#ADBAC7;">            </span><span style="color:#96D0FF;">&#39;color&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#96D0FF;">&#39;rgb(255, 255, 255)&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">            </span><span style="color:#96D0FF;">&#39;width&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">1</span></span>
<span class="line"><span style="color:#ADBAC7;">        },</span></span>
<span class="line"><span style="color:#ADBAC7;">    }</span></span>
<span class="line"><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plot_layout </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> go.Layout(</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">title</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;Date Sets&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">scene</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">{</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;xaxis&#39;</span><span style="color:#ADBAC7;">: {</span><span style="color:#96D0FF;">&#39;title&#39;</span><span style="color:#ADBAC7;">: input_param_name_1},</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;yaxis&#39;</span><span style="color:#ADBAC7;">: {</span><span style="color:#96D0FF;">&#39;title&#39;</span><span style="color:#ADBAC7;">: input_param_name_2},</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;zaxis&#39;</span><span style="color:#ADBAC7;">: {</span><span style="color:#96D0FF;">&#39;title&#39;</span><span style="color:#ADBAC7;">: output_param_name} </span></span>
<span class="line"><span style="color:#ADBAC7;">    },</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">margin</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">{</span><span style="color:#96D0FF;">&#39;l&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">, </span><span style="color:#96D0FF;">&#39;r&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">, </span><span style="color:#96D0FF;">&#39;b&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">, </span><span style="color:#96D0FF;">&#39;t&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">}</span></span>
<span class="line"><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plot_data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [plot_training_trace, plot_test_trace]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plot_figure </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> go.Figure(</span><span style="color:#F69D50;">data</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">plot_data, </span><span style="color:#F69D50;">layout</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">plot_layout)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plotly.offline.plot(plot_figure) </span><span style="color:#768390;"># 如果要用jupter 改成plotly.offline.iplot</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">num_iterations </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">500</span><span style="color:#ADBAC7;">  </span></span>
<span class="line"><span style="color:#ADBAC7;">learning_rate </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.01</span><span style="color:#ADBAC7;">  </span></span>
<span class="line"><span style="color:#ADBAC7;">polynomial_degree </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">  </span></span>
<span class="line"><span style="color:#ADBAC7;">sinusoid_degree </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">  </span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">linear_regression </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression(x_train, y_train, polynomial_degree, sinusoid_degree)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">(theta, cost_history) </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> linear_regression.train(</span></span>
<span class="line"><span style="color:#ADBAC7;">    learning_rate,</span></span>
<span class="line"><span style="color:#ADBAC7;">    num_iterations</span></span>
<span class="line"><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;">(</span><span style="color:#96D0FF;">&#39;开始损失&#39;</span><span style="color:#ADBAC7;">,cost_history[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;">(</span><span style="color:#96D0FF;">&#39;结束损失&#39;</span><span style="color:#ADBAC7;">,cost_history[</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(</span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(num_iterations), cost_history)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.xlabel(</span><span style="color:#96D0FF;">&#39;Iterations&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.ylabel(</span><span style="color:#96D0FF;">&#39;Cost&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.title(</span><span style="color:#96D0FF;">&#39;Gradient Descent Progress&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">predictions_num </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">10</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x_min </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> x_train[:, </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">].min()</span><span style="color:#FF938A;font-style:italic;">;</span></span>
<span class="line"><span style="color:#ADBAC7;">x_max </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> x_train[:, </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">].max()</span><span style="color:#FF938A;font-style:italic;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">y_min </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> x_train[:, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">].min()</span><span style="color:#FF938A;font-style:italic;">;</span></span>
<span class="line"><span style="color:#ADBAC7;">y_max </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> x_train[:, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">].max()</span><span style="color:#FF938A;font-style:italic;">;</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x_axis </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.linspace(x_min, x_max, predictions_num)</span></span>
<span class="line"><span style="color:#ADBAC7;">y_axis </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.linspace(y_min, y_max, predictions_num)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x_predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.zeros((predictions_num </span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;"> predictions_num, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">y_predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.zeros((predictions_num </span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;"> predictions_num, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x_y_index </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0</span></span>
<span class="line"><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> x_index, x_value </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">enumerate</span><span style="color:#ADBAC7;">(x_axis):</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> y_index, y_value </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">enumerate</span><span style="color:#ADBAC7;">(y_axis):</span></span>
<span class="line"><span style="color:#ADBAC7;">        x_predictions[x_y_index] </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> x_value</span></span>
<span class="line"><span style="color:#ADBAC7;">        y_predictions[x_y_index] </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> y_value</span></span>
<span class="line"><span style="color:#ADBAC7;">        x_y_index </span><span style="color:#F47067;">+=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">1</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">z_predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> linear_regression.predict(np.hstack((x_predictions, y_predictions)))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plot_predictions_trace </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> go.Scatter3d(</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">x</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">x_predictions.flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">y</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">y_predictions.flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">z</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">z_predictions.flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">name</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;Prediction Plane&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">mode</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;markers&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">marker</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">{</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;size&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    },</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">opacity</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">0.8</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">surfaceaxis</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">, </span></span>
<span class="line"><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plot_data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [plot_training_trace, plot_test_trace, plot_predictions_trace]</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_figure </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> go.Figure(</span><span style="color:#F69D50;">data</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">plot_data, </span><span style="color:#F69D50;">layout</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">plot_layout)</span></span>
<span class="line"><span style="color:#ADBAC7;">plotly.offline.plot(plot_figure)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> numpy </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> np</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> pandas </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> pd</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> matplotlib.pyplot </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> plt</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> plotly</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> plotly.graph_objs </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> go</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plotly.offline.init_notebook_mode()</span></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> linear_regression </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> LinearRegression</span></span>
<span class="line"><span style="color:#6A737D;"># 多特征回归模型</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> pd.read_csv(</span><span style="color:#032F62;">&#39;../data/world-happiness-report-2017.csv&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">train_data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data.sample(</span><span style="color:#E36209;">frac</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">0.8</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">test_data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data.drop(train_data.index)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">input_param_name_1 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;Economy..GDP.per.Capita.&#39;</span></span>
<span class="line"><span style="color:#24292E;">input_param_name_2 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;Freedom&#39;</span></span>
<span class="line"><span style="color:#24292E;">output_param_name </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;Happiness.Score&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x_train </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> train_data[[input_param_name_1, input_param_name_2]].values</span></span>
<span class="line"><span style="color:#24292E;">y_train </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> train_data[[output_param_name]].values</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x_test </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> test_data[[input_param_name_1, input_param_name_2]].values</span></span>
<span class="line"><span style="color:#24292E;">y_test </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> test_data[[output_param_name]].values</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># Configure the plot with training dataset.</span></span>
<span class="line"><span style="color:#24292E;">plot_training_trace </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> go.Scatter3d(</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">x</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">x_train[:, </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">].flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">y</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">x_train[:, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">].flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">z</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">y_train.flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">name</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Training Set&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">mode</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;markers&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">marker</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">{</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;size&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">10</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;opacity&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;line&#39;</span><span style="color:#24292E;">: {</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#032F62;">&#39;color&#39;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&#39;rgb(255, 255, 255)&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#032F62;">&#39;width&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">1</span></span>
<span class="line"><span style="color:#24292E;">        },</span></span>
<span class="line"><span style="color:#24292E;">    }</span></span>
<span class="line"><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plot_test_trace </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> go.Scatter3d(</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">x</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">x_test[:, </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">].flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">y</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">x_test[:, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">].flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">z</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">y_test.flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">name</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Test Set&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">mode</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;markers&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">marker</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">{</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;size&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">10</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;opacity&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;line&#39;</span><span style="color:#24292E;">: {</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#032F62;">&#39;color&#39;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&#39;rgb(255, 255, 255)&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#032F62;">&#39;width&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">1</span></span>
<span class="line"><span style="color:#24292E;">        },</span></span>
<span class="line"><span style="color:#24292E;">    }</span></span>
<span class="line"><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plot_layout </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> go.Layout(</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">title</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Date Sets&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">scene</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">{</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;xaxis&#39;</span><span style="color:#24292E;">: {</span><span style="color:#032F62;">&#39;title&#39;</span><span style="color:#24292E;">: input_param_name_1},</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;yaxis&#39;</span><span style="color:#24292E;">: {</span><span style="color:#032F62;">&#39;title&#39;</span><span style="color:#24292E;">: input_param_name_2},</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;zaxis&#39;</span><span style="color:#24292E;">: {</span><span style="color:#032F62;">&#39;title&#39;</span><span style="color:#24292E;">: output_param_name} </span></span>
<span class="line"><span style="color:#24292E;">    },</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">margin</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">{</span><span style="color:#032F62;">&#39;l&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&#39;r&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&#39;b&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&#39;t&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">}</span></span>
<span class="line"><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plot_data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [plot_training_trace, plot_test_trace]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plot_figure </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> go.Figure(</span><span style="color:#E36209;">data</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">plot_data, </span><span style="color:#E36209;">layout</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">plot_layout)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plotly.offline.plot(plot_figure) </span><span style="color:#6A737D;"># 如果要用jupter 改成plotly.offline.iplot</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">num_iterations </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">500</span><span style="color:#24292E;">  </span></span>
<span class="line"><span style="color:#24292E;">learning_rate </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.01</span><span style="color:#24292E;">  </span></span>
<span class="line"><span style="color:#24292E;">polynomial_degree </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">  </span></span>
<span class="line"><span style="color:#24292E;">sinusoid_degree </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">  </span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">linear_regression </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression(x_train, y_train, polynomial_degree, sinusoid_degree)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">(theta, cost_history) </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> linear_regression.train(</span></span>
<span class="line"><span style="color:#24292E;">    learning_rate,</span></span>
<span class="line"><span style="color:#24292E;">    num_iterations</span></span>
<span class="line"><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&#39;开始损失&#39;</span><span style="color:#24292E;">,cost_history[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&#39;结束损失&#39;</span><span style="color:#24292E;">,cost_history[</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.plot(</span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(num_iterations), cost_history)</span></span>
<span class="line"><span style="color:#24292E;">plt.xlabel(</span><span style="color:#032F62;">&#39;Iterations&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.ylabel(</span><span style="color:#032F62;">&#39;Cost&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.title(</span><span style="color:#032F62;">&#39;Gradient Descent Progress&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">predictions_num </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">10</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x_min </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x_train[:, </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">].min()</span><span style="color:#B31D28;font-style:italic;">;</span></span>
<span class="line"><span style="color:#24292E;">x_max </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x_train[:, </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">].max()</span><span style="color:#B31D28;font-style:italic;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">y_min </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x_train[:, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">].min()</span><span style="color:#B31D28;font-style:italic;">;</span></span>
<span class="line"><span style="color:#24292E;">y_max </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x_train[:, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">].max()</span><span style="color:#B31D28;font-style:italic;">;</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x_axis </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.linspace(x_min, x_max, predictions_num)</span></span>
<span class="line"><span style="color:#24292E;">y_axis </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.linspace(y_min, y_max, predictions_num)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x_predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.zeros((predictions_num </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> predictions_num, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">y_predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.zeros((predictions_num </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> predictions_num, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x_y_index </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> x_index, x_value </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">enumerate</span><span style="color:#24292E;">(x_axis):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> y_index, y_value </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">enumerate</span><span style="color:#24292E;">(y_axis):</span></span>
<span class="line"><span style="color:#24292E;">        x_predictions[x_y_index] </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x_value</span></span>
<span class="line"><span style="color:#24292E;">        y_predictions[x_y_index] </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> y_value</span></span>
<span class="line"><span style="color:#24292E;">        x_y_index </span><span style="color:#D73A49;">+=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">z_predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> linear_regression.predict(np.hstack((x_predictions, y_predictions)))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plot_predictions_trace </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> go.Scatter3d(</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">x</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">x_predictions.flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">y</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">y_predictions.flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">z</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">z_predictions.flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">name</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Prediction Plane&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">mode</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;markers&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">marker</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">{</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;size&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    },</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">opacity</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">0.8</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">surfaceaxis</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">, </span></span>
<span class="line"><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plot_data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [plot_training_trace, plot_test_trace, plot_predictions_trace]</span></span>
<span class="line"><span style="color:#24292E;">plot_figure </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> go.Figure(</span><span style="color:#E36209;">data</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">plot_data, </span><span style="color:#E36209;">layout</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">plot_layout)</span></span>
<span class="line"><span style="color:#24292E;">plotly.offline.plot(plot_figure)</span></span></code></pre></div><h3 id="非线性回归" tabindex="-1">非线性回归 <a class="header-anchor" href="#非线性回归" aria-label="Permalink to &quot;非线性回归&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> numpy </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> np</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> pandas </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> pd</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> matplotlib.pyplot </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> linear_regression </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> LinearRegression</span></span>
<span class="line"></span>
<span class="line"><span style="color:#768390;"># 非线性回归</span></span>
<span class="line"><span style="color:#ADBAC7;">data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> pd.read_csv(</span><span style="color:#96D0FF;">&#39;../data/non-linear-regression-x-y.csv&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> data[</span><span style="color:#96D0FF;">&#39;x&#39;</span><span style="color:#ADBAC7;">].values.reshape((data.shape[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">], </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">y </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> data[</span><span style="color:#96D0FF;">&#39;y&#39;</span><span style="color:#ADBAC7;">].values.reshape((data.shape[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">], </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">data.head(</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(x, y)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">num_iterations </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">50000</span><span style="color:#ADBAC7;">  </span></span>
<span class="line"><span style="color:#ADBAC7;">learning_rate </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.02</span></span>
<span class="line"><span style="color:#768390;"># 特征变换</span></span>
<span class="line"><span style="color:#ADBAC7;">polynomial_degree </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">15</span></span>
<span class="line"><span style="color:#ADBAC7;">sinusoid_degree </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">15</span></span>
<span class="line"><span style="color:#ADBAC7;">normalize_data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">True</span><span style="color:#ADBAC7;">  </span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">linear_regression </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression(x, y, polynomial_degree, sinusoid_degree, normalize_data)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">(theta, cost_history) </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> linear_regression.train(</span></span>
<span class="line"><span style="color:#ADBAC7;">    learning_rate,</span></span>
<span class="line"><span style="color:#ADBAC7;">    num_iterations</span></span>
<span class="line"><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;">(</span><span style="color:#96D0FF;">&#39;开始损失: </span><span style="color:#F47067;">{:.2f}</span><span style="color:#96D0FF;">&#39;</span><span style="color:#ADBAC7;">.format(cost_history[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">]))</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;">(</span><span style="color:#96D0FF;">&#39;结束损失: </span><span style="color:#F47067;">{:.2f}</span><span style="color:#96D0FF;">&#39;</span><span style="color:#ADBAC7;">.format(cost_history[</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">]))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">theta_table </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> pd.DataFrame({</span><span style="color:#96D0FF;">&#39;Model Parameters&#39;</span><span style="color:#ADBAC7;">: theta.flatten()})</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(</span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(num_iterations), cost_history)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.xlabel(</span><span style="color:#96D0FF;">&#39;Iterations&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.ylabel(</span><span style="color:#96D0FF;">&#39;Cost&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.title(</span><span style="color:#96D0FF;">&#39;Gradient Descent Progress&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">predictions_num </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">1000</span></span>
<span class="line"><span style="color:#ADBAC7;">x_predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.linspace(x.min(), x.max(), predictions_num).reshape(predictions_num, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span><span style="color:#FF938A;font-style:italic;">;</span></span>
<span class="line"><span style="color:#ADBAC7;">y_predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> linear_regression.predict(x_predictions)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.scatter(x, y, </span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;Training Dataset&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(x_predictions, y_predictions, </span><span style="color:#96D0FF;">&#39;r&#39;</span><span style="color:#ADBAC7;">, </span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;Prediction&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> numpy </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> np</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> pandas </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> pd</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> matplotlib.pyplot </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> linear_regression </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> LinearRegression</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 非线性回归</span></span>
<span class="line"><span style="color:#24292E;">data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> pd.read_csv(</span><span style="color:#032F62;">&#39;../data/non-linear-regression-x-y.csv&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data[</span><span style="color:#032F62;">&#39;x&#39;</span><span style="color:#24292E;">].values.reshape((data.shape[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">], </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">y </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data[</span><span style="color:#032F62;">&#39;y&#39;</span><span style="color:#24292E;">].values.reshape((data.shape[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">], </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">data.head(</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.plot(x, y)</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">num_iterations </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">50000</span><span style="color:#24292E;">  </span></span>
<span class="line"><span style="color:#24292E;">learning_rate </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.02</span></span>
<span class="line"><span style="color:#6A737D;"># 特征变换</span></span>
<span class="line"><span style="color:#24292E;">polynomial_degree </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">15</span></span>
<span class="line"><span style="color:#24292E;">sinusoid_degree </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">15</span></span>
<span class="line"><span style="color:#24292E;">normalize_data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">True</span><span style="color:#24292E;">  </span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">linear_regression </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression(x, y, polynomial_degree, sinusoid_degree, normalize_data)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">(theta, cost_history) </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> linear_regression.train(</span></span>
<span class="line"><span style="color:#24292E;">    learning_rate,</span></span>
<span class="line"><span style="color:#24292E;">    num_iterations</span></span>
<span class="line"><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&#39;开始损失: </span><span style="color:#005CC5;">{</span><span style="color:#D73A49;">:.2f</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&#39;</span><span style="color:#24292E;">.format(cost_history[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]))</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&#39;结束损失: </span><span style="color:#005CC5;">{</span><span style="color:#D73A49;">:.2f</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&#39;</span><span style="color:#24292E;">.format(cost_history[</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">]))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">theta_table </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> pd.DataFrame({</span><span style="color:#032F62;">&#39;Model Parameters&#39;</span><span style="color:#24292E;">: theta.flatten()})</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.plot(</span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(num_iterations), cost_history)</span></span>
<span class="line"><span style="color:#24292E;">plt.xlabel(</span><span style="color:#032F62;">&#39;Iterations&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.ylabel(</span><span style="color:#032F62;">&#39;Cost&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.title(</span><span style="color:#032F62;">&#39;Gradient Descent Progress&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">predictions_num </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1000</span></span>
<span class="line"><span style="color:#24292E;">x_predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.linspace(x.min(), x.max(), predictions_num).reshape(predictions_num, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span><span style="color:#B31D28;font-style:italic;">;</span></span>
<span class="line"><span style="color:#24292E;">y_predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> linear_regression.predict(x_predictions)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.scatter(x, y, </span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Training Dataset&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(x_predictions, y_predictions, </span><span style="color:#032F62;">&#39;r&#39;</span><span style="color:#24292E;">, </span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Prediction&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><h2 id="_3-线性回归实验分析" tabindex="-1">3. 线性回归实验分析 <a class="header-anchor" href="#_3-线性回归实验分析" aria-label="Permalink to &quot;3. 线性回归实验分析&quot;">​</a></h2><h3 id="回归方程" tabindex="-1">回归方程 <a class="header-anchor" href="#回归方程" aria-label="Permalink to &quot;回归方程&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> numpy </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> np</span></span>
<span class="line"><span style="color:#ADBAC7;">X </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">2</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">np.random.rand(</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">y </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">4</span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">3</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">X </span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;">np.random.randn(</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">X_b </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.c_[np.ones((</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)),X]</span></span>
<span class="line"><span style="color:#768390;"># array([[1.        , 0.74908024],</span></span>
<span class="line"></span>
<span class="line"><span style="color:#768390;"># linalg.inv 1求逆</span></span>
<span class="line"><span style="color:#ADBAC7;">theta_best </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)</span></span>
<span class="line"><span style="color:#ADBAC7;">theta_best</span></span>
<span class="line"><span style="color:#ADBAC7;">array([[</span><span style="color:#6CB6FF;">4.21509616</span><span style="color:#ADBAC7;">],</span></span>
<span class="line"><span style="color:#ADBAC7;">       [</span><span style="color:#6CB6FF;">2.77011339</span><span style="color:#ADBAC7;">]])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">X_new </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.array([[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">],[</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">]])</span></span>
<span class="line"><span style="color:#ADBAC7;">X_new_b </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.c_[np.ones((</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)),X_new]</span></span>
<span class="line"><span style="color:#ADBAC7;">y_predict </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> X_new_b.dot(theta_best)</span></span>
<span class="line"><span style="color:#ADBAC7;">y_predict</span></span>
<span class="line"><span style="color:#ADBAC7;">array([[</span><span style="color:#6CB6FF;">4.21509616</span><span style="color:#ADBAC7;">],</span></span>
<span class="line"><span style="color:#ADBAC7;">       [</span><span style="color:#6CB6FF;">9.75532293</span><span style="color:#ADBAC7;">]])</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> numpy </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> np</span></span>
<span class="line"><span style="color:#24292E;">X </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">np.random.rand(</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">y </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">4</span><span style="color:#D73A49;">+</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">3</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">X </span><span style="color:#D73A49;">+</span><span style="color:#24292E;">np.random.randn(</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">X_b </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.c_[np.ones((</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)),X]</span></span>
<span class="line"><span style="color:#6A737D;"># array([[1.        , 0.74908024],</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># linalg.inv 1求逆</span></span>
<span class="line"><span style="color:#24292E;">theta_best </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)</span></span>
<span class="line"><span style="color:#24292E;">theta_best</span></span>
<span class="line"><span style="color:#24292E;">array([[</span><span style="color:#005CC5;">4.21509616</span><span style="color:#24292E;">],</span></span>
<span class="line"><span style="color:#24292E;">       [</span><span style="color:#005CC5;">2.77011339</span><span style="color:#24292E;">]])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">X_new </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.array([[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">],[</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">]])</span></span>
<span class="line"><span style="color:#24292E;">X_new_b </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.c_[np.ones((</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)),X_new]</span></span>
<span class="line"><span style="color:#24292E;">y_predict </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> X_new_b.dot(theta_best)</span></span>
<span class="line"><span style="color:#24292E;">y_predict</span></span>
<span class="line"><span style="color:#24292E;">array([[</span><span style="color:#005CC5;">4.21509616</span><span style="color:#24292E;">],</span></span>
<span class="line"><span style="color:#24292E;">       [</span><span style="color:#005CC5;">9.75532293</span><span style="color:#24292E;">]])</span></span></code></pre></div><h3 id="梯度下降" tabindex="-1">梯度下降 <a class="header-anchor" href="#梯度下降" aria-label="Permalink to &quot;梯度下降&quot;">​</a></h3><h4 id="批量梯度下降计算公式" tabindex="-1">批量梯度下降计算公式 <a class="header-anchor" href="#批量梯度下降计算公式" aria-label="Permalink to &quot;批量梯度下降计算公式&quot;">​</a></h4><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%902.png" alt=""></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#ADBAC7;">eta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.1</span><span style="color:#ADBAC7;"> </span><span style="color:#768390;"># 学习率</span></span>
<span class="line"><span style="color:#ADBAC7;">n_iterations </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">1000</span></span>
<span class="line"><span style="color:#ADBAC7;">m </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;"> </span><span style="color:#768390;"># 样本个数</span></span>
<span class="line"><span style="color:#ADBAC7;">theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.random.randn(</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> iteration </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(n_iterations):</span></span>
<span class="line"><span style="color:#ADBAC7;">    gradients </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">2</span><span style="color:#F47067;">/</span><span style="color:#ADBAC7;">m</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;"> X_b.T.dot(X_b.dot(theta)</span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;">y)</span></span>
<span class="line"><span style="color:#ADBAC7;">    theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> theta </span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;"> eta</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">gradients</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">theta</span></span>
<span class="line"><span style="color:#ADBAC7;">array([[</span><span style="color:#6CB6FF;">4.21509616</span><span style="color:#ADBAC7;">],</span></span>
<span class="line"><span style="color:#ADBAC7;">       [</span><span style="color:#6CB6FF;">2.77011339</span><span style="color:#ADBAC7;">]])</span></span>
<span class="line"><span style="color:#ADBAC7;">theta_path_bgd </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> []</span></span>
<span class="line"><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">plot_gradient_descent</span><span style="color:#ADBAC7;">(theta,eta,theta_path </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">None</span><span style="color:#ADBAC7;">):</span></span>
<span class="line"><span style="color:#ADBAC7;">    m </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">len</span><span style="color:#ADBAC7;">(X_b)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.plot(X,y,</span><span style="color:#96D0FF;">&#39;b.&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    n_iterations </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">1000</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> iteration </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(n_iterations): </span></span>
<span class="line"><span style="color:#ADBAC7;">        y_predict </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> X_new_b.dot(theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">        plt.plot(X_new,y_predict,</span><span style="color:#96D0FF;">&#39;b-&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">        gradients </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">2</span><span style="color:#F47067;">/</span><span style="color:#ADBAC7;">m</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;"> X_b.T.dot(X_b.dot(theta)</span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;">y)</span></span>
<span class="line"><span style="color:#ADBAC7;">        theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> theta </span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;"> eta</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">gradients</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">if</span><span style="color:#ADBAC7;"> theta_path </span><span style="color:#F47067;">is</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">not</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">None</span><span style="color:#ADBAC7;">:</span></span>
<span class="line"><span style="color:#ADBAC7;">            theta_path.append(theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.xlabel(</span><span style="color:#96D0FF;">&#39;X_1&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.axis([</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">15</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.title(</span><span style="color:#96D0FF;">&#39;eta = </span><span style="color:#F47067;">{}</span><span style="color:#96D0FF;">&#39;</span><span style="color:#ADBAC7;">.format(eta))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.random.randn(</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.figure(</span><span style="color:#F69D50;">figsize</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">(</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">4</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.subplot(</span><span style="color:#6CB6FF;">131</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_gradient_descent(theta,</span><span style="color:#F69D50;">eta</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.02</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.subplot(</span><span style="color:#6CB6FF;">132</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_gradient_descent(theta,</span><span style="color:#F69D50;">eta</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.1</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">theta_path</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">theta_path_bgd)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.subplot(</span><span style="color:#6CB6FF;">133</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_gradient_descent(theta,</span><span style="color:#F69D50;">eta</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.5</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">eta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.1</span><span style="color:#24292E;"> </span><span style="color:#6A737D;"># 学习率</span></span>
<span class="line"><span style="color:#24292E;">n_iterations </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1000</span></span>
<span class="line"><span style="color:#24292E;">m </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">100</span><span style="color:#24292E;"> </span><span style="color:#6A737D;"># 样本个数</span></span>
<span class="line"><span style="color:#24292E;">theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.random.randn(</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> iteration </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(n_iterations):</span></span>
<span class="line"><span style="color:#24292E;">    gradients </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">m</span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> X_b.T.dot(X_b.dot(theta)</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">y)</span></span>
<span class="line"><span style="color:#24292E;">    theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> theta </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> eta</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">gradients</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">theta</span></span>
<span class="line"><span style="color:#24292E;">array([[</span><span style="color:#005CC5;">4.21509616</span><span style="color:#24292E;">],</span></span>
<span class="line"><span style="color:#24292E;">       [</span><span style="color:#005CC5;">2.77011339</span><span style="color:#24292E;">]])</span></span>
<span class="line"><span style="color:#24292E;">theta_path_bgd </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> []</span></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">plot_gradient_descent</span><span style="color:#24292E;">(theta,eta,theta_path </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">None</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    m </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">len</span><span style="color:#24292E;">(X_b)</span></span>
<span class="line"><span style="color:#24292E;">    plt.plot(X,y,</span><span style="color:#032F62;">&#39;b.&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    n_iterations </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1000</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> iteration </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(n_iterations): </span></span>
<span class="line"><span style="color:#24292E;">        y_predict </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> X_new_b.dot(theta)</span></span>
<span class="line"><span style="color:#24292E;">        plt.plot(X_new,y_predict,</span><span style="color:#032F62;">&#39;b-&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        gradients </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">m</span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> X_b.T.dot(X_b.dot(theta)</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">y)</span></span>
<span class="line"><span style="color:#24292E;">        theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> theta </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> eta</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">gradients</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> theta_path </span><span style="color:#D73A49;">is</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">not</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">None</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">            theta_path.append(theta)</span></span>
<span class="line"><span style="color:#24292E;">    plt.xlabel(</span><span style="color:#032F62;">&#39;X_1&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    plt.axis([</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">15</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#24292E;">    plt.title(</span><span style="color:#032F62;">&#39;eta = </span><span style="color:#005CC5;">{}</span><span style="color:#032F62;">&#39;</span><span style="color:#24292E;">.format(eta))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.random.randn(</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.figure(</span><span style="color:#E36209;">figsize</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">4</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.subplot(</span><span style="color:#005CC5;">131</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plot_gradient_descent(theta,</span><span style="color:#E36209;">eta</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.02</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.subplot(</span><span style="color:#005CC5;">132</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plot_gradient_descent(theta,</span><span style="color:#E36209;">eta</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.1</span><span style="color:#24292E;">,</span><span style="color:#E36209;">theta_path</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">theta_path_bgd)</span></span>
<span class="line"><span style="color:#24292E;">plt.subplot(</span><span style="color:#005CC5;">133</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plot_gradient_descent(theta,</span><span style="color:#E36209;">eta</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.5</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%903.png" alt=""></p><h4 id="随机梯度下降" tabindex="-1">随机梯度下降 <a class="header-anchor" href="#随机梯度下降" aria-label="Permalink to &quot;随机梯度下降&quot;">​</a></h4><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#ADBAC7;">theta_path_sgd</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">[]</span></span>
<span class="line"><span style="color:#ADBAC7;">m </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">len</span><span style="color:#ADBAC7;">(X_b)</span></span>
<span class="line"><span style="color:#ADBAC7;">np.random.seed(</span><span style="color:#6CB6FF;">42</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">n_epochs </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">50</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">t0 </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">5</span></span>
<span class="line"><span style="color:#ADBAC7;">t1 </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">50</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">learning_schedule</span><span style="color:#ADBAC7;">(t):</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">return</span><span style="color:#ADBAC7;"> t0</span><span style="color:#F47067;">/</span><span style="color:#ADBAC7;">(t1</span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;">t)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.random.randn(</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> epoch </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(n_epochs):</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> i </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(m):</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">if</span><span style="color:#ADBAC7;"> epoch </span><span style="color:#F47067;">&lt;</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">and</span><span style="color:#ADBAC7;"> i</span><span style="color:#F47067;">&lt;</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">:</span></span>
<span class="line"><span style="color:#ADBAC7;">            y_predict </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> X_new_b.dot(theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">            plt.plot(X_new,y_predict,</span><span style="color:#96D0FF;">&#39;r-&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">        random_index </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.random.randint(m)</span></span>
<span class="line"><span style="color:#ADBAC7;">        xi </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> X_b[random_index:random_index</span><span style="color:#F47067;">+</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">        yi </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> y[random_index:random_index</span><span style="color:#F47067;">+</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">        gradients </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">2</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;"> xi.T.dot(xi.dot(theta)</span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;">yi)</span></span>
<span class="line"><span style="color:#ADBAC7;">        eta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> learning_schedule(epoch</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">m</span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;">i)</span></span>
<span class="line"><span style="color:#ADBAC7;">        theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> theta</span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;">eta</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">gradients</span></span>
<span class="line"><span style="color:#ADBAC7;">        theta_path_sgd.append(theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(X,y,</span><span style="color:#96D0FF;">&#39;b.&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.axis([</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">15</span><span style="color:#ADBAC7;">])   </span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">theta_path_sgd</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">[]</span></span>
<span class="line"><span style="color:#24292E;">m </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">len</span><span style="color:#24292E;">(X_b)</span></span>
<span class="line"><span style="color:#24292E;">np.random.seed(</span><span style="color:#005CC5;">42</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">n_epochs </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">50</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">t0 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">5</span></span>
<span class="line"><span style="color:#24292E;">t1 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">50</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">learning_schedule</span><span style="color:#24292E;">(t):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> t0</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">(t1</span><span style="color:#D73A49;">+</span><span style="color:#24292E;">t)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.random.randn(</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> epoch </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(n_epochs):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> i </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(m):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> epoch </span><span style="color:#D73A49;">&lt;</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">10</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">and</span><span style="color:#24292E;"> i</span><span style="color:#D73A49;">&lt;</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">            y_predict </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> X_new_b.dot(theta)</span></span>
<span class="line"><span style="color:#24292E;">            plt.plot(X_new,y_predict,</span><span style="color:#032F62;">&#39;r-&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        random_index </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.random.randint(m)</span></span>
<span class="line"><span style="color:#24292E;">        xi </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> X_b[random_index:random_index</span><span style="color:#D73A49;">+</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">        yi </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> y[random_index:random_index</span><span style="color:#D73A49;">+</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">        gradients </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> xi.T.dot(xi.dot(theta)</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">yi)</span></span>
<span class="line"><span style="color:#24292E;">        eta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> learning_schedule(epoch</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">m</span><span style="color:#D73A49;">+</span><span style="color:#24292E;">i)</span></span>
<span class="line"><span style="color:#24292E;">        theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> theta</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">eta</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">gradients</span></span>
<span class="line"><span style="color:#24292E;">        theta_path_sgd.append(theta)</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"><span style="color:#24292E;">plt.plot(X,y,</span><span style="color:#032F62;">&#39;b.&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.axis([</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">15</span><span style="color:#24292E;">])   </span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%904.png" alt=""></p><h4 id="minibatch梯度下降" tabindex="-1">MiniBatch梯度下降 <a class="header-anchor" href="#minibatch梯度下降" aria-label="Permalink to &quot;MiniBatch梯度下降&quot;">​</a></h4><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#ADBAC7;">theta_path_mgd</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">[]</span></span>
<span class="line"><span style="color:#ADBAC7;">n_epochs </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">50</span></span>
<span class="line"><span style="color:#ADBAC7;">minibatch </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">16</span></span>
<span class="line"><span style="color:#ADBAC7;">theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.random.randn(</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">t0, t1 </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">200</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">1000</span></span>
<span class="line"><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">learning_schedule</span><span style="color:#ADBAC7;">(t):</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">return</span><span style="color:#ADBAC7;"> t0 </span><span style="color:#F47067;">/</span><span style="color:#ADBAC7;"> (t </span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;"> t1)</span></span>
<span class="line"><span style="color:#ADBAC7;">np.random.seed(</span><span style="color:#6CB6FF;">42</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">t </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0</span></span>
<span class="line"><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> epoch </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(n_epochs):</span></span>
<span class="line"><span style="color:#ADBAC7;">    shuffled_indices </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.random.permutation(m)</span></span>
<span class="line"><span style="color:#ADBAC7;">    X_b_shuffled </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> X_b[shuffled_indices]</span></span>
<span class="line"><span style="color:#ADBAC7;">    y_shuffled </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> y[shuffled_indices]</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> i </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,m,minibatch):</span></span>
<span class="line"><span style="color:#ADBAC7;">        t</span><span style="color:#F47067;">+=</span><span style="color:#6CB6FF;">1</span></span>
<span class="line"><span style="color:#ADBAC7;">        xi </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> X_b_shuffled[i:i</span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;">minibatch]</span></span>
<span class="line"><span style="color:#ADBAC7;">        yi </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> y_shuffled[i:i</span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;">minibatch]</span></span>
<span class="line"><span style="color:#ADBAC7;">        gradients </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">2</span><span style="color:#F47067;">/</span><span style="color:#ADBAC7;">minibatch</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;"> xi.T.dot(xi.dot(theta)</span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;">yi)</span></span>
<span class="line"><span style="color:#ADBAC7;">        eta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> learning_schedule(t)</span></span>
<span class="line"><span style="color:#ADBAC7;">        theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> theta</span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;">eta</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">gradients</span></span>
<span class="line"><span style="color:#ADBAC7;">        theta_path_mgd.append(theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">theta</span></span>
<span class="line"><span style="color:#ADBAC7;">array([[</span><span style="color:#6CB6FF;">4.25490684</span><span style="color:#ADBAC7;">],</span></span>
<span class="line"><span style="color:#ADBAC7;">       [</span><span style="color:#6CB6FF;">2.80388785</span><span style="color:#ADBAC7;">]])</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">theta_path_mgd</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">[]</span></span>
<span class="line"><span style="color:#24292E;">n_epochs </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">50</span></span>
<span class="line"><span style="color:#24292E;">minibatch </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">16</span></span>
<span class="line"><span style="color:#24292E;">theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.random.randn(</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">t0, t1 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">200</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1000</span></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">learning_schedule</span><span style="color:#24292E;">(t):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> t0 </span><span style="color:#D73A49;">/</span><span style="color:#24292E;"> (t </span><span style="color:#D73A49;">+</span><span style="color:#24292E;"> t1)</span></span>
<span class="line"><span style="color:#24292E;">np.random.seed(</span><span style="color:#005CC5;">42</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">t </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> epoch </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(n_epochs):</span></span>
<span class="line"><span style="color:#24292E;">    shuffled_indices </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.random.permutation(m)</span></span>
<span class="line"><span style="color:#24292E;">    X_b_shuffled </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> X_b[shuffled_indices]</span></span>
<span class="line"><span style="color:#24292E;">    y_shuffled </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> y[shuffled_indices]</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> i </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,m,minibatch):</span></span>
<span class="line"><span style="color:#24292E;">        t</span><span style="color:#D73A49;">+=</span><span style="color:#005CC5;">1</span></span>
<span class="line"><span style="color:#24292E;">        xi </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> X_b_shuffled[i:i</span><span style="color:#D73A49;">+</span><span style="color:#24292E;">minibatch]</span></span>
<span class="line"><span style="color:#24292E;">        yi </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> y_shuffled[i:i</span><span style="color:#D73A49;">+</span><span style="color:#24292E;">minibatch]</span></span>
<span class="line"><span style="color:#24292E;">        gradients </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">minibatch</span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> xi.T.dot(xi.dot(theta)</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">yi)</span></span>
<span class="line"><span style="color:#24292E;">        eta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> learning_schedule(t)</span></span>
<span class="line"><span style="color:#24292E;">        theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> theta</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">eta</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">gradients</span></span>
<span class="line"><span style="color:#24292E;">        theta_path_mgd.append(theta)</span></span>
<span class="line"><span style="color:#24292E;">theta</span></span>
<span class="line"><span style="color:#24292E;">array([[</span><span style="color:#005CC5;">4.25490684</span><span style="color:#24292E;">],</span></span>
<span class="line"><span style="color:#24292E;">       [</span><span style="color:#005CC5;">2.80388785</span><span style="color:#24292E;">]])</span></span></code></pre></div><h4 id="_3种策略的对比实验" tabindex="-1">3种策略的对比实验 <a class="header-anchor" href="#_3种策略的对比实验" aria-label="Permalink to &quot;3种策略的对比实验&quot;">​</a></h4><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#768390;"># 实际当中用minibatch比较多，一般情况下选择batch数量应当越大越好。</span></span>
<span class="line"><span style="color:#768390;"># 批量梯度下降</span></span>
<span class="line"><span style="color:#ADBAC7;">theta_path_bgd </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.array(theta_path_bgd)</span></span>
<span class="line"><span style="color:#768390;"># 随机梯度下降</span></span>
<span class="line"><span style="color:#ADBAC7;">theta_path_sgd </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.array(theta_path_sgd)</span></span>
<span class="line"><span style="color:#768390;"># MiniBatch梯度下降</span></span>
<span class="line"><span style="color:#ADBAC7;">theta_path_mgd </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.array(theta_path_mgd)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.figure(</span><span style="color:#F69D50;">figsize</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">(</span><span style="color:#6CB6FF;">12</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">6</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(theta_path_sgd[:,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">],theta_path_sgd[:,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">],</span><span style="color:#96D0FF;">&#39;r-s&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">linewidth</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;SGD&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(theta_path_mgd[:,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">],theta_path_mgd[:,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">],</span><span style="color:#96D0FF;">&#39;g-+&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">linewidth</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;MINIGD&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(theta_path_bgd[:,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">],theta_path_bgd[:,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">],</span><span style="color:#96D0FF;">&#39;b-o&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">linewidth</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;BGD&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.legend(</span><span style="color:#F69D50;">loc</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;upper left&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.axis([</span><span style="color:#6CB6FF;">3.5</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">4.5</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">2.0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">4.0</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># 实际当中用minibatch比较多，一般情况下选择batch数量应当越大越好。</span></span>
<span class="line"><span style="color:#6A737D;"># 批量梯度下降</span></span>
<span class="line"><span style="color:#24292E;">theta_path_bgd </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.array(theta_path_bgd)</span></span>
<span class="line"><span style="color:#6A737D;"># 随机梯度下降</span></span>
<span class="line"><span style="color:#24292E;">theta_path_sgd </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.array(theta_path_sgd)</span></span>
<span class="line"><span style="color:#6A737D;"># MiniBatch梯度下降</span></span>
<span class="line"><span style="color:#24292E;">theta_path_mgd </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.array(theta_path_mgd)</span></span>
<span class="line"><span style="color:#24292E;">plt.figure(</span><span style="color:#E36209;">figsize</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">12</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">6</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(theta_path_sgd[:,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">],theta_path_sgd[:,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">],</span><span style="color:#032F62;">&#39;r-s&#39;</span><span style="color:#24292E;">,</span><span style="color:#E36209;">linewidth</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;SGD&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(theta_path_mgd[:,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">],theta_path_mgd[:,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">],</span><span style="color:#032F62;">&#39;g-+&#39;</span><span style="color:#24292E;">,</span><span style="color:#E36209;">linewidth</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;MINIGD&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(theta_path_bgd[:,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">],theta_path_bgd[:,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">],</span><span style="color:#032F62;">&#39;b-o&#39;</span><span style="color:#24292E;">,</span><span style="color:#E36209;">linewidth</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;BGD&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.legend(</span><span style="color:#E36209;">loc</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;upper left&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.axis([</span><span style="color:#005CC5;">3.5</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">4.5</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">2.0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">4.0</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%905.png" alt=""></p><h3 id="多项式回归" tabindex="-1">多项式回归 <a class="header-anchor" href="#多项式回归" aria-label="Permalink to &quot;多项式回归&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#ADBAC7;">m </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">100</span></span>
<span class="line"><span style="color:#ADBAC7;">X </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">6</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">np.random.rand(m,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">) </span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">3</span></span>
<span class="line"><span style="color:#ADBAC7;">y </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.5</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">X</span><span style="color:#F47067;">**</span><span style="color:#6CB6FF;">2</span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;">X</span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;">np.random.randn(m,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> sklearn.preprocessing </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> PolynomialFeatures</span></span>
<span class="line"><span style="color:#ADBAC7;">poly_features </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> PolynomialFeatures(</span><span style="color:#F69D50;">degree</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">include_bias</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">False</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">X_poly </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> poly_features.fit_transform(X)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">X_poly[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">array([</span><span style="color:#6CB6FF;">2.82919615</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">8.00435083</span><span style="color:#ADBAC7;">]) </span><span style="color:#768390;"># x x^2</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> sklearn.linear_model </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> LinearRegression</span></span>
<span class="line"><span style="color:#ADBAC7;">lin_reg </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression()</span></span>
<span class="line"><span style="color:#ADBAC7;">lin_reg.fit(X_poly,y)</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (lin_reg.coef_)</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (lin_reg.intercept_)</span></span>
<span class="line"><span style="color:#ADBAC7;">[[</span><span style="color:#6CB6FF;">1.10879671</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.53435287</span><span style="color:#ADBAC7;">]]</span></span>
<span class="line"><span style="color:#ADBAC7;">[</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">0.03765461</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">X_new </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.linspace(</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">).reshape(</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">X_new_poly </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> poly_features.transform(X_new)</span></span>
<span class="line"><span style="color:#ADBAC7;">y_new </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> lin_reg.predict(X_new_poly)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(X,y,</span><span style="color:#96D0FF;">&#39;b.&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(X_new,y_new,</span><span style="color:#96D0FF;">&#39;r--&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;prediction&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.axis([</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">5</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.legend()</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">m </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">100</span></span>
<span class="line"><span style="color:#24292E;">X </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">6</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">np.random.rand(m,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">) </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">3</span></span>
<span class="line"><span style="color:#24292E;">y </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.5</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">X</span><span style="color:#D73A49;">**</span><span style="color:#005CC5;">2</span><span style="color:#D73A49;">+</span><span style="color:#24292E;">X</span><span style="color:#D73A49;">+</span><span style="color:#24292E;">np.random.randn(m,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> sklearn.preprocessing </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> PolynomialFeatures</span></span>
<span class="line"><span style="color:#24292E;">poly_features </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> PolynomialFeatures(</span><span style="color:#E36209;">degree</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#E36209;">include_bias</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">X_poly </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> poly_features.fit_transform(X)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">X_poly[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">array([</span><span style="color:#005CC5;">2.82919615</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">8.00435083</span><span style="color:#24292E;">]) </span><span style="color:#6A737D;"># x x^2</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> sklearn.linear_model </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> LinearRegression</span></span>
<span class="line"><span style="color:#24292E;">lin_reg </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression()</span></span>
<span class="line"><span style="color:#24292E;">lin_reg.fit(X_poly,y)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (lin_reg.coef_)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (lin_reg.intercept_)</span></span>
<span class="line"><span style="color:#24292E;">[[</span><span style="color:#005CC5;">1.10879671</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.53435287</span><span style="color:#24292E;">]]</span></span>
<span class="line"><span style="color:#24292E;">[</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">0.03765461</span><span style="color:#24292E;">]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">X_new </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.linspace(</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">).reshape(</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">X_new_poly </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> poly_features.transform(X_new)</span></span>
<span class="line"><span style="color:#24292E;">y_new </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> lin_reg.predict(X_new_poly)</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(X,y,</span><span style="color:#032F62;">&#39;b.&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(X_new,y_new,</span><span style="color:#032F62;">&#39;r--&#39;</span><span style="color:#24292E;">,</span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;prediction&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.axis([</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">5</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#24292E;">plt.legend()</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%906.png" alt=""></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#768390;"># 特征变换的越复杂，得到的结果过拟合风险越高，不建议做的特别复杂。</span></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> sklearn.pipeline </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> Pipeline</span></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> sklearn.preprocessing </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> StandardScaler</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.figure(</span><span style="color:#F69D50;">figsize</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">(</span><span style="color:#6CB6FF;">12</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">6</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> style,width,degree </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> ((</span><span style="color:#96D0FF;">&#39;g-&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">),(</span><span style="color:#96D0FF;">&#39;b--&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">),(</span><span style="color:#96D0FF;">&#39;r-+&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)):</span></span>
<span class="line"><span style="color:#ADBAC7;">    poly_features </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> PolynomialFeatures(</span><span style="color:#F69D50;">degree</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> degree,</span><span style="color:#F69D50;">include_bias</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">False</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    std </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> StandardScaler()</span></span>
<span class="line"><span style="color:#ADBAC7;">    lin_reg </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression()</span></span>
<span class="line"><span style="color:#ADBAC7;">    polynomial_reg </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> Pipeline([(</span><span style="color:#96D0FF;">&#39;poly_features&#39;</span><span style="color:#ADBAC7;">,poly_features),</span></span>
<span class="line"><span style="color:#ADBAC7;">             (</span><span style="color:#96D0FF;">&#39;StandardScaler&#39;</span><span style="color:#ADBAC7;">,std),</span></span>
<span class="line"><span style="color:#ADBAC7;">             (</span><span style="color:#96D0FF;">&#39;lin_reg&#39;</span><span style="color:#ADBAC7;">,lin_reg)])</span></span>
<span class="line"><span style="color:#ADBAC7;">    polynomial_reg.fit(X,y)</span></span>
<span class="line"><span style="color:#ADBAC7;">    y_new_2 </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> polynomial_reg.predict(X_new)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.plot(X_new,y_new_2,style,</span><span style="color:#F69D50;">label</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;degree   &#39;</span><span style="color:#F47067;">+</span><span style="color:#6CB6FF;">str</span><span style="color:#ADBAC7;">(degree),</span><span style="color:#F69D50;">linewidth</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> width)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(X,y,</span><span style="color:#96D0FF;">&#39;b.&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.axis([</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">5</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.legend()</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># 特征变换的越复杂，得到的结果过拟合风险越高，不建议做的特别复杂。</span></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> sklearn.pipeline </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> Pipeline</span></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> sklearn.preprocessing </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> StandardScaler</span></span>
<span class="line"><span style="color:#24292E;">plt.figure(</span><span style="color:#E36209;">figsize</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">12</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">6</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> style,width,degree </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> ((</span><span style="color:#032F62;">&#39;g-&#39;</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">),(</span><span style="color:#032F62;">&#39;b--&#39;</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">),(</span><span style="color:#032F62;">&#39;r-+&#39;</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)):</span></span>
<span class="line"><span style="color:#24292E;">    poly_features </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> PolynomialFeatures(</span><span style="color:#E36209;">degree</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> degree,</span><span style="color:#E36209;">include_bias</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    std </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> StandardScaler()</span></span>
<span class="line"><span style="color:#24292E;">    lin_reg </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression()</span></span>
<span class="line"><span style="color:#24292E;">    polynomial_reg </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> Pipeline([(</span><span style="color:#032F62;">&#39;poly_features&#39;</span><span style="color:#24292E;">,poly_features),</span></span>
<span class="line"><span style="color:#24292E;">             (</span><span style="color:#032F62;">&#39;StandardScaler&#39;</span><span style="color:#24292E;">,std),</span></span>
<span class="line"><span style="color:#24292E;">             (</span><span style="color:#032F62;">&#39;lin_reg&#39;</span><span style="color:#24292E;">,lin_reg)])</span></span>
<span class="line"><span style="color:#24292E;">    polynomial_reg.fit(X,y)</span></span>
<span class="line"><span style="color:#24292E;">    y_new_2 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> polynomial_reg.predict(X_new)</span></span>
<span class="line"><span style="color:#24292E;">    plt.plot(X_new,y_new_2,style,</span><span style="color:#E36209;">label</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;degree   &#39;</span><span style="color:#D73A49;">+</span><span style="color:#005CC5;">str</span><span style="color:#24292E;">(degree),</span><span style="color:#E36209;">linewidth</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> width)</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(X,y,</span><span style="color:#032F62;">&#39;b.&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.axis([</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">5</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#24292E;">plt.legend()</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%907.png" alt=""></p><h3 id="数据样本数量对结果的影响" tabindex="-1">数据样本数量对结果的影响 <a class="header-anchor" href="#数据样本数量对结果的影响" aria-label="Permalink to &quot;数据样本数量对结果的影响&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> sklearn.metrics </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> mean_squared_error</span></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> sklearn.model_selection </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> train_test_split</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">plot_learning_curves</span><span style="color:#ADBAC7;">(model,X,y):</span></span>
<span class="line"><span style="color:#ADBAC7;">    X_train, X_val, y_train, y_val </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> train_test_split(X,y,</span><span style="color:#F69D50;">test_size</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.2</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">random_state</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    train_errors,val_errors </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [],[]</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> m </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">len</span><span style="color:#ADBAC7;">(X_train)):</span></span>
<span class="line"><span style="color:#ADBAC7;">        model.fit(X_train[:m],y_train[:m])</span></span>
<span class="line"><span style="color:#ADBAC7;">        y_train_predict </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> model.predict(X_train[:m])</span></span>
<span class="line"><span style="color:#ADBAC7;">        y_val_predict </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> model.predict(X_val)</span></span>
<span class="line"><span style="color:#ADBAC7;">        train_errors.append(mean_squared_error(y_train[:m],y_train_predict[:m]))</span></span>
<span class="line"><span style="color:#ADBAC7;">        val_errors.append(mean_squared_error(y_val,y_val_predict))</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.plot(np.sqrt(train_errors),</span><span style="color:#96D0FF;">&#39;r-+&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">linewidth</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">label</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;train_error&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.plot(np.sqrt(val_errors),</span><span style="color:#96D0FF;">&#39;b-&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">linewidth</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">label</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;val_error&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.xlabel(</span><span style="color:#96D0FF;">&#39;Trainsing set size&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.ylabel(</span><span style="color:#96D0FF;">&#39;RMSE&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.legend()</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span></span>
<span class="line"><span style="color:#768390;"># 数据量越少，训练集的效果会越好，但是实际测试效果很一般。实际做模型的时候需要参考测试集和验证集的效果。</span></span>
<span class="line"><span style="color:#ADBAC7;">lin_reg </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression()</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_learning_curves(lin_reg,X,y)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.axis([</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">80</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">3.3</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> sklearn.metrics </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> mean_squared_error</span></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> sklearn.model_selection </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> train_test_split</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">plot_learning_curves</span><span style="color:#24292E;">(model,X,y):</span></span>
<span class="line"><span style="color:#24292E;">    X_train, X_val, y_train, y_val </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> train_test_split(X,y,</span><span style="color:#E36209;">test_size</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.2</span><span style="color:#24292E;">,</span><span style="color:#E36209;">random_state</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    train_errors,val_errors </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [],[]</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> m </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">len</span><span style="color:#24292E;">(X_train)):</span></span>
<span class="line"><span style="color:#24292E;">        model.fit(X_train[:m],y_train[:m])</span></span>
<span class="line"><span style="color:#24292E;">        y_train_predict </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> model.predict(X_train[:m])</span></span>
<span class="line"><span style="color:#24292E;">        y_val_predict </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> model.predict(X_val)</span></span>
<span class="line"><span style="color:#24292E;">        train_errors.append(mean_squared_error(y_train[:m],y_train_predict[:m]))</span></span>
<span class="line"><span style="color:#24292E;">        val_errors.append(mean_squared_error(y_val,y_val_predict))</span></span>
<span class="line"><span style="color:#24292E;">    plt.plot(np.sqrt(train_errors),</span><span style="color:#032F62;">&#39;r-+&#39;</span><span style="color:#24292E;">,</span><span style="color:#E36209;">linewidth</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#E36209;">label</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;train_error&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    plt.plot(np.sqrt(val_errors),</span><span style="color:#032F62;">&#39;b-&#39;</span><span style="color:#24292E;">,</span><span style="color:#E36209;">linewidth</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#E36209;">label</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;val_error&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    plt.xlabel(</span><span style="color:#032F62;">&#39;Trainsing set size&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    plt.ylabel(</span><span style="color:#032F62;">&#39;RMSE&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    plt.legend()</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#6A737D;"># 数据量越少，训练集的效果会越好，但是实际测试效果很一般。实际做模型的时候需要参考测试集和验证集的效果。</span></span>
<span class="line"><span style="color:#24292E;">lin_reg </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression()</span></span>
<span class="line"><span style="color:#24292E;">plot_learning_curves(lin_reg,X,y)</span></span>
<span class="line"><span style="color:#24292E;">plt.axis([</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">80</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">3.3</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%908.png" alt=""></p><h3 id="多项式回归的过拟合风险" tabindex="-1">多项式回归的过拟合风险 <a class="header-anchor" href="#多项式回归的过拟合风险" aria-label="Permalink to &quot;多项式回归的过拟合风险&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#768390;"># 越复杂 越拟合</span></span>
<span class="line"><span style="color:#ADBAC7;">polynomial_reg </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> Pipeline([(</span><span style="color:#96D0FF;">&#39;poly_features&#39;</span><span style="color:#ADBAC7;">,PolynomialFeatures(</span><span style="color:#F69D50;">degree</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">25</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">include_bias</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">False</span><span style="color:#ADBAC7;">)),</span></span>
<span class="line"><span style="color:#ADBAC7;">             (</span><span style="color:#96D0FF;">&#39;lin_reg&#39;</span><span style="color:#ADBAC7;">,LinearRegression())])</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_learning_curves(polynomial_reg,X,y)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.axis([</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">80</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">5</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># 越复杂 越拟合</span></span>
<span class="line"><span style="color:#24292E;">polynomial_reg </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> Pipeline([(</span><span style="color:#032F62;">&#39;poly_features&#39;</span><span style="color:#24292E;">,PolynomialFeatures(</span><span style="color:#E36209;">degree</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">25</span><span style="color:#24292E;">,</span><span style="color:#E36209;">include_bias</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)),</span></span>
<span class="line"><span style="color:#24292E;">             (</span><span style="color:#032F62;">&#39;lin_reg&#39;</span><span style="color:#24292E;">,LinearRegression())])</span></span>
<span class="line"><span style="color:#24292E;">plot_learning_curves(polynomial_reg,X,y)</span></span>
<span class="line"><span style="color:#24292E;">plt.axis([</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">80</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">5</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%909.png" alt=""></p><h3 id="正则化" tabindex="-1">正则化 <a class="header-anchor" href="#正则化" aria-label="Permalink to &quot;正则化&quot;">​</a></h3><p>对权重参数进行惩罚，让权重参数尽可能平滑一些，有两种不同的方法来进行正则化惩罚:</p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%9010.png" alt=""></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> sklearn.linear_model </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> Ridge</span></span>
<span class="line"><span style="color:#ADBAC7;">np.random.seed(</span><span style="color:#6CB6FF;">42</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">m </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">20</span></span>
<span class="line"><span style="color:#ADBAC7;">X </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">3</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">np.random.rand(m,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">y </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.5</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;"> X </span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;">np.random.randn(m,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span><span style="color:#F47067;">/</span><span style="color:#6CB6FF;">1.5</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">+</span><span style="color:#6CB6FF;">1</span></span>
<span class="line"><span style="color:#ADBAC7;">X_new </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.linspace(</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">).reshape(</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">plot_model</span><span style="color:#ADBAC7;">(model_calss,polynomial,alphas,</span><span style="color:#F47067;">**</span><span style="color:#ADBAC7;">model_kargs):</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> alpha,style </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">zip</span><span style="color:#ADBAC7;">(alphas,(</span><span style="color:#96D0FF;">&#39;b-&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#96D0FF;">&#39;g--&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#96D0FF;">&#39;r:&#39;</span><span style="color:#ADBAC7;">)):</span></span>
<span class="line"><span style="color:#ADBAC7;">        model </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> model_calss(alpha,</span><span style="color:#F47067;">**</span><span style="color:#ADBAC7;">model_kargs)</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">if</span><span style="color:#ADBAC7;"> polynomial:</span></span>
<span class="line"><span style="color:#ADBAC7;">            model </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> Pipeline([(</span><span style="color:#96D0FF;">&#39;poly_features&#39;</span><span style="color:#ADBAC7;">,PolynomialFeatures(</span><span style="color:#F69D50;">degree</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">include_bias</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">False</span><span style="color:#ADBAC7;">)),</span></span>
<span class="line"><span style="color:#ADBAC7;">             (</span><span style="color:#96D0FF;">&#39;StandardScaler&#39;</span><span style="color:#ADBAC7;">,StandardScaler()),</span></span>
<span class="line"><span style="color:#ADBAC7;">             (</span><span style="color:#96D0FF;">&#39;lin_reg&#39;</span><span style="color:#ADBAC7;">,model)])</span></span>
<span class="line"><span style="color:#ADBAC7;">        model.fit(X,y)</span></span>
<span class="line"><span style="color:#ADBAC7;">        y_new_regul </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> model.predict(X_new)</span></span>
<span class="line"><span style="color:#ADBAC7;">        lw </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">if</span><span style="color:#ADBAC7;"> alpha </span><span style="color:#F47067;">&gt;</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">else</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">1</span></span>
<span class="line"><span style="color:#ADBAC7;">        plt.plot(X_new,y_new_regul,style,</span><span style="color:#F69D50;">linewidth</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> lw,</span><span style="color:#F69D50;">label</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;alpha = </span><span style="color:#F47067;">{}</span><span style="color:#96D0FF;">&#39;</span><span style="color:#ADBAC7;">.format(alpha))</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.plot(X,y,</span><span style="color:#96D0FF;">&#39;b.&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">linewidth</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.legend()</span></span>
<span class="line"><span style="color:#ADBAC7;"> </span></span>
<span class="line"><span style="color:#ADBAC7;">plt.figure(</span><span style="color:#F69D50;">figsize</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">(</span><span style="color:#6CB6FF;">14</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">6</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.subplot(</span><span style="color:#6CB6FF;">121</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_model(Ridge,</span><span style="color:#F69D50;">polynomial</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">False</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">alphas</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> (</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.subplot(</span><span style="color:#6CB6FF;">122</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_model(Ridge,</span><span style="color:#F69D50;">polynomial</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">True</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">alphas</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> (</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">10</span><span style="color:#F47067;">**-</span><span style="color:#6CB6FF;">5</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> sklearn.linear_model </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> Ridge</span></span>
<span class="line"><span style="color:#24292E;">np.random.seed(</span><span style="color:#005CC5;">42</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">m </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">20</span></span>
<span class="line"><span style="color:#24292E;">X </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">3</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">np.random.rand(m,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">y </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.5</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> X </span><span style="color:#D73A49;">+</span><span style="color:#24292E;">np.random.randn(m,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span><span style="color:#D73A49;">/</span><span style="color:#005CC5;">1.5</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">+</span><span style="color:#005CC5;">1</span></span>
<span class="line"><span style="color:#24292E;">X_new </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.linspace(</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">).reshape(</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">plot_model</span><span style="color:#24292E;">(model_calss,polynomial,alphas,</span><span style="color:#D73A49;">**</span><span style="color:#24292E;">model_kargs):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> alpha,style </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">zip</span><span style="color:#24292E;">(alphas,(</span><span style="color:#032F62;">&#39;b-&#39;</span><span style="color:#24292E;">,</span><span style="color:#032F62;">&#39;g--&#39;</span><span style="color:#24292E;">,</span><span style="color:#032F62;">&#39;r:&#39;</span><span style="color:#24292E;">)):</span></span>
<span class="line"><span style="color:#24292E;">        model </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> model_calss(alpha,</span><span style="color:#D73A49;">**</span><span style="color:#24292E;">model_kargs)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> polynomial:</span></span>
<span class="line"><span style="color:#24292E;">            model </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> Pipeline([(</span><span style="color:#032F62;">&#39;poly_features&#39;</span><span style="color:#24292E;">,PolynomialFeatures(</span><span style="color:#E36209;">degree</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">,</span><span style="color:#E36209;">include_bias</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)),</span></span>
<span class="line"><span style="color:#24292E;">             (</span><span style="color:#032F62;">&#39;StandardScaler&#39;</span><span style="color:#24292E;">,StandardScaler()),</span></span>
<span class="line"><span style="color:#24292E;">             (</span><span style="color:#032F62;">&#39;lin_reg&#39;</span><span style="color:#24292E;">,model)])</span></span>
<span class="line"><span style="color:#24292E;">        model.fit(X,y)</span></span>
<span class="line"><span style="color:#24292E;">        y_new_regul </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> model.predict(X_new)</span></span>
<span class="line"><span style="color:#24292E;">        lw </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> alpha </span><span style="color:#D73A49;">&gt;</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">else</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1</span></span>
<span class="line"><span style="color:#24292E;">        plt.plot(X_new,y_new_regul,style,</span><span style="color:#E36209;">linewidth</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> lw,</span><span style="color:#E36209;">label</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;alpha = </span><span style="color:#005CC5;">{}</span><span style="color:#032F62;">&#39;</span><span style="color:#24292E;">.format(alpha))</span></span>
<span class="line"><span style="color:#24292E;">    plt.plot(X,y,</span><span style="color:#032F62;">&#39;b.&#39;</span><span style="color:#24292E;">,</span><span style="color:#E36209;">linewidth</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    plt.legend()</span></span>
<span class="line"><span style="color:#24292E;"> </span></span>
<span class="line"><span style="color:#24292E;">plt.figure(</span><span style="color:#E36209;">figsize</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">14</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">6</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.subplot(</span><span style="color:#005CC5;">121</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plot_model(Ridge,</span><span style="color:#E36209;">polynomial</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">,</span><span style="color:#E36209;">alphas</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> (</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.subplot(</span><span style="color:#005CC5;">122</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plot_model(Ridge,</span><span style="color:#E36209;">polynomial</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">,</span><span style="color:#E36209;">alphas</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> (</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">10</span><span style="color:#D73A49;">**-</span><span style="color:#005CC5;">5</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%9011.png" alt=""></p><p>惩罚力度越大，alpha值越大的时候，得到的决策方程越平稳。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> sklearn.linear_model </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> Lasso</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.figure(</span><span style="color:#F69D50;">figsize</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">(</span><span style="color:#6CB6FF;">14</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">6</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.subplot(</span><span style="color:#6CB6FF;">121</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_model(Lasso,</span><span style="color:#F69D50;">polynomial</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">False</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">alphas</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> (</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0.1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.subplot(</span><span style="color:#6CB6FF;">122</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_model(Lasso,</span><span style="color:#F69D50;">polynomial</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">True</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">alphas</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> (</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">10</span><span style="color:#F47067;">**-</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> sklearn.linear_model </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> Lasso</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.figure(</span><span style="color:#E36209;">figsize</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">14</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">6</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.subplot(</span><span style="color:#005CC5;">121</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plot_model(Lasso,</span><span style="color:#E36209;">polynomial</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">,</span><span style="color:#E36209;">alphas</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> (</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0.1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.subplot(</span><span style="color:#005CC5;">122</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plot_model(Lasso,</span><span style="color:#E36209;">polynomial</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">,</span><span style="color:#E36209;">alphas</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> (</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">10</span><span style="color:#D73A49;">**-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%9012.png" alt=""></p>`,46);function h(s,m,u,g,f,b){const o=t,e=D("ClientOnly");return l(),r("div",null,[d,y(e,null,{default:A(()=>{var n,a;return[(((n=s.$frontmatter)==null?void 0:n.aside)??!0)&&(((a=s.$frontmatter)==null?void 0:a.showArticleMetadata)??!0)?(l(),F(o,{key:0,article:s.$frontmatter},null,8,["article"])):B("",!0)]}),_:1}),_])}const k=c(E,[["render",h]]);export{q as __pageData,k as default};
