import{_ as c}from"./chunks/ArticleMetadata.59a467b2.js";import{_ as t,v as p,b as r,t as y,O as i,F as l,L as C,R as B,M as A,C as d,B as F}from"./chunks/framework.5cbdba25.js";import"./chunks/md5.02486a14.js";const q=JSON.parse('{"title":"相关分析","description":"","frontmatter":{"title":"相关分析","author":"阿源","date":"2023/06/13 12:00","categories":["机器学习理论基础"],"tags":["机器学习","数学基础"]},"headers":[],"relativePath":"courses/tangyudi/01-数学基础篇/13-相关分析.md","filePath":"courses/tangyudi/01-数学基础篇/13-相关分析.md","lastUpdated":1695348718000}'),h={name:"courses/tangyudi/01-数学基础篇/13-相关分析.md"},E=l("h1",{id:"相关分析",tabindex:"-1"},[C("相关分析 "),l("a",{class:"header-anchor",href:"#相关分析","aria-label":'Permalink to "相关分析"'},"​")],-1),D=B(`<h2 id="_13-相关分析" tabindex="-1">13. 相关分析 <a class="header-anchor" href="#_13-相关分析" aria-label="Permalink to &quot;13. 相关分析&quot;">​</a></h2><h3 id="_1-概述" tabindex="-1">1. 概述 <a class="header-anchor" href="#_1-概述" aria-label="Permalink to &quot;1. 概述&quot;">​</a></h3><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">相关分析：</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">衡量事物之间或称变量之间线性相关程度的强弱，并用适当的统计指标表示出来的过程。</span></span>
<span class="line"><span style="color:#adbac7;">比如，家庭收入和支出、一个人所受教育程度与其收入、子女身高和父母身高等</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">相关分析：</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">衡量事物之间或称变量之间线性相关程度的强弱，并用适当的统计指标表示出来的过程。</span></span>
<span class="line"><span style="color:#24292e;">比如，家庭收入和支出、一个人所受教育程度与其收入、子女身高和父母身高等</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">相关系数：</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">- 衡量变量之间相关程度的一个量值</span></span>
<span class="line"><span style="color:#adbac7;">- 相关系数r的数值范围是在一1到十1之间</span></span>
<span class="line"><span style="color:#adbac7;">- 相关系数r的正负号表示变化方向。“+”号表示变化方向一致，即正相关；“-”号表示变化方向相反，即负相关</span></span>
<span class="line"><span style="color:#adbac7;">- r的绝对值表示变量之间的密切程度(即强度)。绝对值越接近1，表示两个变量之间关系越密切；越接近0，表示两个变量之间关系越不密切</span></span>
<span class="line"><span style="color:#adbac7;">- 相关系数的值，仅仅是一个比值。它不是由相等单位度量而来(即不等距)，也不是百分比，因此，不能直接作加、减、乘、除运算</span></span>
<span class="line"><span style="color:#adbac7;">- 相关系数只能描述两个变量之间的变化方向及密切程度，并不能揭示两者之间的内在本质联系，即存在相关的两个变量，不一定存在因果关系</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">相关系数：</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">- 衡量变量之间相关程度的一个量值</span></span>
<span class="line"><span style="color:#24292e;">- 相关系数r的数值范围是在一1到十1之间</span></span>
<span class="line"><span style="color:#24292e;">- 相关系数r的正负号表示变化方向。“+”号表示变化方向一致，即正相关；“-”号表示变化方向相反，即负相关</span></span>
<span class="line"><span style="color:#24292e;">- r的绝对值表示变量之间的密切程度(即强度)。绝对值越接近1，表示两个变量之间关系越密切；越接近0，表示两个变量之间关系越不密切</span></span>
<span class="line"><span style="color:#24292e;">- 相关系数的值，仅仅是一个比值。它不是由相等单位度量而来(即不等距)，也不是百分比，因此，不能直接作加、减、乘、除运算</span></span>
<span class="line"><span style="color:#24292e;">- 相关系数只能描述两个变量之间的变化方向及密切程度，并不能揭示两者之间的内在本质联系，即存在相关的两个变量，不一定存在因果关系</span></span></code></pre></div><h3 id="_2-皮尔森相关系数" tabindex="-1">2. 皮尔森相关系数 <a class="header-anchor" href="#_2-皮尔森相关系数" aria-label="Permalink to &quot;2. 皮尔森相关系数&quot;">​</a></h3><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">连续变量的相关分析</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">连续变量即数据变量，它的取值之间可以比较大小，可以用加减法计算出差异的大小。如“年龄”、“收入”、“成绩”等变量。</span></span>
<span class="line"><span style="color:#adbac7;">当两个变量都是正态连续变量，而且两者之间呈线性关系时，通常用Pearson相关系数来衡量</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">连续变量的相关分析</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">连续变量即数据变量，它的取值之间可以比较大小，可以用加减法计算出差异的大小。如“年龄”、“收入”、“成绩”等变量。</span></span>
<span class="line"><span style="color:#24292e;">当两个变量都是正态连续变量，而且两者之间呈线性关系时，通常用Pearson相关系数来衡量</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B01.png" alt=""></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">虽然协方差能反映两个随机变量的相关程度（协方差大于0的时候表示两者正相关，小于0的时候表示两者负相关），但是协方差值的大小并不能很好地度量两个随机变量的关联程度。</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">在二维空间中分布着一些数据，我们想知道数据点坐标X轴和Y轴的相关程度，如果X与Y的相关程度较小但是数据分布的比较离散，这样会导致求出的协方差值较大，用这个值来度量相关程度是不合理的</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">为了更好的度量两个随机变量的相关程度，引入了Pearson相关系数，其在协方差的基础上除以了两个随机变量的标准差</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">虽然协方差能反映两个随机变量的相关程度（协方差大于0的时候表示两者正相关，小于0的时候表示两者负相关），但是协方差值的大小并不能很好地度量两个随机变量的关联程度。</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">在二维空间中分布着一些数据，我们想知道数据点坐标X轴和Y轴的相关程度，如果X与Y的相关程度较小但是数据分布的比较离散，这样会导致求出的协方差值较大，用这个值来度量相关程度是不合理的</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">为了更好的度量两个随机变量的相关程度，引入了Pearson相关系数，其在协方差的基础上除以了两个随机变量的标准差</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B02.png" alt=""></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">pearson是一个介于-1和1之间的值，当两个变量的线性关系增强时，相关系数趋于1或-1；当一个变量增大，另一个变量也增大时，表明它们之间是正相关的，相关系数大于0；如果一个变量增大，另一个变量却减小，表明它们之间是负相关的，相关系数小于0；如果相关系数等于0，表明它们之间不存在线性相关关系。</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">pearson是一个介于-1和1之间的值，当两个变量的线性关系增强时，相关系数趋于1或-1；当一个变量增大，另一个变量也增大时，表明它们之间是正相关的，相关系数大于0；如果一个变量增大，另一个变量却减小，表明它们之间是负相关的，相关系数小于0；如果相关系数等于0，表明它们之间不存在线性相关关系。</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#768390;"># np.corrcoef(a)可计算行与行之间的相关系数，np.corrcoef(a,rowvar=0)用于计算各列之间的相关系数</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> numpy </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> np</span></span>
<span class="line"><span style="color:#ADBAC7;">tang </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.array([[</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">8</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">9</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">7</span><span style="color:#ADBAC7;">],  </span></span>
<span class="line"><span style="color:#ADBAC7;">       [</span><span style="color:#6CB6FF;">4</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">5</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">4</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">],  </span></span>
<span class="line"><span style="color:#ADBAC7;">       [</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">]])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">np.corrcoef(tang)</span></span>
<span class="line"><span style="color:#ADBAC7;">array([[ </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">.        ,  </span><span style="color:#6CB6FF;">0.64168895</span><span style="color:#ADBAC7;">,  </span><span style="color:#6CB6FF;">0.84016805</span><span style="color:#ADBAC7;">],</span></span>
<span class="line"><span style="color:#ADBAC7;">       [ </span><span style="color:#6CB6FF;">0.64168895</span><span style="color:#ADBAC7;">,  </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">.        ,  </span><span style="color:#6CB6FF;">0.76376262</span><span style="color:#ADBAC7;">],</span></span>
<span class="line"><span style="color:#ADBAC7;">       [ </span><span style="color:#6CB6FF;">0.84016805</span><span style="color:#ADBAC7;">,  </span><span style="color:#6CB6FF;">0.76376262</span><span style="color:#ADBAC7;">,  </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">.        ]])</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">np.corrcoef(tang,</span><span style="color:#F69D50;">rowvar</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">) </span></span>
<span class="line"><span style="color:#ADBAC7;">array([[ </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">.        ,  </span><span style="color:#6CB6FF;">0.98898224</span><span style="color:#ADBAC7;">,  </span><span style="color:#6CB6FF;">0.9526832</span><span style="color:#ADBAC7;"> ,  </span><span style="color:#6CB6FF;">0.9939441</span><span style="color:#ADBAC7;"> ,  </span><span style="color:#6CB6FF;">0.97986371</span><span style="color:#ADBAC7;">],</span></span>
<span class="line"><span style="color:#ADBAC7;">       [ </span><span style="color:#6CB6FF;">0.98898224</span><span style="color:#ADBAC7;">,  </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">.        ,  </span><span style="color:#6CB6FF;">0.98718399</span><span style="color:#ADBAC7;">,  </span><span style="color:#6CB6FF;">0.99926008</span><span style="color:#ADBAC7;">,  </span><span style="color:#6CB6FF;">0.99862543</span><span style="color:#ADBAC7;">],</span></span>
<span class="line"><span style="color:#ADBAC7;">       [ </span><span style="color:#6CB6FF;">0.9526832</span><span style="color:#ADBAC7;"> ,  </span><span style="color:#6CB6FF;">0.98718399</span><span style="color:#ADBAC7;">,  </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">.        ,  </span><span style="color:#6CB6FF;">0.98031562</span><span style="color:#ADBAC7;">,  </span><span style="color:#6CB6FF;">0.99419163</span><span style="color:#ADBAC7;">],</span></span>
<span class="line"><span style="color:#ADBAC7;">       [ </span><span style="color:#6CB6FF;">0.9939441</span><span style="color:#ADBAC7;"> ,  </span><span style="color:#6CB6FF;">0.99926008</span><span style="color:#ADBAC7;">,  </span><span style="color:#6CB6FF;">0.98031562</span><span style="color:#ADBAC7;">,  </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">.        ,  </span><span style="color:#6CB6FF;">0.99587059</span><span style="color:#ADBAC7;">],</span></span>
<span class="line"><span style="color:#ADBAC7;">       [ </span><span style="color:#6CB6FF;">0.97986371</span><span style="color:#ADBAC7;">,  </span><span style="color:#6CB6FF;">0.99862543</span><span style="color:#ADBAC7;">,  </span><span style="color:#6CB6FF;">0.99419163</span><span style="color:#ADBAC7;">,  </span><span style="color:#6CB6FF;">0.99587059</span><span style="color:#ADBAC7;">,  </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">.        ]])</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># np.corrcoef(a)可计算行与行之间的相关系数，np.corrcoef(a,rowvar=0)用于计算各列之间的相关系数</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> numpy </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> np</span></span>
<span class="line"><span style="color:#24292E;">tang </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.array([[</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">10</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">8</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">9</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">7</span><span style="color:#24292E;">],  </span></span>
<span class="line"><span style="color:#24292E;">       [</span><span style="color:#005CC5;">4</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">5</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">3</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">3</span><span style="color:#24292E;">],  </span></span>
<span class="line"><span style="color:#24292E;">       [</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">3</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">]])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">np.corrcoef(tang)</span></span>
<span class="line"><span style="color:#24292E;">array([[ </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">.        ,  </span><span style="color:#005CC5;">0.64168895</span><span style="color:#24292E;">,  </span><span style="color:#005CC5;">0.84016805</span><span style="color:#24292E;">],</span></span>
<span class="line"><span style="color:#24292E;">       [ </span><span style="color:#005CC5;">0.64168895</span><span style="color:#24292E;">,  </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">.        ,  </span><span style="color:#005CC5;">0.76376262</span><span style="color:#24292E;">],</span></span>
<span class="line"><span style="color:#24292E;">       [ </span><span style="color:#005CC5;">0.84016805</span><span style="color:#24292E;">,  </span><span style="color:#005CC5;">0.76376262</span><span style="color:#24292E;">,  </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">.        ]])</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">np.corrcoef(tang,</span><span style="color:#E36209;">rowvar</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">) </span></span>
<span class="line"><span style="color:#24292E;">array([[ </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">.        ,  </span><span style="color:#005CC5;">0.98898224</span><span style="color:#24292E;">,  </span><span style="color:#005CC5;">0.9526832</span><span style="color:#24292E;"> ,  </span><span style="color:#005CC5;">0.9939441</span><span style="color:#24292E;"> ,  </span><span style="color:#005CC5;">0.97986371</span><span style="color:#24292E;">],</span></span>
<span class="line"><span style="color:#24292E;">       [ </span><span style="color:#005CC5;">0.98898224</span><span style="color:#24292E;">,  </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">.        ,  </span><span style="color:#005CC5;">0.98718399</span><span style="color:#24292E;">,  </span><span style="color:#005CC5;">0.99926008</span><span style="color:#24292E;">,  </span><span style="color:#005CC5;">0.99862543</span><span style="color:#24292E;">],</span></span>
<span class="line"><span style="color:#24292E;">       [ </span><span style="color:#005CC5;">0.9526832</span><span style="color:#24292E;"> ,  </span><span style="color:#005CC5;">0.98718399</span><span style="color:#24292E;">,  </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">.        ,  </span><span style="color:#005CC5;">0.98031562</span><span style="color:#24292E;">,  </span><span style="color:#005CC5;">0.99419163</span><span style="color:#24292E;">],</span></span>
<span class="line"><span style="color:#24292E;">       [ </span><span style="color:#005CC5;">0.9939441</span><span style="color:#24292E;"> ,  </span><span style="color:#005CC5;">0.99926008</span><span style="color:#24292E;">,  </span><span style="color:#005CC5;">0.98031562</span><span style="color:#24292E;">,  </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">.        ,  </span><span style="color:#005CC5;">0.99587059</span><span style="color:#24292E;">],</span></span>
<span class="line"><span style="color:#24292E;">       [ </span><span style="color:#005CC5;">0.97986371</span><span style="color:#24292E;">,  </span><span style="color:#005CC5;">0.99862543</span><span style="color:#24292E;">,  </span><span style="color:#005CC5;">0.99419163</span><span style="color:#24292E;">,  </span><span style="color:#005CC5;">0.99587059</span><span style="color:#24292E;">,  </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">.        ]])</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B03.png" alt=""></p><h3 id="_3-计算与检验" tabindex="-1">3. 计算与检验 <a class="header-anchor" href="#_3-计算与检验" aria-label="Permalink to &quot;3. 计算与检验&quot;">​</a></h3><p>相关系数的假设性检验</p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B04.png" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B05.png" alt=""></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> numpy </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> np</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> scipy.stats </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> stats  </span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> scipy</span></span>
<span class="line"><span style="color:#768390;">#https://docs.scipy.org/doc/scipy-0.19.1/reference/stats.html#module-scipy.stats</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [</span><span style="color:#6CB6FF;">10.35</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">6.24</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">3.18</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">8.46</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">3.21</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">7.65</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">4.32</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">8.66</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">9.12</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">10.31</span><span style="color:#ADBAC7;">]  </span></span>
<span class="line"><span style="color:#ADBAC7;">y </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [</span><span style="color:#6CB6FF;">5.1</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">3.15</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">1.67</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">4.33</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">1.76</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">4.11</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">2.11</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">4.88</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">4.99</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">5.12</span><span style="color:#ADBAC7;">]  </span></span>
<span class="line"><span style="color:#ADBAC7;">correlation,pvalue </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> stats.stats.pearsonr(x,y) </span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (</span><span style="color:#96D0FF;">&#39;correlation&#39;</span><span style="color:#ADBAC7;">,correlation)</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (</span><span style="color:#96D0FF;">&#39;pvalue&#39;</span><span style="color:#ADBAC7;">,pvalue)</span></span>
<span class="line"><span style="color:#ADBAC7;">correlation </span><span style="color:#6CB6FF;">0.989176319869</span></span>
<span class="line"><span style="color:#ADBAC7;">pvalue </span><span style="color:#6CB6FF;">5.92687594648e-08</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> matplotlib.pyplot </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> plt</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.scatter(x,y)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> numpy </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> np</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> scipy.stats </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> stats  </span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> scipy</span></span>
<span class="line"><span style="color:#6A737D;">#https://docs.scipy.org/doc/scipy-0.19.1/reference/stats.html#module-scipy.stats</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [</span><span style="color:#005CC5;">10.35</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">6.24</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">3.18</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">8.46</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">3.21</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">7.65</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4.32</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">8.66</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">9.12</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">10.31</span><span style="color:#24292E;">]  </span></span>
<span class="line"><span style="color:#24292E;">y </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [</span><span style="color:#005CC5;">5.1</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">3.15</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1.67</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4.33</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1.76</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4.11</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">2.11</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4.88</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4.99</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">5.12</span><span style="color:#24292E;">]  </span></span>
<span class="line"><span style="color:#24292E;">correlation,pvalue </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> stats.stats.pearsonr(x,y) </span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (</span><span style="color:#032F62;">&#39;correlation&#39;</span><span style="color:#24292E;">,correlation)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (</span><span style="color:#032F62;">&#39;pvalue&#39;</span><span style="color:#24292E;">,pvalue)</span></span>
<span class="line"><span style="color:#24292E;">correlation </span><span style="color:#005CC5;">0.989176319869</span></span>
<span class="line"><span style="color:#24292E;">pvalue </span><span style="color:#005CC5;">5.92687594648e-08</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> matplotlib.pyplot </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> plt</span></span>
<span class="line"><span style="color:#24292E;">plt.scatter(x,y)</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><h3 id="_4-斯皮尔曼等级相关" tabindex="-1">4. 斯皮尔曼等级相关 <a class="header-anchor" href="#_4-斯皮尔曼等级相关" aria-label="Permalink to &quot;4. 斯皮尔曼等级相关&quot;">​</a></h3><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">等级变量的相关分析</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">当测量得到的数据不是等距或等比数据，而是具有等级顺序的数据；或者得到的数据是等距或等比数据，但其所来自的总体分布不是正态的，不满足求皮尔森相关系数（积差相关）的要求。这时就要运用等级相关系数。</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">等级变量的相关分析</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">当测量得到的数据不是等距或等比数据，而是具有等级顺序的数据；或者得到的数据是等距或等比数据，但其所来自的总体分布不是正态的，不满足求皮尔森相关系数（积差相关）的要求。这时就要运用等级相关系数。</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B06.png" alt=""></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">计算得出，他们的皮尔森相关系数r=1，P-vlaue≈0，从以上可以直观看出，如果两个基因的表达量呈线性关系，则具有显著的皮尔森相关性。</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">以上是两个基因呈线性关系的结果。如果两者呈非线性关系，例如幂函数关系（曲线关系），那又如何呢？ 我们再试试。</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">两个基因A、D，他们的关系是D=A^10，在8个样本中的表达量值如下：</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">计算得出，他们的皮尔森相关系数r=1，P-vlaue≈0，从以上可以直观看出，如果两个基因的表达量呈线性关系，则具有显著的皮尔森相关性。</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">以上是两个基因呈线性关系的结果。如果两者呈非线性关系，例如幂函数关系（曲线关系），那又如何呢？ 我们再试试。</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">两个基因A、D，他们的关系是D=A^10，在8个样本中的表达量值如下：</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B07.png" alt=""></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> numpy </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> np</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> scipy.stats </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> stats  </span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> scipy</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [</span><span style="color:#6CB6FF;">0.6</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0.7</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">2.1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">2.9</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">3.2</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">5.5</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">6.7</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">y </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.power(x,</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">correlation,pvalue </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> stats.stats.pearsonr(x,y) </span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (</span><span style="color:#96D0FF;">&#39;correlation&#39;</span><span style="color:#ADBAC7;">,correlation)</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (</span><span style="color:#96D0FF;">&#39;pvalue&#39;</span><span style="color:#ADBAC7;">,pvalue)</span></span>
<span class="line"><span style="color:#ADBAC7;">correlation </span><span style="color:#6CB6FF;">0.765928796314</span></span>
<span class="line"><span style="color:#ADBAC7;">pvalue </span><span style="color:#6CB6FF;">0.0266964972088</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> numpy </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> np</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> scipy.stats </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> stats  </span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> scipy</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [</span><span style="color:#005CC5;">0.6</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0.7</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">2.1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">2.9</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">3.2</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">5.5</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">6.7</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">y </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.power(x,</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">correlation,pvalue </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> stats.stats.pearsonr(x,y) </span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (</span><span style="color:#032F62;">&#39;correlation&#39;</span><span style="color:#24292E;">,correlation)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (</span><span style="color:#032F62;">&#39;pvalue&#39;</span><span style="color:#24292E;">,pvalue)</span></span>
<span class="line"><span style="color:#24292E;">correlation </span><span style="color:#005CC5;">0.765928796314</span></span>
<span class="line"><span style="color:#24292E;">pvalue </span><span style="color:#005CC5;">0.0266964972088</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">可以看到，基因A、D相关系数，无论数值还是显著性都下降了。皮尔森相关系数是一种线性相关系数，因此如果两个变量呈线性关系的时候，具有最大的显著性。对于非线性关系（例如A、D的幂函数关系），则其对相关性的检测功效会下降。</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">这时我们可以考虑另外一个相关系数计算方法：斯皮尔曼等级相关。</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">可以看到，基因A、D相关系数，无论数值还是显著性都下降了。皮尔森相关系数是一种线性相关系数，因此如果两个变量呈线性关系的时候，具有最大的显著性。对于非线性关系（例如A、D的幂函数关系），则其对相关性的检测功效会下降。</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">这时我们可以考虑另外一个相关系数计算方法：斯皮尔曼等级相关。</span></span></code></pre></div><h4 id="概述" tabindex="-1">概述 <a class="header-anchor" href="#概述" aria-label="Permalink to &quot;概述&quot;">​</a></h4><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">当两个变量值以等级次序排列或以等级次序表示时，两个相应总体并不一定呈正态分布，样本容量也不一定大于30，表示这两变量之间的相关，称为Spearman等级相关。</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">简单点说，就是无论两个变量的数据如何变化，符合什么样的分布，我们只关心每个数值在变量内的排列顺序。如果两个变量的对应值，在各组内的排序顺位是相同或类似的，则具有显著的相关性。</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">当两个变量值以等级次序排列或以等级次序表示时，两个相应总体并不一定呈正态分布，样本容量也不一定大于30，表示这两变量之间的相关，称为Spearman等级相关。</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">简单点说，就是无论两个变量的数据如何变化，符合什么样的分布，我们只关心每个数值在变量内的排列顺序。如果两个变量的对应值，在各组内的排序顺位是相同或类似的，则具有显著的相关性。</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B08.png" alt=""></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">利用斯皮尔曼等级相关计算A、D基因表达量的相关性，结果是：r=1，p-value = 4.96e-05</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">这里斯皮尔曼等级相关的显著性显然高于皮尔森相关。这是因为虽然两个基因的表达量是非线性关系，但两个基因表达量在所有样本中的排列顺序是完全相同的，因为具有极显著的斯皮尔曼等级相关性。</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">利用斯皮尔曼等级相关计算A、D基因表达量的相关性，结果是：r=1，p-value = 4.96e-05</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">这里斯皮尔曼等级相关的显著性显然高于皮尔森相关。这是因为虽然两个基因的表达量是非线性关系，但两个基因表达量在所有样本中的排列顺序是完全相同的，因为具有极显著的斯皮尔曼等级相关性。</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#ADBAC7;">x </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [</span><span style="color:#6CB6FF;">10.35</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">6.24</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">3.18</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">8.46</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">3.21</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">7.65</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">4.32</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">8.66</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">9.12</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">10.31</span><span style="color:#ADBAC7;">]  </span></span>
<span class="line"><span style="color:#ADBAC7;">y </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [</span><span style="color:#6CB6FF;">5.13</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">3.15</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">1.67</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">4.33</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">1.76</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">4.11</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">2.11</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">4.88</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">4.99</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">5.12</span><span style="color:#ADBAC7;">]  </span></span>
<span class="line"><span style="color:#ADBAC7;">correlation,pvalue </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> stats.stats.spearmanr(x,y)  </span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (</span><span style="color:#96D0FF;">&#39;correlation&#39;</span><span style="color:#ADBAC7;">,correlation)</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (</span><span style="color:#96D0FF;">&#39;pvalue&#39;</span><span style="color:#ADBAC7;">,pvalue)</span></span>
<span class="line"><span style="color:#ADBAC7;">correlation </span><span style="color:#6CB6FF;">1.0</span></span>
<span class="line"><span style="color:#ADBAC7;">pvalue </span><span style="color:#6CB6FF;">6.64689742203e-64</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [</span><span style="color:#6CB6FF;">10.35</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">6.24</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">3.18</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">8.46</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">3.21</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">7.65</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">4.32</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">8.66</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">9.12</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">10.31</span><span style="color:#ADBAC7;">]  </span></span>
<span class="line"><span style="color:#ADBAC7;">y </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [</span><span style="color:#6CB6FF;">5.13</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">3.15</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">1.67</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">4.33</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">1.76</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">4.11</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">2.11</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">4.88</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">4.99</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">5.12</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">x </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> scipy.stats.stats.rankdata(x)</span></span>
<span class="line"><span style="color:#ADBAC7;">y </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> scipy.stats.stats.rankdata(y)</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (x,y)</span></span>
<span class="line"><span style="color:#ADBAC7;">correlation,pvalue </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> stats.stats.spearmanr(x,y)  </span></span>
<span class="line"></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (</span><span style="color:#96D0FF;">&#39;correlation&#39;</span><span style="color:#ADBAC7;">,correlation)</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (</span><span style="color:#96D0FF;">&#39;pvalue&#39;</span><span style="color:#ADBAC7;">,pvalue)</span></span>
<span class="line"><span style="color:#ADBAC7;">[ </span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">.   4.   1.   6.   2.   5.   3.   7.   8.   9.] [ </span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">.   4.   1.   6.   2.   5.   3.   7.   8.   9.]</span></span>
<span class="line"><span style="color:#ADBAC7;">correlation </span><span style="color:#6CB6FF;">1.0</span></span>
<span class="line"><span style="color:#ADBAC7;">pvalue </span><span style="color:#6CB6FF;">6.64689742203e-64</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [</span><span style="color:#005CC5;">10.35</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">6.24</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">3.18</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">8.46</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">3.21</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">7.65</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4.32</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">8.66</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">9.12</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">10.31</span><span style="color:#24292E;">]  </span></span>
<span class="line"><span style="color:#24292E;">y </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [</span><span style="color:#005CC5;">5.13</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">3.15</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1.67</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4.33</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1.76</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4.11</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">2.11</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4.88</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4.99</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">5.12</span><span style="color:#24292E;">]  </span></span>
<span class="line"><span style="color:#24292E;">correlation,pvalue </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> stats.stats.spearmanr(x,y)  </span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (</span><span style="color:#032F62;">&#39;correlation&#39;</span><span style="color:#24292E;">,correlation)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (</span><span style="color:#032F62;">&#39;pvalue&#39;</span><span style="color:#24292E;">,pvalue)</span></span>
<span class="line"><span style="color:#24292E;">correlation </span><span style="color:#005CC5;">1.0</span></span>
<span class="line"><span style="color:#24292E;">pvalue </span><span style="color:#005CC5;">6.64689742203e-64</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [</span><span style="color:#005CC5;">10.35</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">6.24</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">3.18</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">8.46</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">3.21</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">7.65</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4.32</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">8.66</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">9.12</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">10.31</span><span style="color:#24292E;">]  </span></span>
<span class="line"><span style="color:#24292E;">y </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [</span><span style="color:#005CC5;">5.13</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">3.15</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1.67</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4.33</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1.76</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4.11</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">2.11</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4.88</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4.99</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">5.12</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> scipy.stats.stats.rankdata(x)</span></span>
<span class="line"><span style="color:#24292E;">y </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> scipy.stats.stats.rankdata(y)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (x,y)</span></span>
<span class="line"><span style="color:#24292E;">correlation,pvalue </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> stats.stats.spearmanr(x,y)  </span></span>
<span class="line"></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (</span><span style="color:#032F62;">&#39;correlation&#39;</span><span style="color:#24292E;">,correlation)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (</span><span style="color:#032F62;">&#39;pvalue&#39;</span><span style="color:#24292E;">,pvalue)</span></span>
<span class="line"><span style="color:#24292E;">[ </span><span style="color:#005CC5;">10</span><span style="color:#24292E;">.   4.   1.   6.   2.   5.   3.   7.   8.   9.] [ </span><span style="color:#005CC5;">10</span><span style="color:#24292E;">.   4.   1.   6.   2.   5.   3.   7.   8.   9.]</span></span>
<span class="line"><span style="color:#24292E;">correlation </span><span style="color:#005CC5;">1.0</span></span>
<span class="line"><span style="color:#24292E;">pvalue </span><span style="color:#005CC5;">6.64689742203e-64</span></span></code></pre></div><h4 id="案例" tabindex="-1">案例 <a class="header-anchor" href="#案例" aria-label="Permalink to &quot;案例&quot;">​</a></h4><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B09.png" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B010.png" alt=""></p><h3 id="_5-肯德尔和谐系数" tabindex="-1">5. 肯德尔和谐系数 <a class="header-anchor" href="#_5-肯德尔和谐系数" aria-label="Permalink to &quot;5. 肯德尔和谐系数&quot;">​</a></h3><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">当多个（两个以上）变量值以等级次序排列或以等级次序表示，描述这几个变量之间的一致性程度的量，称为肯德尔和谐系数。它常用来表示几个评定者对同一组学生成绩用等级先后评定多次之间的一致性程度。</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">当多个（两个以上）变量值以等级次序排列或以等级次序表示，描述这几个变量之间的一致性程度的量，称为肯德尔和谐系数。它常用来表示几个评定者对同一组学生成绩用等级先后评定多次之间的一致性程度。</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B011.png" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B012.png" alt=""></p><h4 id="案例1-同一评价者无相同等级评定时" tabindex="-1">案例1：同一评价者无相同等级评定时 <a class="header-anchor" href="#案例1-同一评价者无相同等级评定时" aria-label="Permalink to &quot;案例1：同一评价者无相同等级评定时&quot;">​</a></h4><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B013.png" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B014.png" alt=""></p><h4 id="案例2-同一评价者有相同等级评定时" tabindex="-1">案例2：同一评价者有相同等级评定时 <a class="header-anchor" href="#案例2-同一评价者有相同等级评定时" aria-label="Permalink to &quot;案例2：同一评价者有相同等级评定时&quot;">​</a></h4><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B015.png" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B016.png" alt=""></p><h4 id="肯德尔和谐系数的显著性检验" tabindex="-1">肯德尔和谐系数的显著性检验 <a class="header-anchor" href="#肯德尔和谐系数的显著性检验" aria-label="Permalink to &quot;肯德尔和谐系数的显著性检验&quot;">​</a></h4><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">肯德尔和谐系数的显著性检验</span></span>
<span class="line"><span style="color:#adbac7;">评分者人数(k)在3-20之间，被评者(N)在3-7之间时，可查《肯德尔和谐系数(W)显著性临界值表》，检验W是否达到显著性水平。若实际计算的S值大于k、N相同的表内临界值 ，则W达到显著水平。</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">当K=6 N=6，查表得检验水平分别为α = 0.01，α = 0.05的临界值各为S0.01 = 282.4，S0.05 = 221.4，均小于实算的S=546，故W达到显著水平，认为6位教师对6篇论文的评定相当一致。</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">当被评者n＞7时，则可用如下的x2统计量对W是否达到显著水平作检验。</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">肯德尔和谐系数的显著性检验</span></span>
<span class="line"><span style="color:#24292e;">评分者人数(k)在3-20之间，被评者(N)在3-7之间时，可查《肯德尔和谐系数(W)显著性临界值表》，检验W是否达到显著性水平。若实际计算的S值大于k、N相同的表内临界值 ，则W达到显著水平。</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">当K=6 N=6，查表得检验水平分别为α = 0.01，α = 0.05的临界值各为S0.01 = 282.4，S0.05 = 221.4，均小于实算的S=546，故W达到显著水平，认为6位教师对6篇论文的评定相当一致。</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">当被评者n＞7时，则可用如下的x2统计量对W是否达到显著水平作检验。</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#ADBAC7;">x1 </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">9</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">8</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">7</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">6</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">x2 </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">8</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">9</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">6</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">7</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">tau, p_value </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> stats.kendalltau(x1, x2)</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (</span><span style="color:#96D0FF;">&#39;tau&#39;</span><span style="color:#ADBAC7;">,tau)</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (</span><span style="color:#96D0FF;">&#39;p_value&#39;</span><span style="color:#ADBAC7;">,p_value)</span></span>
<span class="line"><span style="color:#ADBAC7;">tau </span><span style="color:#6CB6FF;">0.6</span></span>
<span class="line"><span style="color:#ADBAC7;">p_value </span><span style="color:#6CB6FF;">0.141644690295</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">x1 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">9</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">8</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">7</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">6</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">x2 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">8</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">9</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">6</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">7</span><span style="color:#24292E;">]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">tau, p_value </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> stats.kendalltau(x1, x2)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (</span><span style="color:#032F62;">&#39;tau&#39;</span><span style="color:#24292E;">,tau)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (</span><span style="color:#032F62;">&#39;p_value&#39;</span><span style="color:#24292E;">,p_value)</span></span>
<span class="line"><span style="color:#24292E;">tau </span><span style="color:#005CC5;">0.6</span></span>
<span class="line"><span style="color:#24292E;">p_value </span><span style="color:#005CC5;">0.141644690295</span></span></code></pre></div><h3 id="_6-质量相关分析" tabindex="-1">6. 质量相关分析 <a class="header-anchor" href="#_6-质量相关分析" aria-label="Permalink to &quot;6. 质量相关分析&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#ADBAC7;">质量相关是指一个变量为质，另一个变量为量，这两个变量之间的相关。如智商、学科分数、身高、体重等是表现为量的变量，男与女、优与劣、及格与不及格等是表现为质的变量。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">质与量的相关主要包括二列相关、点二列相关、多系列相关。</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">质量相关是指一个变量为质，另一个变量为量，这两个变量之间的相关。如智商、学科分数、身高、体重等是表现为量的变量，男与女、优与劣、及格与不及格等是表现为质的变量。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">质与量的相关主要包括二列相关、点二列相关、多系列相关。</span></span></code></pre></div><h4 id="二列相关" tabindex="-1">二列相关 <a class="header-anchor" href="#二列相关" aria-label="Permalink to &quot;二列相关&quot;">​</a></h4><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">二列相关</span></span>
<span class="line"><span style="color:#adbac7;">当两个变量都是正态连续变量．其中一个变量被人为地划分成二分变量(如按一定标推将属于正态连续变量的学科考试分数划分成及格与不及格，录取与未录取，把某一体育项目测验结果划分成通过与未通过，达标与末达标，把健康状况划分成好与差，等等)，表示这两个变量之间的相关，称为二列相关。</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">二列相关的使用条件：</span></span>
<span class="line"><span style="color:#adbac7;">- 两个变量都是连续变量，且总体呈正态分布，或总体接近正态分布，至少是单峰对称分布。</span></span>
<span class="line"><span style="color:#adbac7;">- 两个变量之间是线性关系。</span></span>
<span class="line"><span style="color:#adbac7;">- 二分变量是人为划分的，其分界点应尽量靠近中值。</span></span>
<span class="line"><span style="color:#adbac7;">- 样本容量应当大于80。</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">二列相关</span></span>
<span class="line"><span style="color:#24292e;">当两个变量都是正态连续变量．其中一个变量被人为地划分成二分变量(如按一定标推将属于正态连续变量的学科考试分数划分成及格与不及格，录取与未录取，把某一体育项目测验结果划分成通过与未通过，达标与末达标，把健康状况划分成好与差，等等)，表示这两个变量之间的相关，称为二列相关。</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">二列相关的使用条件：</span></span>
<span class="line"><span style="color:#24292e;">- 两个变量都是连续变量，且总体呈正态分布，或总体接近正态分布，至少是单峰对称分布。</span></span>
<span class="line"><span style="color:#24292e;">- 两个变量之间是线性关系。</span></span>
<span class="line"><span style="color:#24292e;">- 二分变量是人为划分的，其分界点应尽量靠近中值。</span></span>
<span class="line"><span style="color:#24292e;">- 样本容量应当大于80。</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B017.png" alt=""></p><h4 id="案例-1" tabindex="-1">案例 <a class="header-anchor" href="#案例-1" aria-label="Permalink to &quot;案例&quot;">​</a></h4><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B018.png" alt=""></p><h4 id="点二列相关" tabindex="-1">点二列相关 <a class="header-anchor" href="#点二列相关" aria-label="Permalink to &quot;点二列相关&quot;">​</a></h4><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">当两个变量其中一个是正态连续性变量，另一个是真正的二分名义变量(例如，男与女，已婚和未婚，色盲与非色盲，生与死，等等)，这时，表示这两个变量之间的相关，称为点二列相关。</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">当两个变量其中一个是正态连续性变量，另一个是真正的二分名义变量(例如，男与女，已婚和未婚，色盲与非色盲，生与死，等等)，这时，表示这两个变量之间的相关，称为点二列相关。</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B019.png" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B020.png" alt=""></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#ADBAC7;">x </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">y </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [</span><span style="color:#6CB6FF;">84</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">82</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">76</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">60</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">72</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">74</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">76</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">84</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">88</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">90</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">78</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">80</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">92</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">94</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">96</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">88</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">90</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">78</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">76</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">74</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">stats.pointbiserialr(x, y)</span></span>
<span class="line"><span style="color:#ADBAC7;">PointbiserialrResult(</span><span style="color:#F69D50;">correlation</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">0.7849870641173371</span><span style="color:#ADBAC7;">, </span><span style="color:#F69D50;">pvalue</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">4.1459279734903919e-05</span><span style="color:#ADBAC7;">)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">y </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [</span><span style="color:#005CC5;">84</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">82</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">76</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">60</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">72</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">74</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">76</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">84</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">88</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">90</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">78</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">80</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">92</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">94</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">96</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">88</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">90</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">78</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">76</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">74</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">stats.pointbiserialr(x, y)</span></span>
<span class="line"><span style="color:#24292E;">PointbiserialrResult(</span><span style="color:#E36209;">correlation</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">0.7849870641173371</span><span style="color:#24292E;">, </span><span style="color:#E36209;">pvalue</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">4.1459279734903919e-05</span><span style="color:#24292E;">)</span></span></code></pre></div><h3 id="_7-品质相关分析" tabindex="-1">7. 品质相关分析 <a class="header-anchor" href="#_7-品质相关分析" aria-label="Permalink to &quot;7. 品质相关分析&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#ADBAC7;">两个变量都是按质划分成几种类别，表示这两个变量之间的相关称为品质相关。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">如，一个变量按性别分成男与女，另一个变量按学科成绩分成及格与不及格；又如，一个变量按学校类别分成重点及非重点，另一个变量按学科成绩分成优、良、中、差，等等。</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">两个变量都是按质划分成几种类别，表示这两个变量之间的相关称为品质相关。</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">如，一个变量按性别分成男与女，另一个变量按学科成绩分成及格与不及格；又如，一个变量按学校类别分成重点及非重点，另一个变量按学科成绩分成优、良、中、差，等等。</span></span></code></pre></div><h4 id="列联相关系数" tabindex="-1">列联相关系数 <a class="header-anchor" href="#列联相关系数" aria-label="Permalink to &quot;列联相关系数&quot;">​</a></h4><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%9021.png" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E6%80%A7%E5%88%86%E6%9E%9022.png" alt=""></p><h4 id="φ相关" tabindex="-1">φ相关 <a class="header-anchor" href="#φ相关" aria-label="Permalink to &quot;φ相关&quot;">​</a></h4><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E5%88%86%E6%9E%9023.png" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E5%88%86%E6%9E%9024.png" alt=""></p><h3 id="_8-偏相关与复相关" tabindex="-1">8. 偏相关与复相关 <a class="header-anchor" href="#_8-偏相关与复相关" aria-label="Permalink to &quot;8. 偏相关与复相关&quot;">​</a></h3><h4 id="偏相关分析" tabindex="-1">偏相关分析 <a class="header-anchor" href="#偏相关分析" aria-label="Permalink to &quot;偏相关分析&quot;">​</a></h4><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">在多要素所构成的地理系统中，先不考虑其它要素的影响，而单独研究两个要素之间的相互关系的密切程度，这称为偏相关。用以度量偏相关程度的统计量，称为偏相关系数。</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">在分析变量x1和x2之间的净相关时，当控制了变量x3的线性作用后，x1和x2之间的一阶偏相关系数定义为：</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">在多要素所构成的地理系统中，先不考虑其它要素的影响，而单独研究两个要素之间的相互关系的密切程度，这称为偏相关。用以度量偏相关程度的统计量，称为偏相关系数。</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">在分析变量x1和x2之间的净相关时，当控制了变量x3的线性作用后，x1和x2之间的一阶偏相关系数定义为：</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E5%88%86%E6%9E%9025.png" alt=""></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">偏相关系数的性质</span></span>
<span class="line"><span style="color:#adbac7;">偏相关系数分布的范围在-1到1之间</span></span>
<span class="line"><span style="color:#adbac7;">偏相关系数的绝对值越大，表示其偏相关程度越大</span></span>
<span class="line"><span style="color:#adbac7;">偏相关系数的绝对值必小于或最多等于由同一系列资料所求得的复相关系数，即 R1·23≥|r12·3|</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">偏相关系数的性质</span></span>
<span class="line"><span style="color:#24292e;">偏相关系数分布的范围在-1到1之间</span></span>
<span class="line"><span style="color:#24292e;">偏相关系数的绝对值越大，表示其偏相关程度越大</span></span>
<span class="line"><span style="color:#24292e;">偏相关系数的绝对值必小于或最多等于由同一系列资料所求得的复相关系数，即 R1·23≥|r12·3|</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E5%88%86%E6%9E%9026.png" alt=""></p><h4 id="复相关系数" tabindex="-1">复相关系数 <a class="header-anchor" href="#复相关系数" aria-label="Permalink to &quot;复相关系数&quot;">​</a></h4><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#adbac7;">反映几个要素与某一个要素之间 的复相关程度。复相关系数介于0到1之间。</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">复相关系数越大，则表明要素（变量）之间的相关程度越密切。复相关系数为1，表示完全相关；复相关系数为0，表示完全无关。</span></span>
<span class="line"><span style="color:#adbac7;"></span></span>
<span class="line"><span style="color:#adbac7;">复相关系数必大于或至少等于单相关系数的绝对值。</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">反映几个要素与某一个要素之间 的复相关程度。复相关系数介于0到1之间。</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">复相关系数越大，则表明要素（变量）之间的相关程度越密切。复相关系数为1，表示完全相关；复相关系数为0，表示完全无关。</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">复相关系数必大于或至少等于单相关系数的绝对值。</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/python/math/%E7%9B%B8%E5%85%B3%E5%88%86%E6%9E%9027.png" alt=""></p>`,74);function g(s,u,b,v,m,k){const o=c,e=A("ClientOnly");return p(),r("div",null,[E,y(e,null,{default:i(()=>{var a,n;return[(((a=s.$frontmatter)==null?void 0:a.aside)??!0)&&(((n=s.$frontmatter)==null?void 0:n.showArticleMetadata)??!0)?(p(),d(o,{key:0,article:s.$frontmatter},null,8,["article"])):F("",!0)]}),_:1}),D])}const P=t(h,[["render",g]]);export{q as __pageData,P as default};
