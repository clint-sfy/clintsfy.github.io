import{_ as p}from"./chunks/ArticleMetadata.CQf8Ggee.js";import{_ as h,C as n,c as d,o as i,k as l,G as c,P as m,a as u,w as b,b as S,e as f}from"./chunks/framework.BbsDpi52.js";import"./chunks/md5.CF1HUy9Q.js";const L=JSON.parse('{"title":"Slam基础","description":"","frontmatter":{"title":"Slam基础","author":"阿源","date":"2023/11/01 12:00","categories":["个人项目"],"tags":["个人项目","ROS"]},"headers":[],"relativePath":"my_project/02-AGV项目/01-Slam基础及部署.md","filePath":"my_project/02-AGV项目/01-Slam基础及部署.md","lastUpdated":1713341239000}'),k={name:"my_project/02-AGV项目/01-Slam基础及部署.md"};function A(e,a,_,g,M,E){const o=p,s=n("ClientOnly");return i(),d("div",null,[a[0]||(a[0]=l("h1",{id:"slam基础",tabindex:"-1"},[u("Slam基础 "),l("a",{class:"header-anchor",href:"#slam基础","aria-label":'Permalink to "Slam基础"'},"​")],-1)),c(s,null,{default:b(()=>{var t,r;return[(((t=e.$frontmatter)==null?void 0:t.aside)??!0)&&(((r=e.$frontmatter)==null?void 0:r.showArticleMetadata)??!0)?(i(),S(o,{key:0,article:e.$frontmatter},null,8,["article"])):f("",!0)]}),_:1}),a[1]||(a[1]=m('<p>2D激光雷达SLAM方案有gmapping和Cartographer。目前室内应用还是Cartographer居多，它是谷歌开源的，有闭环功能。</p><p>3D激光雷达SLAM。比较知名的有LOAM、ALOAM、LeGO-LOAM、LIO-SAM、LVI-SAM等</p><ul><li>LOAM是卡内基梅隆大学的Ji Zhang早期发表的多线LiDAR SLAM算法。是该领域的鼻祖，不过该代码可读性差，作者后来将其闭源。</li><li>A-LOAM是港科大秦通（VINS系列一作）在LOAM原有代码基础上，使用Ceres-solver和Eigen库对其进行重构和优化，在保持原有算法原理的基础上，使其可读性大大增加，作为入门多线激光slam最好选择。</li><li>LeGO-LOAM 是麻省理工学院的Tixiao Shan在原有LOAM基础上，做了一些改进包括:1、对前端里程计的前量化改造，提取地面点更适配水平安装的LiDAR; 2、使用SLAM中的Keyframe概念以及回环检测位姿图优化的方式对后端进行重构。</li><li>LIO-SAM 是Tixiao Shan在LeGO-LOAM的扩展，添加了IMU预积分因子和GPS因子：前端使用紧耦合的IMU融合方式，替代原有的帧间里程计，使得前端更轻量；后端沿用LeGO-LOAM，在此基础上融入了GPS观测。同时前端后端相互耦合，提高系统精度。</li><li>LVI-SAM是Tixiao Shan 2021年最新的开源工作，他将LIO-SAM和VINS-Mono进行了结合，是一个通过平滑和建图实现激光雷达-视觉-惯性里程计的紧耦合框架，由两个紧耦合子系统组成：一个视觉惯性系统VIS和一个激光雷达惯性系统LIS。当两个子系统中的一个发生故障时，系统也可以发挥作用，这增加了它在无纹理和无特征环境中的鲁棒性。</li></ul><p>FAST-LIO2是香港大学火星实验室（MARS）发表在IEEE-RAL和IEEE-TRO的两篇论文，是一种具有高计算效率、高鲁棒性的雷达惯性里程计（LIO）。它通过紧耦合误差状态卡尔曼滤波器实现IMU和激光雷达融合的状态估计，是目前最先进的开源LIO框架之一。</p><p>FAST-LIO2涵盖流形、李群李代数、IMU积分 、雷达残差、卡尔曼滤波等多方位的知识，代码可读性好，学习FAST-LIO2有助于理解多传感器融合原理，夯实理论知识，提高实践能力。</p><h2 id="传感器原理篇" tabindex="-1">传感器原理篇 <a class="header-anchor" href="#传感器原理篇" aria-label="Permalink to &quot;传感器原理篇&quot;">​</a></h2><h3 id="_1-视觉传感器" tabindex="-1">1. 视觉传感器 <a class="header-anchor" href="#_1-视觉传感器" aria-label="Permalink to &quot;1. 视觉传感器&quot;">​</a></h3><h4 id="_1-1-基本原理" tabindex="-1">1.1 基本原理 <a class="header-anchor" href="#_1-1-基本原理" aria-label="Permalink to &quot;1.1 基本原理&quot;">​</a></h4><p>视觉传感器是用来收集图像和视觉信息的工具,该传感器其实是属于光电传感器的一种,视觉传感器的基本原理是叫做&quot;光电效应”,简单来说就是有的材料在光照下会产生电流(外光电效应),有的材料在光照下电子会发生变化(内光电效应)。</p><p>对于视觉传感器而言,其工作原理即为,当外界的光进入传感器后,传感器通过内部的感光元件收集到光信号,并通过相关电路处理,将光信号转换为电信号输出。</p><h4 id="_1-2-原理分类" tabindex="-1">1.2 原理分类 <a class="header-anchor" href="#_1-2-原理分类" aria-label="Permalink to &quot;1.2 原理分类&quot;">​</a></h4><p>光电效应分为外光电效应和内光电效应,其中内光电效应又分为光电导效应和光生伏特效应,光电导效应需要给电路加电压,而光生伏特不用。这三种光电效应的区分很简单,就是在光线作用下,它们电子的变化是不一样的。</p><p>而对于视觉传感器来说,其最常用的即为光电导效应,主流的传感器有两种,分别为CCD和CMOs。两者都是通过感光二极管进行光电转换,将图像转化为数字数据,CCD和CMOS的主要差距就是数字数据传输的方式不同。由于CMOS传感器的每个像素由四个晶体管与一个感光二极管构成(含放大器与A/D转换电路),使得每个像素的感光区域远小于像素本身的表面积,因此在像素尺寸相同的情况下,CMOS传感器的灵敏度要低于CCD传感器。</p><p>而CMOS相较于CCD而言最主要的优势就是非常省电,不像由二极管组成的cCD,CMOS电路几乎没有静态电量消耗,只有在电路接通时才有电量的消耗。这就使得CMOS的耗电量只有普通CCD的1/3左右。</p><h4 id="_1-3-产品分类" tabindex="-1">1.3 产品分类 <a class="header-anchor" href="#_1-3-产品分类" aria-label="Permalink to &quot;1.3 产品分类&quot;">​</a></h4><p>我们从原理上阐述了相机常用的两种视觉传感器,但是在实际选型中,我们会更会在意产品的分类,即是单目相机还是双目相机、是非事件相机还是事件相机</p><h5 id="单目相机" tabindex="-1">单目相机 <a class="header-anchor" href="#单目相机" aria-label="Permalink to &quot;单目相机&quot;">​</a></h5><p>单目相机作为日常使用中最简单的视觉传感器,其因为结构简单,成本低,便于标定和识别等优势从而占领了绝大多数市场,但是我们也非常明白单目相机是无法在单张图片里,无法确定一个物体的真实大小的。也就是说,我们需要使用多帧并利用三角化才能完成深度的确定,这就对CPU的算力提出了要求。目前来看,主流的SLAM算法都是支持单目的,虽然不如双目稳定性高,但是在绝大多数场景中,单目SLAM已经可以稳定的定位建图。</p><h5 id="双目相机" tabindex="-1">双目相机 <a class="header-anchor" href="#双目相机" aria-label="Permalink to &quot;双目相机&quot;">​</a></h5><p>双目相机是除单目相机以外使用较多的相机,其相较于单目而言,最大的优势就是存在基线,可以直接计算出相机和物体之间的距离,消除了单目的尺度等价性,但是深度的计算范围受基线限制。缺点也比较明显,即计算量大,同时需要对两个相机完成标定,但是现在绝大多数的双目相机都在内置的FPGA芯片中完成了加速的操作,同时在出厂时候也提供了比价精确的内外参的标定参数。</p><h5 id="鱼眼相机" tabindex="-1">鱼眼相机 <a class="header-anchor" href="#鱼眼相机" aria-label="Permalink to &quot;鱼眼相机&quot;">​</a></h5><p>鱼眼相机作为单目相机的大类中的一个小类,其因为自身的FOV视场角比一般的鱼眼相机大很多,视场角可以接近或等于180°。所以可以获得更大的视野,同时能够提取到更多的特征。但是其缺点也在这里,鱼眼镜头的焦距很短、视角很大,能使景物的透视感得到极大的夸张。所以导致画面中除通过中心部分的直线仍保持直线外,其他部分的直线都产生了不同程度的畸变,而在边缘处畸变会收到更大的影响,所以需要一个比较良好的内参标定才能完成鱼眼相机的去畸变的工作。</p><h5 id="深度相机" tabindex="-1">深度相机 <a class="header-anchor" href="#深度相机" aria-label="Permalink to &quot;深度相机&quot;">​</a></h5><p>深度相机是以Kinect以及realsence为代表的这一类的RGB-D深度相机,该类相机可以不用计算就能直接得到相机和目标物体之间的距离,这就避免了传统双目相机求景深所需要的大量计算。但是这类深度相机测量深度的范围窄,噪声大,视野小,容易受到光照的影响,所以一般适用场景仅为室内。</p><h5 id="环视相机" tabindex="-1">环视相机 <a class="header-anchor" href="#环视相机" aria-label="Permalink to &quot;环视相机&quot;">​</a></h5><p>环视相机为最近几年自动驾驶发展火热后所产生的一种多相机拼接所产生的360°环视效果的相机,其是由多个鱼眼相机拼接而成,每一个鱼眼相机的感受视场角都超过180度;通过将四个视场拼接从而形成了一个360度的感知视野。由于这些特性,其与双目相机类似,所以环视相机非常依赖内外参数的标定。否则无法准确的估计出BEV视角下障碍物的深度。</p><h5 id="红外相机" tabindex="-1">红外相机 <a class="header-anchor" href="#红外相机" aria-label="Permalink to &quot;红外相机&quot;">​</a></h5><p>红外相机作为单目相机的一个分支,其能够通过感知物体发出的红外光,来与传统的彩色相机、黑白相机、昼夜转换相机搭配使用。同时红外相机可以在完全无光的夜晚,或是在雨、雪等烟云密布的恶劣环境,能够清晰地观察到所需监控的目标。但是红外相机的缺点也很明显,即其价格相对于传统相机来说更加昂贵</p><h5 id="事件相机" tabindex="-1">事件相机 <a class="header-anchor" href="#事件相机" aria-label="Permalink to &quot;事件相机&quot;">​</a></h5><p>事件相机也是近年来比较流行的相机,其具备极快的响应速度、减少无效信息、降低算力和功耗、高动态范围等优势,可以帮助自动驾驶车辆降低信息处理的复杂度、提高车辆的行驶安全,并能够在极亮或者极暗环境下正常工作。缺点也很明显,就是数据异步不易处理、单一事件有效信息少、数据稀疏不完整等</p><h4 id="_1-4-参数解读" tabindex="-1">1.4 参数解读 <a class="header-anchor" href="#_1-4-参数解读" aria-label="Permalink to &quot;1.4 参数解读&quot;">​</a></h4><p>对于我们常用视觉传感器而言其主要参数主要分为几大类,分别是:性能参数、相机内参、相机外参。其中性能参数与相机内参是相机在出厂时候就固定了的,而外参标定是与标定存在一定的关系。下面我们就从三个方面来介绍相机的参数</p><h5 id="性能参数" tabindex="-1">性能参数 <a class="header-anchor" href="#性能参数" aria-label="Permalink to &quot;性能参数&quot;">​</a></h5><p>分辨率:一般是说摄像头能支持到的最大图像大小,如640x480(普清),800x600,1280×720(高清),1920×1080(全高清或超清)等。这个数字越大,则代表了摄像头的单位面积下更加清晰,当然我们在选型时候,也需要考虑该场景所需要的分辨率的要求。因为如果一味的增加分辨率,这会导致计算复杂度的增加,不利于图像数据的传输以及系统优化。</p><p>色彩空间:摄像头采集数据的存放格式,一般有YUYV, YV12,NV12,MJPEG等。一般的编码器输入为YV12(JM,×264)或者NV12(×264内部帧存储格式,将NV12输入x264更有优势),如果摄像头输出的是YUYV格式,就需要进行色彩空间转换,转换为软件能够接受的格式,这势必增加了计算量。MJPEG是MotionJPEG,可以理解为PEG图像的序列,这类序列可以大大降低存储数据量,由此也会影响摄像头的输出帧率。</p><p>帧率:一般是说摄像头在某种色彩空间中最大分辨率下能够支持的最高视频捕获能力。帧率也需要根据实际需求来进行选择,一般来说传统的30FPS的视频帧率已经可以满足大多数场景的需求。</p><h5 id="相机内参" tabindex="-1">相机内参 <a class="header-anchor" href="#相机内参" aria-label="Permalink to &quot;相机内参&quot;">​</a></h5><p>对于相机而言去畸变这类操作会涉及到内参的运算,我们常说的相机内参有四个,分别为fx,fy,u0,V0这四个参数。具体公式为:</p><p>fx = F/dx</p><p>fy = F/dy</p><p>其中dx，dy表示x方向和y方向的一个像素分别占多少长度单位,即一个像素代表的实际物理的大小,其是实现图像物理坐标系与像素坐标系转换的关键。</p><p>另外两个u0,V0表示图像的中心像素坐标系和图像原点像素坐标之间的相差的横向和纵向像素数。对应的理论值应该是图像宽度和高度的一半,但是实际上是由偏差的,一边越好的摄像头则会越接近于分辨率的一半。这四个参数就组成了相机的内参</p><p>此外畸变参数也可以算作内参的一种,一般在鱼眼镜头中会比较常用这些畸变参数。其中k1,k2,k3径向畸变系数,p1,p2是切向畸变系数。径向畸变发生在相机坐标系转图像物理坐标系的过程中。而切向畸变是发生在相机制作过程,其是由于感光元平面跟透镜不平行。径向畸变,即由于透镜的不同区域的焦距的不同而引起的畸变,分为枕形畸变和桶形畸变如下图所示,越靠近镜头边缘畸变越明显。</p><h5 id="相机外参" tabindex="-1">相机外参 <a class="header-anchor" href="#相机外参" aria-label="Permalink to &quot;相机外参&quot;">​</a></h5><p>相机的外参是车体坐标系在相机坐标系下的描述。R旋转参数是每个轴的旋转矩阵的乘积,其中每个轴的旋转参数。T是平移参数。根据旋转参数和平移参数可以转化为外参矩阵。</p><h3 id="_2-激光雷达原理" tabindex="-1">2. 激光雷达原理 <a class="header-anchor" href="#_2-激光雷达原理" aria-label="Permalink to &quot;2. 激光雷达原理&quot;">​</a></h3><h4 id="_2-1-基本原理" tabindex="-1">2.1 基本原理 <a class="header-anchor" href="#_2-1-基本原理" aria-label="Permalink to &quot;2.1 基本原理&quot;">​</a></h4><p>激光雷达作为机器人最常用的传感器之一,其主要的工作原理就是通过测量激光信号的时间差和相位差来确定位置。相比于上文讲到得可见光摄像头,红外摄像头等视觉传感器而言,激光具有以下几个特点,首先是激光雷达可以直接提供环境中特征的深度,并得到目标相对完整的空间信息,而不需要借助复杂的三角化运算。其次激光雷达不受光照等条件的影响,抗干扰性强,可以全天候工作。但是激光雷达仍然存在有几个比较大的问题,第一个就是价格昂贵,相较于摄像头而言,激光雷达的价格会高出不少。同时激光雷达不具备纹理信息,无法有效的基于RGB等信息完成目标识别与分割,虽然近年来有一些工作聚焦于基于多线激光雷达的识别分割,但是效果性能远不如摄像头的视觉分割,最后一就是激光雷达仍然无法胜任雨雪天气,或者玻璃门等场景,这会导致激光的噪点过多和失效。</p><p>对于一个激光雷达来说,其主要有以下四个部分组成:激光发射部分、扫描系统、激光接受部分和信息处理部分,结构较为复杂。</p><ol><li><p>激光发射部分:激励源周期性地驱动激光器,发射激光脉冲,激光调制器通过光束控制器控制发射激光的方向和线数,最后通过发射光学系统,将激光发射至目标物体;</p></li><li><p>激光接收系统:经接收光学系统,光电探测器接受目标物体反射回来的激光,产生接收信号;</p></li><li><p>扫描系统,以稳定的转速旋转起来,实现对所在平面的扫描,并产生实时的平面图信息;</p></li><li><p>信息处理系统:接收信号经过放大处理和数模转换,经由信息处理模块计算,获取目标表面形态、物理属性等特性,最终建立物体模型。</p></li></ol><p>对于激光雷达而言,主要的测距方法被分为两种,第一种就是以飞行时间(time of flight)法为主,利用发射器发射的脉冲信号和接收器接受到的反射脉冲信号的时间间隔来计算和目标物体的距离。而另一种就是使用相干法,即调频连续波(FMCW)激光雷达发射一束连续的光束,频率随时间稳定地发生变化,相较于飞行时间(time of fliaht)法而言,该种激光雷达不会受到其他激光雷达或者太阳光的影响,还可以利用多普勒频移来测量物体的速度和距离,但是这种方式仍然存在有发射激光的线宽限制、线性调频脉冲的频率范围、线性脉冲频率变化的线性度,以及单个线性调频脉冲的可复制性等问题。</p><h4 id="_2-2-分类" tabindex="-1">2.2 分类 <a class="header-anchor" href="#_2-2-分类" aria-label="Permalink to &quot;2.2 分类&quot;">​</a></h4><p>对于激光雷达而言，其作为LIO这类激光SLAM的载体而言,其可以利用两帧的ICP匹配完成激光里程计的推导,并根据机器人的状态估计,和构建传感器所感知的环境模型组成SLAM系统。激光雷达的种类繁多,主要分为2D激光雷达和3D激光雷达,它们由激光雷达光束的数量定义。在生产工艺方面,激光雷达还可分为机械激光雷达,混合式固态激光雷达(如MEMS)和固态激光雷达。国内外的较为知名的厂商为:</p><p>1)一径科技：专注全固态激光雷达,主要供应MEMS类型的激光雷达2)禾赛科技:代表系列为Pandar系列,其主要的产品Pandar40系列为机械激光雷达 3)镭神智能：镭神作为国内比较久的企业,其品种丰富,同时也是全球唯一家掌握了TOF时间飞行法、相位法、三角法和调频连续波等四种测量方法的激光雷达公司。可以看出其较高的研发实力 4)Livox(览沃)：Livox是国内无人机龙头大疆孵化的激光雷达公司,其成本低廉,生产的固态激光雷达基本均为干元级别。同时官方提供的预开发均是较为完善的。</p><h4 id="数据频率" tabindex="-1">数据频率 <a class="header-anchor" href="#数据频率" aria-label="Permalink to &quot;数据频率&quot;">​</a></h4><p>数据频率在激光雷达中代表的就是单位周期内采集的点数,因为激光雷达在旋转扫描,因此水平方向上扫描的点数和激光雷达的扫描频率有一定的关系,扫描越快则点数会相对较少,扫描慢则点数相对较多。一般这个参数也被称为水平分辨率。这个般来说和激光束有着直接关系。</p><h4 id="有效检测距离" tabindex="-1">有效检测距离 <a class="header-anchor" href="#有效检测距离" aria-label="Permalink to &quot;有效检测距离&quot;">​</a></h4><p>激光雷达是一个收发异轴的光学系统(其实所有的机械雷达都是),也就是说,发射出去的激光光路和返回的激光光路并不重合。由于激光雷达检测障碍物的有效距离和最小垂直分辨率有关系,也就是说角度分辨率越小,则检测的效果越好。如果两个激光光束之间的角度为0.4,那么当探测距离为200m的时候,两个激光光束之间的距离为200m*tan0.4≈1.4m。也就是说在200m之后,只能检测到高于1.4m的障碍物了,这就导致了各大厂商设置了一个有效检测的范围,用来指定在特定范围内无法是在精度允许范围内的,一般来说精度误差越小,有效检测距离越大。该款激光雷达就是更加适合的激光雷达。</p><h3 id="_3-惯性导航" tabindex="-1">3. 惯性导航 <a class="header-anchor" href="#_3-惯性导航" aria-label="Permalink to &quot;3. 惯性导航&quot;">​</a></h3><p>作用：补偿激光雷达点云过程中的畸变，IMU的频率会比较快，通过帧间的约束，可以有效去除机械式激光雷达点云间的畸变。</p><h4 id="_3-1-基本原理" tabindex="-1">3.1 基本原理 <a class="header-anchor" href="#_3-1-基本原理" aria-label="Permalink to &quot;3.1 基本原理&quot;">​</a></h4><p>惯性导航系统是一种利用惯性敏感器件、基准方向及最初的位置信息来确定运载体在惯性空间中的位置、方向和速度的自主式导航系统,有时也简称为惯导。其工作环境不仅包括空中、地面,还可以在水下。惯性导航之所以叫惯性导航,就是因为使用的是惯性器件,也就是加速度计,陀螺仪,磁力计,气压计等因此,惯性导航系统至少需要包括含有加速度计、陀螺仪等的惯性测量单元和用于推理的计算单元两大部分。其基础组成部分就是加速度计、陀螺仪和磁力计。 加速度计测量加速度,利用的原理是a=F/M,测量物体的惯性力。加速度计在惯性参照系中用于测量系统的线加速度,但只能测量相对于系统运动方向的加速度。可以通过对加速度进行解算,求得角速度,但由于精度不高,不具有很好的使用价值。但是加速度计可以辅助陀螺仪进行角度解算。 第二个常用传感器就是陀螺仪,陀螺仪是基于惯性参照的,主要用于测量系统的角速率。一般会将惯性参考系中系统初始方位作为初始条件,并对角速率进行积分,就可以根据时刻推算得到系统的当前方向。但由于其工作原理是积分,所以在静态会有累计误差,表现为角度会一致增加或者一直减少。 另一个常用的传感器是磁力计/地磁场传感器,它是以地球磁场作为探测的,俗称电子罗盘。当加速度传感器完全水平的时候,重力传感器无法分辨出在水平面旋转的角度,此时就只有陀螺仪可以检测。基本上现有的惯导传感器就是通过这三个传感器的相互校正,并终于可以在大的理论上得到比较准确的姿态参数。</p><h4 id="_3-2-惯导分类" tabindex="-1">3.2 惯导分类 <a class="header-anchor" href="#_3-2-惯导分类" aria-label="Permalink to &quot;3.2 惯导分类&quot;">​</a></h4><p>惯性导航系统根据陀螺仪的不同,可分为机电(包含液浮、气浮、静电、挠性等种类)陀螺仪、光学(包含激光、光纤等种类)陀螺仪、微机械(MEMS)陀螺仪等类型的惯性导航系统。这是主流惯性导航工具不断迭代的进展。目前来说,主流的惯性导航传感器又被分为平台式惯性导航系统和捷联式惯性导航系统。</p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/ros/slam/20231121141419.png" alt=""></p><p>平台式惯性导航将陀螺仪和加速度等惯性元件通过万向支架角运动,采用物理平台模拟导航坐标系统,稳定平台由陀螺仪控制,使平台始终跟踪要求的导航坐标系。 捷联式惯导则是采用数学算法确定出导航坐标系,即将加速度计和陀螺仪直接安装在运载体上,陀螺仪输出用来计算运载体相对导航坐标系的姿态变化,加速度计输出经姿态变化至导航坐标系内。</p><h4 id="_3-3-参数解读" tabindex="-1">3.3 参数解读 <a class="header-anchor" href="#_3-3-参数解读" aria-label="Permalink to &quot;3.3 参数解读&quot;">​</a></h4><p>对于惯性导航而言,人们发现惯性导航中的相位噪声中不仅有白噪声,而且有闪烁噪声。其中白噪声是无规律的,且无法被预测的。而闪烁噪声人们则发现结果是无法通过标准差收敛的,为此David Allan于1966年提出了Allan方差分析,该方法不仅可以准确识别噪声类型,还能精确确定噪声的特性参数,其最大优点在于对各类噪声的幂律谱项都是收敛的。对于IMU标定而言,标定可以分为确定性误差和随机误差,确定性误差包括:交轴耦合误差(Axis-misalignment),比例因子误差(Scale Factor),零偏(Bias)。随机误差则主要是高斯白噪声和bias随机游走。Allen方差主要用于标定随机误差。</p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/ros/slam/20231121141553.png" alt=""></p><p>下面我们来看一下Allen每个误差的含义: 角度随机游走(Angular random walk,ARw)：利用Allan方差来计算,单位为/vh。工程上可以理解为衡量陀螺白噪声方差的一个量,二者有一定的换算关系。因为角速度的白噪声积分会使角度的误差中含有一节马尔科夫性质的误差。</p><p>零偏不稳定性(bias):bias会在运动的过程中逐渐变化,但是在一个较短的时间内是不变的.需要进行估计。 角速度随机游走(Rate Random Walk,RRW):利用Allan方差来计算,单位为/(h)^1.5.陀螺的角速率输出随着时间缓慢变化,通常由系统误差引起,比如环境温度的缓慢变化。可以用来衡量零偏的变化规律。</p><p>速率斜坡(Rate Ramp):利用Allan方差来计算,单位为/(h)2陀螺的角速率输出随着时间缓慢变化,通常由系统误差引起,比如环境温度的缓慢变化,可以通过严格的环境控制或引入补偿来降低此类误差。</p><h3 id="_4-轮速计" tabindex="-1">4. 轮速计 <a class="header-anchor" href="#_4-轮速计" aria-label="Permalink to &quot;4. 轮速计&quot;">​</a></h3><h4 id="_4-1-基本原理" tabindex="-1">4.1 基本原理 <a class="header-anchor" href="#_4-1-基本原理" aria-label="Permalink to &quot;4.1 基本原理&quot;">​</a></h4><p>轮速计本身的参数就是安装在机器人底盘启动电机轮子处的光电编码器,通过检测车轮在一定时间内移动的距离,从而推算出机器人相对位姿的变化。准确来说轮速信号的采集过程实际上可以看作是对轮子旋转件的测速过程,当旋转件转动一定幅度后会触发编码器,从而完成轮速计的计数。</p><h4 id="_4-2-分类" tabindex="-1">4.2 分类 <a class="header-anchor" href="#_4-2-分类" aria-label="Permalink to &quot;4.2 分类&quot;">​</a></h4><p>转速测量常用的光电式、电涡流式和电磁式等也曾应用于汽车轮速信号的测量。相比较而言,电磁式轮速传感器工作可靠,价格合适,受环境因素(如温度、灰尘等)的影响较小,基于以上优点,电磁式轮速传感器在轮速信号的采集中应用广泛。</p><p>电磁式轮速传感器大致分为电感式、霍尔式和磁阻式三种类型。其中,电感式轮速传感器是被动式轮速传感器,又称无源轮速传感器;相对应的,霍尔式和磁阻式轮速传感器是主动式轮速传感器,也称有源轮速传感器,有一个电源电路为传感器提供外部电压供电,在外部供电无法提供时,主动式轮速传感器将无轮速信号产生。下面我们来详细了解一下这三个传感器</p><h5 id="电感式轮速传感器" tabindex="-1">电感式轮速传感器 <a class="header-anchor" href="#电感式轮速传感器" aria-label="Permalink to &quot;电感式轮速传感器&quot;">​</a></h5><p>电感式轮速传感器是基于电磁感应原理来实现的,主要是利用电磁感应把被测对象的运动转化为线圈的自感系数和互感系数的变化,然后再由电路转化为电压或者电流的变化量输出,从而实现非电量向电量的转换</p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/ros/slam/20231121142440659.png" alt=""></p><h5 id="霍尔式轮速传感器" tabindex="-1">霍尔式轮速传感器 <a class="header-anchor" href="#霍尔式轮速传感器" aria-label="Permalink to &quot;霍尔式轮速传感器&quot;">​</a></h5><p>霍尔式轮速传感器基于霍尔效应,由霍尔组件结合电子元件组成,霍尔元件外加与电流方向垂直的磁场,在霍尔元件的两端会产生电势差,即霍尔电势差</p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/ros/slam/20231121142545.png" alt=""></p><h5 id="磁阻式轮速传感器" tabindex="-1">磁阻式轮速传感器 <a class="header-anchor" href="#磁阻式轮速传感器" aria-label="Permalink to &quot;磁阻式轮速传感器&quot;">​</a></h5><p>可变磁阻式轮速传感器基于磁阻效应,与霍尔效应类似的是,在磁阻效应元件上接通电流和通过磁场,这里的磁场与电流成角度a 设置,如下图所示,这样磁场耦合到磁阻效应元件(一般为铁磁材料制作的薄板,称之为韦斯磁畴)方向的磁通量的变化率发生变化,从而改变元件的电阻(系数)。</p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/ros/slam/20231121142924.png" alt=""></p><h3 id="_5-gnss" tabindex="-1">5. GNSS <a class="header-anchor" href="#_5-gnss" aria-label="Permalink to &quot;5. GNSS&quot;">​</a></h3><p>GNSS由GPS、全球导航卫星系统(GLONASs)、Galileo系统和北斗系统在内的多个卫星系统组成。这里我们以GPS为例概述一下GNSs.GPS可以为GPS接收器提供可以处理的卫星信号,GPS接收器根据这些接收到信号就可以估计位置、速度和时间。GPS卫星发射的信号是由基频为fo=10.23MHz的信号产生的。该信号的时间戳采用原子钟来计时,因此一天的误差只有10-13秒。L波段有两个载波信号,分别是L1和L2,都是由基频信号与整数相乘生成的。载波信号L1和L2通过编码来进行双相位调制,向接收端提供时钟数据的同时,会传输诸如轨道参数等卫星信息。这些编码是由一个个状态为+1或-1的序列组成,分别对应二进制的0和1。当编码状态发生改变时,通过将载波相位进行180o偏移来实现双相位调制。卫星信号包含卫星轨道、轨道扰动、GPS时间、卫星时钟、电离层参数和系统状态等信息。</p><p>除了传统的GPS这类精度在米级的定位系统以外,近年来随着自动驾驶的发展RTK(Real-time kinematic)也被机器人广泛应用,RTK称为实时动态差分法,又称为载波相位差分技术,是实时处理两个测量站载波相位观测量的差分方法。RTK工作模式下,少存在三个基准街站(GNSS接收机),同时基准站和机器人之间的距离并没有超过通信范围。此时可以根据三个基准站接收到的测量数据进行计算得出差分数据,然后将差分数据发送给机器人,并经过坐标系转换,最终得出我们所需要的坐标数据。</p><p>RTK的基本思想是减少或消除基站和移动探测站端的公有误差,如下图所示。RTK GNSS通过减少卫星时钟误差、轨道偏移、电离层延迟和对流层延迟来提高精度。图中展示了RTK-GNSS的基本工作思路。减小这些GNSS误差项的一个有效方法是在一个位置已知的基站上安装一个GNSS接收器。基站上的接收器根据卫星数据计算其位置,并将该位置与已知的实际位置进行比较,并计算出误差偏移量。计算出的误差偏移量通过基站传递到移动端。</p><h2 id="slam数据集使用" tabindex="-1">Slam数据集使用 <a class="header-anchor" href="#slam数据集使用" aria-label="Permalink to &quot;Slam数据集使用&quot;">​</a></h2><h3 id="_1-m2dgr" tabindex="-1">1. M2DGR <a class="header-anchor" href="#_1-m2dgr" aria-label="Permalink to &quot;1. M2DGR&quot;">​</a></h3><p>M2DGR是由上海交大采针对地面机器人导航采集的sLAM数据集,包含了环视RGB相机、红外相机、事件相机、32线激光雷达、IMU与原始GNSS信息,覆盖了室内外具有挑战性的场景,给当前的SLAM算法带来了很大的挑战性。</p><p>项目主页位于：<a href="https://github.com/SJTU-ViSYS/M2DGR%E3%80%82" target="_blank" rel="noreferrer">https://github.com/SJTU-ViSYS/M2DGR。</a></p><p>论文位于：<a href="https://github.com/SJTU-ViSYS/M2DGR/blob/main/main.pdf" target="_blank" rel="noreferrer">https://github.com/SJTU-ViSYS/M2DGR/blob/main/main.pdf</a>.</p><p>主要贡献有:</p><ol><li>为室内和室外的地面机器人收集了长期具有挑战性的序列,并拥有一个完整的传感器套件,其中包括6个环视鱼眼摄像机、一个指向天空的鱼眼摄像机、一个透视彩色摄像机、一个事件摄像机、一个红外摄像机、一个32束激光雷达、两个GNSS接收器和两个imu。这是首个拥有如此丰富的传感器信息的专注于地面机器人导航的SLAM数据集。</li><li>记录了一些具有挑战性的情况下的轨迹,如电梯、完全黑暗,这些情况很容易导致现有的定位解决方案失败。这些情况在地面机器人应用中是很常见的,但在以前的数据集中很少讨论。</li><li>启动地面机器人导航的benchmark。在这个基准上评估了现有的各种设计的最先进的SLAM算法,并分别分析了它们的特点和缺陷。</li></ol><p>作者搭建了一个三层的地面机器人,如图所示</p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/ros/slam/20231121143934.png" alt=""></p><p>传感器的具体型号和参数如下表所示</p><p><img src="https://cdn.jsdelivr.net/gh/clint-sfy/blogcdn@master/ros/slam/20231121144357.png" alt=""></p><p>真值的格式为TUM格式,即#timestamp(s) x ty tz qx qy zqw</p><p>所有的数据格式均为rosbag,包括以下topic:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code"><code><span class="line"><span></span></span></code></pre></div><p>序列总共包含street、circle、gate等九种不同场景的环境,其中难度较大的包括street(时间长、环境复杂,且在室外的远特征不利于视觉SLAM算法进行深度估计)、Door(室内外交替场景,对于GNSS方法具有挑战性)、lift(小车通过电梯从一楼运动到二楼)、roomdark(完全黑暗的房间)。论文里对主流的sOTA算法进行了评估,绝对轨迹误差的RMSE结果如下表所示。</p><h3 id="_2-kitti" tabindex="-1">2. Kitti <a class="header-anchor" href="#_2-kitti" aria-label="Permalink to &quot;2. Kitti&quot;">​</a></h3><p>KITTI数据集由德国卡尔斯鲁厄理工学院和丰田美国技术研究院联合创办,是目前国际上最大的自动驾驶场景下的计算机视觉算法评测数据集之一。该数据集用于评测立体图像(stereo),光流(optical flow),视觉测距(visual odometry),3D物体检测(objectdetection)和3D跟踪(tracking)等计算机视觉技术在车载环境下的性能。KITTI包含市区、乡村和高速公路等场景采集的真实图像数据,每张图像中最多达15辆车和30个行人,还有各种程度的遮挡与截断。 论文地址为：<a href="https://www.mrt.kit.edu/z/publ/download/2013/GeigerAI2013JRR.pdf" target="_blank" rel="noreferrer">https://www.mrt.kit.edu/z/publ/download/2013/GeigerAI2013JRR.pdf</a></p><p>官网链接为：<a href="https://www.cvlibs.net/datasets/kitti/eval_odometry.php" target="_blank" rel="noreferrer">https://www.cvlibs.net/datasets/kitti/eval_odometry.php</a>,</p><p>可以选择odometry并下载原始数据</p><p>主要适用范围:评估自动驾驶场景下的纯激光SLAM算法、激光+视觉的算法</p><p>KITTI数据集的数据采集平台装配有2个灰度摄像机,2个彩色摄像机,一个Velodyne 64线3D激光雷达,4个光学镜头,以及1个GPS导航系统。</p><h3 id="_3-euroc" tabindex="-1">3. Euroc <a class="header-anchor" href="#_3-euroc" aria-label="Permalink to &quot;3. Euroc&quot;">​</a></h3><p>EuRoC是一个微型无人机(MAV)上收集的视觉惯性数据集官网为<a href="https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets" target="_blank" rel="noreferrer">https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets</a> 论文为<a href="https://www.researchgate.net/profile/Michael-Burri/publication/291954561_The_EuRoC_micro_aerial_vehicle_datasets/links/56afOc6008ae19a38516937c/The-EuRoC-micro-aerial-vehicle-datasets.pdf" target="_blank" rel="noreferrer">https://www.researchgate.net/profile/Michael-Burri/publication/291954561_The_EuRoC_micro_aerial_vehicle_datasets/links/56afOc6008ae19a38516937c/The-EuRoC-micro-aerial-vehicle-datasets.pdf</a></p><h3 id="_4-slam精度评估" tabindex="-1">4. slam精度评估 <a class="header-anchor" href="#_4-slam精度评估" aria-label="Permalink to &quot;4. slam精度评估&quot;">​</a></h3><p>SLAM精度的评估有两个最重要的指标,即绝对轨迹误差(ATE)和相对位姿误差(RPE)的均方根误差(RMSE):绝对轨迹误差:直接计算相机位姿的真实值与SLAM系统的估计值之间的差值,首先将真实值与估计值的时间戳对齐,然后计算每对位姿之间的差值,适合于评估SLAM系统的性能。 相对位姿误差:用于计算两个相同时间戳上相机位姿的真实值与SLAM算法的估计值之间每隔一段时间位姿变化量之间的差值,也可以理解为位姿真实值与与估计值的实时比较。该标准适合于估计系统的漂移。</p><p>evo是一款用于视觉里程计和slam问题的轨迹评估工具。核心功能是能够绘制相机的轨迹,或评估估计轨迹与真值的误差。支持多种数据集的轨迹格式(TUM、KITTI、EuRoC MAV、ROS的bag),同时支持这些数据格式之间进行相互转换。在此仅对其基本功能做简要介绍。</p><p>该工具目前被托管在github上了,其项目地址为<a href="https://github.com/MichaelGrupp/evo%E3%80%82%E4%BD%9C%E8%80%85%E6%8F%90%E4%BE%9B%E4%BA%86%E4%B8%A4%E7%A7%8D%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95%E3%80%82%E6%8E%A8%E8%8D%90%E4%BD%BF%E7%94%A8pip%E5%B7%A5%E5%85%B7%E8%BF%9B%E8%A1%8C%E5%AE%89%E8%A3%85,%E5%8F%AA%E9%9C%80%E8%A6%81%E4%B8%80%E8%A1%8C%E4%BB%A3%E7%A0%81%E5%8D%B3%E5%8F%AF,%E5%B0%86%E5%A6%82%E4%B8%8B%E4%BB%A3%E7%A0%81%E5%A4%8D%E5%88%B6%E5%88%B0%E4%BD%A0%E7%9A%84%E7%BB%88%E7%AB%AF%E4%B8%AD%E8%BF%90%E8%A1%8C" target="_blank" rel="noreferrer">https://github.com/MichaelGrupp/evo。作者提供了两种安装方法。推荐使用pip工具进行安装,只需要一行代码即可,将如下代码复制到你的终端中运行</a></p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark-dimmed vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#F69D50;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> evo</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> --upgrade</span><span style="--shiki-light:#005CC5;--shiki-dark:#6CB6FF;"> --no-binary</span><span style="--shiki-light:#032F62;--shiki-dark:#96D0FF;"> evo</span></span></code></pre></div><p>evo工具主要有如下六个命令: evo_ape-用于评估绝对轨迹误教; evo_rpe-用于评估相对位姿误差; evo_traj-这个主要是用来画轨迹、输出轨迹文件、转换数据格式等功能;</p><p>evo_config-这个主要用于evo工具全局设置和配置文件操作;</p><p>evo_res-比较来自evo_ape或evo_rpe生成的一个或多个结果文件的工具;</p><p>evo_fig-(实验)工具,用于重新打开序列化图(使用-serialize_plot保存);</p>',123))])}const v=h(k,[["render",A]]);export{L as __pageData,v as default};
