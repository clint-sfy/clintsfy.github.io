<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>线性回归 | 阿源的知识库</title>
    <meta name="description" content="个人技术知识库，记录 & 分享个人碎片化、结构化、体系化的技术知识内容。">
    <link rel="preload stylesheet" href="/assets/style.d8880d86.css" as="style">
    
    <script type="module" src="/assets/app.5f6ab0f7.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.2ed14f66.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/framework.2aeb816e.js">
    <link rel="modulepreload" href="/assets/chunks/theme.a01badbe.js">
    <link rel="modulepreload" href="/assets/chunks/md5.772bbdf1.js">
    <link rel="modulepreload" href="/assets/chunks/use-popup-manager.3f657eb0.js">
    <link rel="modulepreload" href="/assets/chunks/virtual_mermaid-config.ade1a5ba.js">
    <link rel="modulepreload" href="/assets/chunks/ArticleMetadata.e10718d6.js">
    <link rel="modulepreload" href="/assets/courses_tangyudi_02-机器学习篇_01-线性回归.md.6dffb065.lean.js">
    <link rel="icon" href="/favicon.ico">
    <meta name="author" content="Charles7c">
    <meta name="keywords" content="查尔斯的知识库, 知识库, 博客, Charles7c">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="theme-color" content="#3c8772">
    <meta property="og:type" content="website">
    <meta property="og:locale" content="zh_CN">
    <meta property="og:title" content="阿源的知识库">
    <meta property="og:description" content="个人技术知识库，记录 &amp; 分享个人碎片化、结构化、体系化的技术知识内容。">
    <meta property="og:site" content="https://blog.clint-sfy.cn">
    <meta property="og:site_name" content="阿源的知识库">
    <meta property="og:image" content="https://blog.clint-sfy.cn/logo.jpg">
    <script id="check-dark-light">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-4fcb24f0><!--[--><!--]--><!--[--><span tabindex="-1" data-v-a5c1bab3></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-a5c1bab3> Skip to content </a><!--]--><!----><header class="VPNav" data-v-4fcb24f0 data-v-05a374fe><div class="VPNavBar has-sidebar" data-v-05a374fe data-v-a9879803><div class="container" data-v-a9879803><div class="title" data-v-a9879803><div class="VPNavBarTitle has-sidebar" data-v-a9879803 data-v-ac0e29ec><a class="title" href="/" data-v-ac0e29ec><!--[--><!--]--><!--[--><img class="VPImage logo" src="/logo.png" alt data-v-65c82d5d><!--]--><!--[-->阿源的知识库<!--]--><!--[--><!--]--></a></div></div><div class="content" data-v-a9879803><div class="curtain" data-v-a9879803></div><div class="content-body" data-v-a9879803><!--[--><!--]--><div class="VPNavBarSearch search" style="--vp-meta-key:&#39;Meta&#39;;" data-v-a9879803><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg class="DocSearch-Search-Icon" width="20" height="20" viewBox="0 0 20 20" aria-label="search icon"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜索文档</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-a9879803 data-v-7c687a88><span id="main-nav-aria-label" class="visually-hidden" data-v-7c687a88>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/introduction" tabindex="0" data-v-7c687a88 data-v-8ce6bdaf><!--[-->首页<!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/my_project/01-project/01-%E9%A1%B9%E7%9B%AE1/01-%E4%BB%8B%E7%BB%8D" tabindex="0" data-v-7c687a88 data-v-8ce6bdaf><!--[-->项目文档<!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-7c687a88 data-v-8c1da57f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-8c1da57f><span class="text" data-v-8c1da57f><!----> 前沿 &amp; 工作 <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-8c1da57f><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-8c1da57f><div class="VPMenu" data-v-8c1da57f data-v-aff3ecf7><div class="items" data-v-aff3ecf7><!--[--><!--[--><div class="VPMenuLink" data-v-aff3ecf7 data-v-b61fb414><a class="VPLink link" href="/categories/issues/index" data-v-b61fb414><!--[-->Bug万象集<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-aff3ecf7 data-v-b61fb414><a class="VPLink link" href="/categories/chatgpt/01-ChatGPT%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/01-GPT%E9%A1%B9%E7%9B%AE" data-v-b61fb414><!--[-->ChatGPT<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup active" data-v-7c687a88 data-v-8c1da57f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-8c1da57f><span class="text" data-v-8c1da57f><!----> 学习笔记 <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-8c1da57f><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-8c1da57f><div class="VPMenu" data-v-8c1da57f data-v-aff3ecf7><div class="items" data-v-aff3ecf7><!--[--><!--[--><div class="VPMenuLink" data-v-aff3ecf7 data-v-b61fb414><a class="VPLink link" href="/courses/c/index" data-v-b61fb414><!--[-->C语言基础快速入门<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-aff3ecf7 data-v-b61fb414><a class="VPLink link" href="/courses/c_plus/01-C++%E7%9A%84%E5%9F%BA%E7%A1%80/01-c++%E5%AF%B9c%E7%9A%84%E6%89%A9%E5%B1%95" data-v-b61fb414><!--[-->C++基础快速入门<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-aff3ecf7 data-v-b61fb414><a class="VPLink link" href="/courses/python/01-python%E5%9F%BA%E7%A1%80%E7%AF%87/01-python%E5%9F%BA%E7%A1%80" data-v-b61fb414><!--[-->Python基础快速入门<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-aff3ecf7 data-v-b61fb414><a class="VPLink link active" href="/courses/tangyudi/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87/01-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92" data-v-b61fb414><!--[-->唐宇迪AI课程<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-aff3ecf7 data-v-b61fb414><a class="VPLink link" href="/courses/yuanzi/03-QT%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E5%92%8C%E9%83%A8%E7%BD%B2/01-linux%E5%AE%89%E8%A3%85qt" data-v-b61fb414><!--[-->正点原子Linux课程<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/tags" tabindex="0" data-v-7c687a88 data-v-8ce6bdaf><!--[-->我的标签<!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-7c687a88 data-v-8c1da57f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-8c1da57f><span class="text" data-v-8c1da57f><!----> 关于 <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-8c1da57f><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-8c1da57f><div class="VPMenu" data-v-8c1da57f data-v-aff3ecf7><div class="items" data-v-aff3ecf7><!--[--><!--[--><div class="VPMenuLink" data-v-aff3ecf7 data-v-b61fb414><a class="VPLink link" href="/about/index" data-v-b61fb414><!--[-->关于知识库<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-aff3ecf7 data-v-b61fb414><a class="VPLink link" href="/about/me" data-v-b61fb414><!--[-->关于我<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-aff3ecf7 data-v-b61fb414><a class="VPLink link" href="/about/donate" data-v-b61fb414><!--[-->赞助<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-aff3ecf7 data-v-b61fb414><a class="VPLink link" href="/about/see" data-v-b61fb414><!--[-->在线体验<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-aff3ecf7 data-v-b61fb414><a class="VPLink link" href="/archives" data-v-b61fb414><!--[-->我的归档<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-a9879803 data-v-94372bba><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="toggle dark mode" aria-checked="false" data-v-94372bba data-v-e5b225bc data-v-6fc16645><span class="check" data-v-6fc16645><span class="icon" data-v-6fc16645><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-e5b225bc><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-e5b225bc><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-a9879803 data-v-c838d38e data-v-3624d9f6><!--[--><a class="VPSocialLink no-icon" href="https://github.com/clint-sfy" aria-label="github" target="_blank" rel="noopener" data-v-3624d9f6 data-v-d27e23fd><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a><a class="VPSocialLink no-icon" href="https://gitee.com/clint_sfy" aria-label target="_blank" rel="noopener" data-v-3624d9f6 data-v-d27e23fd><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>码云</title><path d="M11.984 0A12 12 0 0 0 0 12a12 12 0 0 0 12 12 12 12 0 0 0 12-12A12 12 0 0 0 12 0a12 12 0 0 0-.016 0zm6.09 5.333c.328 0 .593.266.592.593v1.482a.594.594 0 0 1-.593.592H9.777c-.982 0-1.778.796-1.778 1.778v5.63c0 .327.266.592.593.592h5.63c.982 0 1.778-.796 1.778-1.778v-.296a.593.593 0 0 0-.592-.593h-4.15a.592.592 0 0 1-.592-.592v-1.482a.593.593 0 0 1 .593-.592h6.815c.327 0 .593.265.593.592v3.408a4 4 0 0 1-4 4H5.926a.593.593 0 0 1-.593-.593V9.778a4.444 4.444 0 0 1 4.445-4.444h8.296Z"/></svg></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-a9879803 data-v-3e258995 data-v-8c1da57f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-8c1da57f><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-8c1da57f><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-8c1da57f><div class="VPMenu" data-v-8c1da57f data-v-aff3ecf7><!----><!--[--><!--[--><!----><div class="group" data-v-3e258995><div class="item appearance" data-v-3e258995><p class="label" data-v-3e258995>切换日光/暗黑模式</p><div class="appearance-action" data-v-3e258995><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="toggle dark mode" aria-checked="false" data-v-3e258995 data-v-e5b225bc data-v-6fc16645><span class="check" data-v-6fc16645><span class="icon" data-v-6fc16645><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-e5b225bc><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-e5b225bc><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><div class="group" data-v-3e258995><div class="item social-links" data-v-3e258995><div class="VPSocialLinks social-links-list" data-v-3e258995 data-v-3624d9f6><!--[--><a class="VPSocialLink no-icon" href="https://github.com/clint-sfy" aria-label="github" target="_blank" rel="noopener" data-v-3624d9f6 data-v-d27e23fd><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a><a class="VPSocialLink no-icon" href="https://gitee.com/clint_sfy" aria-label target="_blank" rel="noopener" data-v-3624d9f6 data-v-d27e23fd><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>码云</title><path d="M11.984 0A12 12 0 0 0 0 12a12 12 0 0 0 12 12 12 12 0 0 0 12-12A12 12 0 0 0 12 0a12 12 0 0 0-.016 0zm6.09 5.333c.328 0 .593.266.592.593v1.482a.594.594 0 0 1-.593.592H9.777c-.982 0-1.778.796-1.778 1.778v5.63c0 .327.266.592.593.592h5.63c.982 0 1.778-.796 1.778-1.778v-.296a.593.593 0 0 0-.592-.593h-4.15a.592.592 0 0 1-.592-.592v-1.482a.593.593 0 0 1 .593-.592h6.815c.327 0 .593.265.593.592v3.408a4 4 0 0 1-4 4H5.926a.593.593 0 0 1-.593-.593V9.778a4.444 4.444 0 0 1 4.445-4.444h8.296Z"/></svg></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-a9879803 data-v-7d88f313><span class="container" data-v-7d88f313><span class="top" data-v-7d88f313></span><span class="middle" data-v-7d88f313></span><span class="bottom" data-v-7d88f313></span></span></button></div></div></div></div><!----></header><div class="VPLocalNav reached-top" data-v-4fcb24f0 data-v-eb2e1b3c><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-eb2e1b3c><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="menu-icon" data-v-eb2e1b3c><path d="M17,11H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,11,17,11z"></path><path d="M21,7H3C2.4,7,2,6.6,2,6s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,7,21,7z"></path><path d="M21,15H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,15,21,15z"></path><path d="M17,19H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,19,17,19z"></path></svg><span class="menu-text" data-v-eb2e1b3c>文章</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-eb2e1b3c data-v-aaa51a79><button data-v-aaa51a79>返回顶部</button><!----></div></div><aside class="VPSidebar" data-v-4fcb24f0 data-v-b318eb5c><div class="curtain" data-v-b318eb5c></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-b318eb5c><span class="visually-hidden" id="sidebar-aria-label" data-v-b318eb5c> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="group" data-v-b318eb5c><section class="VPSidebarItem level-0 collapsible" data-v-b318eb5c data-v-791e5f86><div class="item" role="button" tabindex="0" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><h2 class="text" data-v-791e5f86>数学基础篇 (16篇)</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-791e5f86><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-791e5f86><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-791e5f86><!--[--><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/01-%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-red mr-[6px]" style="font-weight: 550; display: inline-block;">1</div>高等数学基础</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/02-%E5%BE%AE%E7%A7%AF%E5%88%86" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-orange mr-[6px]" style="font-weight: 550; display: inline-block;">2</div>微积分</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/03-%E6%B3%B0%E5%8B%92%E5%85%AC%E5%BC%8F%E5%92%8C%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-yellow mr-[6px]" style="font-weight: 550; display: inline-block;">3</div>泰勒公式和拉格朗日</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/04-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">4</div>线性代数基础</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/05-%E7%89%B9%E5%BE%81%E5%80%BC%E4%B8%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">5</div>特征值与矩阵分解</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/06-%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">6</div>随机变量</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/07-%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">7</div>概率论基础</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/08-%E5%87%A0%E7%A7%8D%E5%88%86%E5%B8%83" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">8</div>几种分布</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/09-%E6%A0%B8%E5%87%BD%E6%95%B0%E5%8F%98%E6%8D%A2" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">9</div>核函数变换</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/10-%E7%86%B5%E4%B8%8E%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">10</div>熵与激活函数</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/11-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">11</div>回归分析</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/12-%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">12</div>假设检验</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/13-%E7%9B%B8%E5%85%B3%E5%88%86%E6%9E%90" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">13</div>相关分析</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/14-%E6%96%B9%E5%B7%AE%E5%88%86%E6%9E%90" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">14</div>方差分析</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/15-%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">15</div>聚类分析</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/16-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E6%9E%90" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">16</div>贝叶斯分析</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-b318eb5c><section class="VPSidebarItem level-0 collapsible has-active" data-v-b318eb5c data-v-791e5f86><div class="item" role="button" tabindex="0" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><h2 class="text" data-v-791e5f86>机器学习篇 (12篇)</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-791e5f86><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-791e5f86><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-791e5f86><!--[--><div class="VPSidebarItem level-1 is-link is-active has-active" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87/01-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-red mr-[6px]" style="font-weight: 550; display: inline-block;">1</div>线性回归</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87/02-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-orange mr-[6px]" style="font-weight: 550; display: inline-block;">2</div>模型评估方法</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87/03-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-yellow mr-[6px]" style="font-weight: 550; display: inline-block;">3</div>逻辑回归</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87/04-%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">4</div>聚类算法</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87/05-%E5%86%B3%E7%AD%96%E6%A0%91" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">5</div>决策树</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87/06-%E9%9B%86%E6%88%90%E7%AE%97%E6%B3%95" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">6</div>集成算法</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87/07-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">7</div>支持向量机</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87/08-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">8</div>神经网络</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87/09-%E8%B4%9D%E5%8F%B6%E6%96%AF" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">9</div>贝叶斯</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87/10-%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">10</div>关联规则</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87/11-%E8%AF%8D%E5%90%91%E9%87%8F" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">11</div>词向量</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87/12-%E9%99%8D%E7%BB%B4" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">12</div>降维</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="group" data-v-b318eb5c><section class="VPSidebarItem level-0 collapsible collapsed" data-v-b318eb5c data-v-791e5f86><div class="item" role="button" tabindex="0" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><h2 class="text" data-v-791e5f86>深度学习篇 (4篇)</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-791e5f86><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="caret-icon" data-v-791e5f86><path d="M9,19c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l5.3-5.3L8.3,6.7c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l6,6c0.4,0.4,0.4,1,0,1.4l-6,6C9.5,18.9,9.3,19,9,19z"></path></svg></div></div><div class="items" data-v-791e5f86><!--[--><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/03-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AF%87/01-Pytorch" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-red mr-[6px]" style="font-weight: 550; display: inline-block;">1</div>Pytorch</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/03-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AF%87/02-MMLAB%E5%AE%9E%E6%88%98" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-orange mr-[6px]" style="font-weight: 550; display: inline-block;">2</div>MMLAB</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/03-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AF%87/03-OpenCV" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-yellow mr-[6px]" style="font-weight: 550; display: inline-block;">3</div>OpenCV</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-791e5f86 data-v-791e5f86><div class="item" data-v-791e5f86><div class="indicator" data-v-791e5f86></div><a class="VPLink link link" href="/courses/tangyudi/03-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AF%87/04-YOLO" data-v-791e5f86><!--[--><p class="text" data-v-791e5f86><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">4</div>YOLO</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-4fcb24f0 data-v-0dcf1054><div class="VPDoc has-sidebar has-aside" data-v-0dcf1054 data-v-48b5bc29><!--[--><!--]--><div class="container" data-v-48b5bc29><div class="aside" data-v-48b5bc29><div class="aside-curtain" data-v-48b5bc29></div><div class="aside-container" data-v-48b5bc29><div class="aside-content" data-v-48b5bc29><div class="VPDocAside" data-v-48b5bc29 data-v-b311d026><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" data-v-b311d026 data-v-1498c68b><div class="content" data-v-1498c68b><div class="outline-marker" data-v-1498c68b></div><div class="outline-title" data-v-1498c68b>目录</div><nav aria-labelledby="doc-outline-aria-label" data-v-1498c68b><span class="visually-hidden" id="doc-outline-aria-label" data-v-1498c68b> Table of Contents for current page </span><ul class="root" data-v-1498c68b data-v-0170c45a><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-b311d026></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-48b5bc29><div class="content-container" data-v-48b5bc29><!--[--><!--]--><!----><main class="main" data-v-48b5bc29><div style="position:relative;" class="vp-doc _courses_tangyudi_02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87_01-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92" data-v-48b5bc29><div><h1 id="线性回归" tabindex="-1">线性回归 <a class="header-anchor" href="#线性回归" aria-label="Permalink to &quot;线性回归&quot;">​</a></h1><!----><h2 id="_1-线性回归原理推导" tabindex="-1">1. 线性回归原理推导 <a class="header-anchor" href="#_1-线性回归原理推导" aria-label="Permalink to &quot;1. 线性回归原理推导&quot;">​</a></h2><p><img src="https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/ML/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%921.png" alt=""></p><h2 id="_2-线性回归代码实现" tabindex="-1">2. 线性回归代码实现 <a class="header-anchor" href="#_2-线性回归代码实现" aria-label="Permalink to &quot;2. 线性回归代码实现&quot;">​</a></h2><h3 id="通用代码" tabindex="-1">通用代码 <a class="header-anchor" href="#通用代码" aria-label="Permalink to &quot;通用代码&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> numpy </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> np</span></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> utils.features </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> prepare_for_training</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">class</span><span style="color:#ADBAC7;"> </span><span style="color:#F69D50;">LinearRegression</span><span style="color:#ADBAC7;">:</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">__init__</span><span style="color:#ADBAC7;">(self,data,labels,polynomial_degree </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,sinusoid_degree </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,normalize_data</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">True</span><span style="color:#ADBAC7;">):</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#96D0FF;">        1.对数据进行预处理操作</span></span>
<span class="line"><span style="color:#96D0FF;">        2.先得到所有的特征个数</span></span>
<span class="line"><span style="color:#96D0FF;">        3.初始化参数矩阵</span></span>
<span class="line"><span style="color:#96D0FF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#ADBAC7;">        (data_processed,</span></span>
<span class="line"><span style="color:#ADBAC7;">         features_mean, </span></span>
<span class="line"><span style="color:#ADBAC7;">         features_deviation) </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> prepare_for_training(data, polynomial_degree, sinusoid_degree,</span><span style="color:#F69D50;">normalize_data</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">True</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#768390;"># print(data_processed)</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> data_processed  </span><span style="color:#768390;"># 预处理完的数据</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.labels </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> labels  </span><span style="color:#768390;"># 标签</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.features_mean </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> features_mean  </span><span style="color:#768390;">#</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.features_deviation </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> features_deviation</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.polynomial_degree </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> polynomial_degree</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.sinusoid_degree </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> sinusoid_degree</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.normalize_data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> normalize_data</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span></span>
<span class="line"><span style="color:#ADBAC7;">        num_features </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.data.shape[</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.zeros((num_features,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#768390;"># train(学习率  迭代次数)</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">train</span><span style="color:#ADBAC7;">(self,alpha,num_iterations </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">500</span><span style="color:#ADBAC7;">):</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#96D0FF;">                    训练模块，执行梯度下降</span></span>
<span class="line"><span style="color:#96D0FF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#ADBAC7;">        cost_history </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.gradient_descent(alpha,num_iterations)</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">return</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.theta,cost_history</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#768390;"># 实现小批量梯度下降法</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">gradient_descent</span><span style="color:#ADBAC7;">(self,alpha,num_iterations):</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#96D0FF;">                    实际迭代模块，会迭代num_iterations次</span></span>
<span class="line"><span style="color:#96D0FF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#ADBAC7;">        cost_history </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> []</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> _ </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(num_iterations):</span></span>
<span class="line"><span style="color:#ADBAC7;">            </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.gradient_step(alpha)</span></span>
<span class="line"><span style="color:#ADBAC7;">            cost_history.append(</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.cost_function(</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.data,</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.labels))</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">return</span><span style="color:#ADBAC7;"> cost_history</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#768390;"># 实现小批量梯度下降法 具体步骤</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">gradient_step</span><span style="color:#ADBAC7;">(self,alpha):    </span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#96D0FF;">                    梯度下降参数更新计算方法，注意是矩阵运算</span></span>
<span class="line"><span style="color:#96D0FF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#768390;"># 样本的个数</span></span>
<span class="line"><span style="color:#ADBAC7;">        num_examples </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.data.shape[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#768390;"># 预测值 predictions = np.dot(data,theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">        prediction </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression.hypothesis(</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.data,</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#768390;"># 残差 = 预测值 - 真实值</span></span>
<span class="line"><span style="color:#ADBAC7;">        delta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> prediction </span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.labels</span></span>
<span class="line"><span style="color:#ADBAC7;">        theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.theta</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#768390;"># 更新theta 小批量梯度下降法</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#768390;"># 公式直接带进去</span></span>
<span class="line"><span style="color:#ADBAC7;">        theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> theta </span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;"> alpha</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">(</span><span style="color:#6CB6FF;">1</span><span style="color:#F47067;">/</span><span style="color:#ADBAC7;">num_examples)</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">(np.dot(delta.T,</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.data)).T</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> theta</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">cost_function</span><span style="color:#ADBAC7;">(self,data,labels):</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#96D0FF;">                    损失计算方法</span></span>
<span class="line"><span style="color:#96D0FF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#768390;"># 该函数会计算模型预测值和实际值之间的平均误差的平方和，然后将其除以样本数量得到平均误差值作为损失值。</span></span>
<span class="line"><span style="color:#ADBAC7;">        num_examples </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> data.shape[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">        delta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression.hypothesis(</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.data,</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.theta) </span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;"> labels</span></span>
<span class="line"><span style="color:#ADBAC7;">        cost </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> (</span><span style="color:#6CB6FF;">1</span><span style="color:#F47067;">/</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">)</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">np.dot(delta.T,delta)</span><span style="color:#F47067;">/</span><span style="color:#ADBAC7;">num_examples</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">return</span><span style="color:#ADBAC7;"> cost[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">][</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#DCBDFB;">@</span><span style="color:#6CB6FF;">staticmethod</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">hypothesis</span><span style="color:#ADBAC7;">(data,theta):   </span></span>
<span class="line"><span style="color:#ADBAC7;">        predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.dot(data,theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">return</span><span style="color:#ADBAC7;"> predictions</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#768390;"># 得到当前的损失</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">get_cost</span><span style="color:#ADBAC7;">(self,data,labels):  </span></span>
<span class="line"><span style="color:#ADBAC7;">        data_processed </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> prepare_for_training(data,</span></span>
<span class="line"><span style="color:#ADBAC7;">         </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.polynomial_degree,</span></span>
<span class="line"><span style="color:#ADBAC7;">         </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.sinusoid_degree,</span></span>
<span class="line"><span style="color:#ADBAC7;">         </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.normalize_data</span></span>
<span class="line"><span style="color:#ADBAC7;">         )[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">return</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.cost_function(data_processed,labels)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">predict</span><span style="color:#ADBAC7;">(self,data):</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#96D0FF;">                    用训练的参数模型，与预测得到回归值结果</span></span>
<span class="line"><span style="color:#96D0FF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#ADBAC7;">        data_processed </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> prepare_for_training(data,</span></span>
<span class="line"><span style="color:#ADBAC7;">         </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.polynomial_degree,</span></span>
<span class="line"><span style="color:#ADBAC7;">         </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.sinusoid_degree,</span></span>
<span class="line"><span style="color:#ADBAC7;">         </span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.normalize_data</span></span>
<span class="line"><span style="color:#ADBAC7;">         )[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">         </span></span>
<span class="line"><span style="color:#ADBAC7;">        predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression.hypothesis(data_processed,</span><span style="color:#6CB6FF;">self</span><span style="color:#ADBAC7;">.theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">return</span><span style="color:#ADBAC7;"> predictions</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> numpy </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> np</span></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> utils.features </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> prepare_for_training</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">LinearRegression</span><span style="color:#24292E;">:</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">(self,data,labels,polynomial_degree </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,sinusoid_degree </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,normalize_data</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">        1.对数据进行预处理操作</span></span>
<span class="line"><span style="color:#032F62;">        2.先得到所有的特征个数</span></span>
<span class="line"><span style="color:#032F62;">        3.初始化参数矩阵</span></span>
<span class="line"><span style="color:#032F62;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">        (data_processed,</span></span>
<span class="line"><span style="color:#24292E;">         features_mean, </span></span>
<span class="line"><span style="color:#24292E;">         features_deviation) </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> prepare_for_training(data, polynomial_degree, sinusoid_degree,</span><span style="color:#E36209;">normalize_data</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># print(data_processed)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data_processed  </span><span style="color:#6A737D;"># 预处理完的数据</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.labels </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> labels  </span><span style="color:#6A737D;"># 标签</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.features_mean </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> features_mean  </span><span style="color:#6A737D;">#</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.features_deviation </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> features_deviation</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.polynomial_degree </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> polynomial_degree</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.sinusoid_degree </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> sinusoid_degree</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.normalize_data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> normalize_data</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"><span style="color:#24292E;">        num_features </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data.shape[</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.zeros((num_features,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># train(学习率  迭代次数)</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">train</span><span style="color:#24292E;">(self,alpha,num_iterations </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">500</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">                    训练模块，执行梯度下降</span></span>
<span class="line"><span style="color:#032F62;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">        cost_history </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.gradient_descent(alpha,num_iterations)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.theta,cost_history</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 实现小批量梯度下降法</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">gradient_descent</span><span style="color:#24292E;">(self,alpha,num_iterations):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">                    实际迭代模块，会迭代num_iterations次</span></span>
<span class="line"><span style="color:#032F62;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">        cost_history </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> []</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> _ </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(num_iterations):</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.gradient_step(alpha)</span></span>
<span class="line"><span style="color:#24292E;">            cost_history.append(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.cost_function(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data,</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.labels))</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> cost_history</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 实现小批量梯度下降法 具体步骤</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">gradient_step</span><span style="color:#24292E;">(self,alpha):    </span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">                    梯度下降参数更新计算方法，注意是矩阵运算</span></span>
<span class="line"><span style="color:#032F62;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 样本的个数</span></span>
<span class="line"><span style="color:#24292E;">        num_examples </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data.shape[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 预测值 predictions = np.dot(data,theta)</span></span>
<span class="line"><span style="color:#24292E;">        prediction </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression.hypothesis(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data,</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.theta)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 残差 = 预测值 - 真实值</span></span>
<span class="line"><span style="color:#24292E;">        delta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> prediction </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.labels</span></span>
<span class="line"><span style="color:#24292E;">        theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.theta</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 更新theta 小批量梯度下降法</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 公式直接带进去</span></span>
<span class="line"><span style="color:#24292E;">        theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> theta </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> alpha</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">1</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">num_examples)</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">(np.dot(delta.T,</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data)).T</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> theta</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">cost_function</span><span style="color:#24292E;">(self,data,labels):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">                    损失计算方法</span></span>
<span class="line"><span style="color:#032F62;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 该函数会计算模型预测值和实际值之间的平均误差的平方和，然后将其除以样本数量得到平均误差值作为损失值。</span></span>
<span class="line"><span style="color:#24292E;">        num_examples </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data.shape[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">        delta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression.hypothesis(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data,</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.theta) </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> labels</span></span>
<span class="line"><span style="color:#24292E;">        cost </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> (</span><span style="color:#005CC5;">1</span><span style="color:#D73A49;">/</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">)</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">np.dot(delta.T,delta)</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">num_examples</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> cost[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">][</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6F42C1;">@</span><span style="color:#005CC5;">staticmethod</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">hypothesis</span><span style="color:#24292E;">(data,theta):   </span></span>
<span class="line"><span style="color:#24292E;">        predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.dot(data,theta)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> predictions</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 得到当前的损失</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">get_cost</span><span style="color:#24292E;">(self,data,labels):  </span></span>
<span class="line"><span style="color:#24292E;">        data_processed </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> prepare_for_training(data,</span></span>
<span class="line"><span style="color:#24292E;">         </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.polynomial_degree,</span></span>
<span class="line"><span style="color:#24292E;">         </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.sinusoid_degree,</span></span>
<span class="line"><span style="color:#24292E;">         </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.normalize_data</span></span>
<span class="line"><span style="color:#24292E;">         )[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.cost_function(data_processed,labels)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">predict</span><span style="color:#24292E;">(self,data):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">                    用训练的参数模型，与预测得到回归值结果</span></span>
<span class="line"><span style="color:#032F62;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">        data_processed </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> prepare_for_training(data,</span></span>
<span class="line"><span style="color:#24292E;">         </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.polynomial_degree,</span></span>
<span class="line"><span style="color:#24292E;">         </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.sinusoid_degree,</span></span>
<span class="line"><span style="color:#24292E;">         </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.normalize_data</span></span>
<span class="line"><span style="color:#24292E;">         )[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">         </span></span>
<span class="line"><span style="color:#24292E;">        predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression.hypothesis(data_processed,</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.theta)</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> predictions</span></span></code></pre></div><h3 id="线性回归-1" tabindex="-1">线性回归 <a class="header-anchor" href="#线性回归-1" aria-label="Permalink to &quot;线性回归&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> numpy </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> np</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> pandas </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> pd</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> matplotlib.pyplot </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> linear_regression </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> LinearRegression</span></span>
<span class="line"></span>
<span class="line"><span style="color:#768390;"># 根据gdp 去预测幸福指数</span></span>
<span class="line"><span style="color:#ADBAC7;">data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> pd.read_csv(</span><span style="color:#96D0FF;">&#39;../data/world-happiness-report-2017.csv&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#768390;"># 得到训练和测试数据</span></span>
<span class="line"><span style="color:#ADBAC7;">train_data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> data.sample(</span><span style="color:#F69D50;">frac</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.8</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">test_data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> data.drop(train_data.index)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">input_param_name </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;Economy..GDP.per.Capita.&#39;</span></span>
<span class="line"><span style="color:#ADBAC7;">output_param_name </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;Happiness.Score&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#768390;"># 这里要注意！传数组进去！二维矩阵</span></span>
<span class="line"><span style="color:#ADBAC7;">x_train </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> train_data[[input_param_name]].values</span></span>
<span class="line"><span style="color:#ADBAC7;">y_train </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> train_data[[output_param_name]].values</span></span>
<span class="line"></span>
<span class="line"><span style="color:#768390;"># 这里是一维的</span></span>
<span class="line"><span style="color:#ADBAC7;">x_test </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> test_data[input_param_name].values</span></span>
<span class="line"><span style="color:#ADBAC7;">y_test </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> test_data[output_param_name].values</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.scatter(x_train,y_train,</span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;Train data&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.scatter(x_test,y_test,</span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;test data&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.xlabel(input_param_name)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.ylabel(output_param_name)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.title(</span><span style="color:#96D0FF;">&#39;Happy&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.legend()</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#768390;"># 开始训练回归模型</span></span>
<span class="line"><span style="color:#ADBAC7;">num_iterations </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">500</span></span>
<span class="line"><span style="color:#ADBAC7;">learning_rate </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.01</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">linear_regression </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression(x_train,y_train)</span></span>
<span class="line"><span style="color:#ADBAC7;">(theta,cost_history) </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> linear_regression.train(learning_rate,num_iterations)</span></span>
<span class="line"><span style="color:#768390;"># cost_history 是一个损失函数的列表</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (</span><span style="color:#96D0FF;">&#39;开始时的损失：&#39;</span><span style="color:#ADBAC7;">,cost_history[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (</span><span style="color:#96D0FF;">&#39;训练后的损失：&#39;</span><span style="color:#ADBAC7;">,cost_history[</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(</span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(num_iterations),cost_history)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.xlabel(</span><span style="color:#96D0FF;">&#39;Iter&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.ylabel(</span><span style="color:#96D0FF;">&#39;cost&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.title(</span><span style="color:#96D0FF;">&#39;GD&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">predictions_num </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">100</span></span>
<span class="line"><span style="color:#768390;"># 生成一个指定间隔序列 记得要变成一个二维数组 （，100）-&gt;（100,1）</span></span>
<span class="line"><span style="color:#ADBAC7;">x_predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.linspace(x_train.min(),x_train.max(),predictions_num).reshape(predictions_num,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">y_predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> linear_regression.predict(x_predictions)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.scatter(x_train,y_train,</span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;Train data&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.scatter(x_test,y_test,</span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;test data&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(x_predictions,y_predictions,</span><span style="color:#96D0FF;">&#39;r&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">label</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;Prediction&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.xlabel(input_param_name)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.ylabel(output_param_name)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.title(</span><span style="color:#96D0FF;">&#39;Happy&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.legend()</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> numpy </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> np</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> pandas </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> pd</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> matplotlib.pyplot </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> linear_regression </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> LinearRegression</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 根据gdp 去预测幸福指数</span></span>
<span class="line"><span style="color:#24292E;">data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> pd.read_csv(</span><span style="color:#032F62;">&#39;../data/world-happiness-report-2017.csv&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 得到训练和测试数据</span></span>
<span class="line"><span style="color:#24292E;">train_data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data.sample(</span><span style="color:#E36209;">frac</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.8</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">test_data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data.drop(train_data.index)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">input_param_name </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;Economy..GDP.per.Capita.&#39;</span></span>
<span class="line"><span style="color:#24292E;">output_param_name </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;Happiness.Score&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 这里要注意！传数组进去！二维矩阵</span></span>
<span class="line"><span style="color:#24292E;">x_train </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> train_data[[input_param_name]].values</span></span>
<span class="line"><span style="color:#24292E;">y_train </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> train_data[[output_param_name]].values</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 这里是一维的</span></span>
<span class="line"><span style="color:#24292E;">x_test </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> test_data[input_param_name].values</span></span>
<span class="line"><span style="color:#24292E;">y_test </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> test_data[output_param_name].values</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.scatter(x_train,y_train,</span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Train data&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.scatter(x_test,y_test,</span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;test data&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.xlabel(input_param_name)</span></span>
<span class="line"><span style="color:#24292E;">plt.ylabel(output_param_name)</span></span>
<span class="line"><span style="color:#24292E;">plt.title(</span><span style="color:#032F62;">&#39;Happy&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.legend()</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 开始训练回归模型</span></span>
<span class="line"><span style="color:#24292E;">num_iterations </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">500</span></span>
<span class="line"><span style="color:#24292E;">learning_rate </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.01</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">linear_regression </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression(x_train,y_train)</span></span>
<span class="line"><span style="color:#24292E;">(theta,cost_history) </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> linear_regression.train(learning_rate,num_iterations)</span></span>
<span class="line"><span style="color:#6A737D;"># cost_history 是一个损失函数的列表</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (</span><span style="color:#032F62;">&#39;开始时的损失：&#39;</span><span style="color:#24292E;">,cost_history[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (</span><span style="color:#032F62;">&#39;训练后的损失：&#39;</span><span style="color:#24292E;">,cost_history[</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.plot(</span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(num_iterations),cost_history)</span></span>
<span class="line"><span style="color:#24292E;">plt.xlabel(</span><span style="color:#032F62;">&#39;Iter&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.ylabel(</span><span style="color:#032F62;">&#39;cost&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.title(</span><span style="color:#032F62;">&#39;GD&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">predictions_num </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">100</span></span>
<span class="line"><span style="color:#6A737D;"># 生成一个指定间隔序列 记得要变成一个二维数组 （，100）-&gt;（100,1）</span></span>
<span class="line"><span style="color:#24292E;">x_predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.linspace(x_train.min(),x_train.max(),predictions_num).reshape(predictions_num,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">y_predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> linear_regression.predict(x_predictions)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.scatter(x_train,y_train,</span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Train data&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.scatter(x_test,y_test,</span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;test data&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(x_predictions,y_predictions,</span><span style="color:#032F62;">&#39;r&#39;</span><span style="color:#24292E;">,</span><span style="color:#E36209;">label</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;Prediction&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.xlabel(input_param_name)</span></span>
<span class="line"><span style="color:#24292E;">plt.ylabel(output_param_name)</span></span>
<span class="line"><span style="color:#24292E;">plt.title(</span><span style="color:#032F62;">&#39;Happy&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.legend()</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><h3 id="多特征回归模型" tabindex="-1">多特征回归模型 <a class="header-anchor" href="#多特征回归模型" aria-label="Permalink to &quot;多特征回归模型&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> numpy </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> np</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> pandas </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> pd</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> matplotlib.pyplot </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> plt</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> plotly</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> plotly.graph_objs </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> go</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plotly.offline.init_notebook_mode()</span></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> linear_regression </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> LinearRegression</span></span>
<span class="line"><span style="color:#768390;"># 多特征回归模型</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> pd.read_csv(</span><span style="color:#96D0FF;">&#39;../data/world-happiness-report-2017.csv&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">train_data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> data.sample(</span><span style="color:#F69D50;">frac</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">0.8</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">test_data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> data.drop(train_data.index)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">input_param_name_1 </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;Economy..GDP.per.Capita.&#39;</span></span>
<span class="line"><span style="color:#ADBAC7;">input_param_name_2 </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;Freedom&#39;</span></span>
<span class="line"><span style="color:#ADBAC7;">output_param_name </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;Happiness.Score&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x_train </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> train_data[[input_param_name_1, input_param_name_2]].values</span></span>
<span class="line"><span style="color:#ADBAC7;">y_train </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> train_data[[output_param_name]].values</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x_test </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> test_data[[input_param_name_1, input_param_name_2]].values</span></span>
<span class="line"><span style="color:#ADBAC7;">y_test </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> test_data[[output_param_name]].values</span></span>
<span class="line"></span>
<span class="line"><span style="color:#768390;"># Configure the plot with training dataset.</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_training_trace </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> go.Scatter3d(</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">x</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">x_train[:, </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">].flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">y</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">x_train[:, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">].flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">z</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">y_train.flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">name</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;Training Set&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">mode</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;markers&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">marker</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">{</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;size&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;opacity&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;line&#39;</span><span style="color:#ADBAC7;">: {</span></span>
<span class="line"><span style="color:#ADBAC7;">            </span><span style="color:#96D0FF;">&#39;color&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#96D0FF;">&#39;rgb(255, 255, 255)&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">            </span><span style="color:#96D0FF;">&#39;width&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">1</span></span>
<span class="line"><span style="color:#ADBAC7;">        },</span></span>
<span class="line"><span style="color:#ADBAC7;">    }</span></span>
<span class="line"><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plot_test_trace </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> go.Scatter3d(</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">x</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">x_test[:, </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">].flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">y</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">x_test[:, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">].flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">z</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">y_test.flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">name</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;Test Set&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">mode</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;markers&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">marker</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">{</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;size&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;opacity&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;line&#39;</span><span style="color:#ADBAC7;">: {</span></span>
<span class="line"><span style="color:#ADBAC7;">            </span><span style="color:#96D0FF;">&#39;color&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#96D0FF;">&#39;rgb(255, 255, 255)&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">            </span><span style="color:#96D0FF;">&#39;width&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">1</span></span>
<span class="line"><span style="color:#ADBAC7;">        },</span></span>
<span class="line"><span style="color:#ADBAC7;">    }</span></span>
<span class="line"><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plot_layout </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> go.Layout(</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">title</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;Date Sets&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">scene</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">{</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;xaxis&#39;</span><span style="color:#ADBAC7;">: {</span><span style="color:#96D0FF;">&#39;title&#39;</span><span style="color:#ADBAC7;">: input_param_name_1},</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;yaxis&#39;</span><span style="color:#ADBAC7;">: {</span><span style="color:#96D0FF;">&#39;title&#39;</span><span style="color:#ADBAC7;">: input_param_name_2},</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;zaxis&#39;</span><span style="color:#ADBAC7;">: {</span><span style="color:#96D0FF;">&#39;title&#39;</span><span style="color:#ADBAC7;">: output_param_name} </span></span>
<span class="line"><span style="color:#ADBAC7;">    },</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">margin</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">{</span><span style="color:#96D0FF;">&#39;l&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">, </span><span style="color:#96D0FF;">&#39;r&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">, </span><span style="color:#96D0FF;">&#39;b&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">, </span><span style="color:#96D0FF;">&#39;t&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">}</span></span>
<span class="line"><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plot_data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [plot_training_trace, plot_test_trace]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plot_figure </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> go.Figure(</span><span style="color:#F69D50;">data</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">plot_data, </span><span style="color:#F69D50;">layout</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">plot_layout)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plotly.offline.plot(plot_figure) </span><span style="color:#768390;"># 如果要用jupter 改成plotly.offline.iplot</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">num_iterations </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">500</span><span style="color:#ADBAC7;">  </span></span>
<span class="line"><span style="color:#ADBAC7;">learning_rate </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.01</span><span style="color:#ADBAC7;">  </span></span>
<span class="line"><span style="color:#ADBAC7;">polynomial_degree </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">  </span></span>
<span class="line"><span style="color:#ADBAC7;">sinusoid_degree </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">  </span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">linear_regression </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression(x_train, y_train, polynomial_degree, sinusoid_degree)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">(theta, cost_history) </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> linear_regression.train(</span></span>
<span class="line"><span style="color:#ADBAC7;">    learning_rate,</span></span>
<span class="line"><span style="color:#ADBAC7;">    num_iterations</span></span>
<span class="line"><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;">(</span><span style="color:#96D0FF;">&#39;开始损失&#39;</span><span style="color:#ADBAC7;">,cost_history[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;">(</span><span style="color:#96D0FF;">&#39;结束损失&#39;</span><span style="color:#ADBAC7;">,cost_history[</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(</span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(num_iterations), cost_history)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.xlabel(</span><span style="color:#96D0FF;">&#39;Iterations&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.ylabel(</span><span style="color:#96D0FF;">&#39;Cost&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.title(</span><span style="color:#96D0FF;">&#39;Gradient Descent Progress&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">predictions_num </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">10</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x_min </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> x_train[:, </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">].min()</span><span style="color:#FF938A;font-style:italic;">;</span></span>
<span class="line"><span style="color:#ADBAC7;">x_max </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> x_train[:, </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">].max()</span><span style="color:#FF938A;font-style:italic;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">y_min </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> x_train[:, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">].min()</span><span style="color:#FF938A;font-style:italic;">;</span></span>
<span class="line"><span style="color:#ADBAC7;">y_max </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> x_train[:, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">].max()</span><span style="color:#FF938A;font-style:italic;">;</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x_axis </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.linspace(x_min, x_max, predictions_num)</span></span>
<span class="line"><span style="color:#ADBAC7;">y_axis </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.linspace(y_min, y_max, predictions_num)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x_predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.zeros((predictions_num </span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;"> predictions_num, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">y_predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.zeros((predictions_num </span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;"> predictions_num, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x_y_index </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0</span></span>
<span class="line"><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> x_index, x_value </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">enumerate</span><span style="color:#ADBAC7;">(x_axis):</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> y_index, y_value </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">enumerate</span><span style="color:#ADBAC7;">(y_axis):</span></span>
<span class="line"><span style="color:#ADBAC7;">        x_predictions[x_y_index] </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> x_value</span></span>
<span class="line"><span style="color:#ADBAC7;">        y_predictions[x_y_index] </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> y_value</span></span>
<span class="line"><span style="color:#ADBAC7;">        x_y_index </span><span style="color:#F47067;">+=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">1</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">z_predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> linear_regression.predict(np.hstack((x_predictions, y_predictions)))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plot_predictions_trace </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> go.Scatter3d(</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">x</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">x_predictions.flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">y</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">y_predictions.flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">z</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">z_predictions.flatten(),</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">name</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;Prediction Plane&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">mode</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;markers&#39;</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">marker</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">{</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#96D0FF;">&#39;size&#39;</span><span style="color:#ADBAC7;">: </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    },</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">opacity</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">0.8</span><span style="color:#ADBAC7;">,</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F69D50;">surfaceaxis</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">, </span></span>
<span class="line"><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plot_data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [plot_training_trace, plot_test_trace, plot_predictions_trace]</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_figure </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> go.Figure(</span><span style="color:#F69D50;">data</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">plot_data, </span><span style="color:#F69D50;">layout</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">plot_layout)</span></span>
<span class="line"><span style="color:#ADBAC7;">plotly.offline.plot(plot_figure)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> numpy </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> np</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> pandas </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> pd</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> matplotlib.pyplot </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> plt</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> plotly</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> plotly.graph_objs </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> go</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plotly.offline.init_notebook_mode()</span></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> linear_regression </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> LinearRegression</span></span>
<span class="line"><span style="color:#6A737D;"># 多特征回归模型</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> pd.read_csv(</span><span style="color:#032F62;">&#39;../data/world-happiness-report-2017.csv&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">train_data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data.sample(</span><span style="color:#E36209;">frac</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">0.8</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">test_data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data.drop(train_data.index)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">input_param_name_1 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;Economy..GDP.per.Capita.&#39;</span></span>
<span class="line"><span style="color:#24292E;">input_param_name_2 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;Freedom&#39;</span></span>
<span class="line"><span style="color:#24292E;">output_param_name </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;Happiness.Score&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x_train </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> train_data[[input_param_name_1, input_param_name_2]].values</span></span>
<span class="line"><span style="color:#24292E;">y_train </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> train_data[[output_param_name]].values</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x_test </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> test_data[[input_param_name_1, input_param_name_2]].values</span></span>
<span class="line"><span style="color:#24292E;">y_test </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> test_data[[output_param_name]].values</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># Configure the plot with training dataset.</span></span>
<span class="line"><span style="color:#24292E;">plot_training_trace </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> go.Scatter3d(</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">x</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">x_train[:, </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">].flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">y</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">x_train[:, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">].flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">z</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">y_train.flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">name</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Training Set&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">mode</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;markers&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">marker</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">{</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;size&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">10</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;opacity&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;line&#39;</span><span style="color:#24292E;">: {</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#032F62;">&#39;color&#39;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&#39;rgb(255, 255, 255)&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#032F62;">&#39;width&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">1</span></span>
<span class="line"><span style="color:#24292E;">        },</span></span>
<span class="line"><span style="color:#24292E;">    }</span></span>
<span class="line"><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plot_test_trace </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> go.Scatter3d(</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">x</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">x_test[:, </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">].flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">y</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">x_test[:, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">].flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">z</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">y_test.flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">name</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Test Set&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">mode</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;markers&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">marker</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">{</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;size&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">10</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;opacity&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;line&#39;</span><span style="color:#24292E;">: {</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#032F62;">&#39;color&#39;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&#39;rgb(255, 255, 255)&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#032F62;">&#39;width&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">1</span></span>
<span class="line"><span style="color:#24292E;">        },</span></span>
<span class="line"><span style="color:#24292E;">    }</span></span>
<span class="line"><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plot_layout </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> go.Layout(</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">title</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Date Sets&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">scene</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">{</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;xaxis&#39;</span><span style="color:#24292E;">: {</span><span style="color:#032F62;">&#39;title&#39;</span><span style="color:#24292E;">: input_param_name_1},</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;yaxis&#39;</span><span style="color:#24292E;">: {</span><span style="color:#032F62;">&#39;title&#39;</span><span style="color:#24292E;">: input_param_name_2},</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;zaxis&#39;</span><span style="color:#24292E;">: {</span><span style="color:#032F62;">&#39;title&#39;</span><span style="color:#24292E;">: output_param_name} </span></span>
<span class="line"><span style="color:#24292E;">    },</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">margin</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">{</span><span style="color:#032F62;">&#39;l&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&#39;r&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&#39;b&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&#39;t&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">}</span></span>
<span class="line"><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plot_data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [plot_training_trace, plot_test_trace]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plot_figure </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> go.Figure(</span><span style="color:#E36209;">data</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">plot_data, </span><span style="color:#E36209;">layout</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">plot_layout)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plotly.offline.plot(plot_figure) </span><span style="color:#6A737D;"># 如果要用jupter 改成plotly.offline.iplot</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">num_iterations </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">500</span><span style="color:#24292E;">  </span></span>
<span class="line"><span style="color:#24292E;">learning_rate </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.01</span><span style="color:#24292E;">  </span></span>
<span class="line"><span style="color:#24292E;">polynomial_degree </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">  </span></span>
<span class="line"><span style="color:#24292E;">sinusoid_degree </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">  </span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">linear_regression </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression(x_train, y_train, polynomial_degree, sinusoid_degree)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">(theta, cost_history) </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> linear_regression.train(</span></span>
<span class="line"><span style="color:#24292E;">    learning_rate,</span></span>
<span class="line"><span style="color:#24292E;">    num_iterations</span></span>
<span class="line"><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&#39;开始损失&#39;</span><span style="color:#24292E;">,cost_history[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&#39;结束损失&#39;</span><span style="color:#24292E;">,cost_history[</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.plot(</span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(num_iterations), cost_history)</span></span>
<span class="line"><span style="color:#24292E;">plt.xlabel(</span><span style="color:#032F62;">&#39;Iterations&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.ylabel(</span><span style="color:#032F62;">&#39;Cost&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.title(</span><span style="color:#032F62;">&#39;Gradient Descent Progress&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">predictions_num </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">10</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x_min </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x_train[:, </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">].min()</span><span style="color:#B31D28;font-style:italic;">;</span></span>
<span class="line"><span style="color:#24292E;">x_max </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x_train[:, </span><span style="color:#005CC5;">0</span><span style="color:#24292E;">].max()</span><span style="color:#B31D28;font-style:italic;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">y_min </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x_train[:, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">].min()</span><span style="color:#B31D28;font-style:italic;">;</span></span>
<span class="line"><span style="color:#24292E;">y_max </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x_train[:, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">].max()</span><span style="color:#B31D28;font-style:italic;">;</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x_axis </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.linspace(x_min, x_max, predictions_num)</span></span>
<span class="line"><span style="color:#24292E;">y_axis </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.linspace(y_min, y_max, predictions_num)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x_predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.zeros((predictions_num </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> predictions_num, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">y_predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.zeros((predictions_num </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> predictions_num, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x_y_index </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> x_index, x_value </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">enumerate</span><span style="color:#24292E;">(x_axis):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> y_index, y_value </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">enumerate</span><span style="color:#24292E;">(y_axis):</span></span>
<span class="line"><span style="color:#24292E;">        x_predictions[x_y_index] </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x_value</span></span>
<span class="line"><span style="color:#24292E;">        y_predictions[x_y_index] </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> y_value</span></span>
<span class="line"><span style="color:#24292E;">        x_y_index </span><span style="color:#D73A49;">+=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">z_predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> linear_regression.predict(np.hstack((x_predictions, y_predictions)))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plot_predictions_trace </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> go.Scatter3d(</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">x</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">x_predictions.flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">y</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">y_predictions.flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">z</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">z_predictions.flatten(),</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">name</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Prediction Plane&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">mode</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;markers&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">marker</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">{</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#032F62;">&#39;size&#39;</span><span style="color:#24292E;">: </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    },</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">opacity</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">0.8</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#E36209;">surfaceaxis</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">, </span></span>
<span class="line"><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plot_data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [plot_training_trace, plot_test_trace, plot_predictions_trace]</span></span>
<span class="line"><span style="color:#24292E;">plot_figure </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> go.Figure(</span><span style="color:#E36209;">data</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">plot_data, </span><span style="color:#E36209;">layout</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">plot_layout)</span></span>
<span class="line"><span style="color:#24292E;">plotly.offline.plot(plot_figure)</span></span></code></pre></div><h3 id="非线性回归" tabindex="-1">非线性回归 <a class="header-anchor" href="#非线性回归" aria-label="Permalink to &quot;非线性回归&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> numpy </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> np</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> pandas </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> pd</span></span>
<span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> matplotlib.pyplot </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> linear_regression </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> LinearRegression</span></span>
<span class="line"></span>
<span class="line"><span style="color:#768390;"># 非线性回归</span></span>
<span class="line"><span style="color:#ADBAC7;">data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> pd.read_csv(</span><span style="color:#96D0FF;">&#39;../data/non-linear-regression-x-y.csv&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">x </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> data[</span><span style="color:#96D0FF;">&#39;x&#39;</span><span style="color:#ADBAC7;">].values.reshape((data.shape[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">], </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">y </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> data[</span><span style="color:#96D0FF;">&#39;y&#39;</span><span style="color:#ADBAC7;">].values.reshape((data.shape[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">], </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">data.head(</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(x, y)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">num_iterations </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">50000</span><span style="color:#ADBAC7;">  </span></span>
<span class="line"><span style="color:#ADBAC7;">learning_rate </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.02</span></span>
<span class="line"><span style="color:#768390;"># 特征变换</span></span>
<span class="line"><span style="color:#ADBAC7;">polynomial_degree </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">15</span></span>
<span class="line"><span style="color:#ADBAC7;">sinusoid_degree </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">15</span></span>
<span class="line"><span style="color:#ADBAC7;">normalize_data </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">True</span><span style="color:#ADBAC7;">  </span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">linear_regression </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression(x, y, polynomial_degree, sinusoid_degree, normalize_data)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">(theta, cost_history) </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> linear_regression.train(</span></span>
<span class="line"><span style="color:#ADBAC7;">    learning_rate,</span></span>
<span class="line"><span style="color:#ADBAC7;">    num_iterations</span></span>
<span class="line"><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;">(</span><span style="color:#96D0FF;">&#39;开始损失: </span><span style="color:#F47067;">{:.2f}</span><span style="color:#96D0FF;">&#39;</span><span style="color:#ADBAC7;">.format(cost_history[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">]))</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;">(</span><span style="color:#96D0FF;">&#39;结束损失: </span><span style="color:#F47067;">{:.2f}</span><span style="color:#96D0FF;">&#39;</span><span style="color:#ADBAC7;">.format(cost_history[</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">]))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">theta_table </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> pd.DataFrame({</span><span style="color:#96D0FF;">&#39;Model Parameters&#39;</span><span style="color:#ADBAC7;">: theta.flatten()})</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(</span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(num_iterations), cost_history)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.xlabel(</span><span style="color:#96D0FF;">&#39;Iterations&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.ylabel(</span><span style="color:#96D0FF;">&#39;Cost&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.title(</span><span style="color:#96D0FF;">&#39;Gradient Descent Progress&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">predictions_num </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">1000</span></span>
<span class="line"><span style="color:#ADBAC7;">x_predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.linspace(x.min(), x.max(), predictions_num).reshape(predictions_num, </span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span><span style="color:#FF938A;font-style:italic;">;</span></span>
<span class="line"><span style="color:#ADBAC7;">y_predictions </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> linear_regression.predict(x_predictions)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.scatter(x, y, </span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;Training Dataset&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(x_predictions, y_predictions, </span><span style="color:#96D0FF;">&#39;r&#39;</span><span style="color:#ADBAC7;">, </span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;Prediction&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> numpy </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> np</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> pandas </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> pd</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> matplotlib.pyplot </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> linear_regression </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> LinearRegression</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 非线性回归</span></span>
<span class="line"><span style="color:#24292E;">data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> pd.read_csv(</span><span style="color:#032F62;">&#39;../data/non-linear-regression-x-y.csv&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data[</span><span style="color:#032F62;">&#39;x&#39;</span><span style="color:#24292E;">].values.reshape((data.shape[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">], </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">y </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data[</span><span style="color:#032F62;">&#39;y&#39;</span><span style="color:#24292E;">].values.reshape((data.shape[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">], </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">data.head(</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.plot(x, y)</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">num_iterations </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">50000</span><span style="color:#24292E;">  </span></span>
<span class="line"><span style="color:#24292E;">learning_rate </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.02</span></span>
<span class="line"><span style="color:#6A737D;"># 特征变换</span></span>
<span class="line"><span style="color:#24292E;">polynomial_degree </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">15</span></span>
<span class="line"><span style="color:#24292E;">sinusoid_degree </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">15</span></span>
<span class="line"><span style="color:#24292E;">normalize_data </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">True</span><span style="color:#24292E;">  </span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">linear_regression </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression(x, y, polynomial_degree, sinusoid_degree, normalize_data)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">(theta, cost_history) </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> linear_regression.train(</span></span>
<span class="line"><span style="color:#24292E;">    learning_rate,</span></span>
<span class="line"><span style="color:#24292E;">    num_iterations</span></span>
<span class="line"><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&#39;开始损失: </span><span style="color:#005CC5;">{</span><span style="color:#D73A49;">:.2f</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&#39;</span><span style="color:#24292E;">.format(cost_history[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]))</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&#39;结束损失: </span><span style="color:#005CC5;">{</span><span style="color:#D73A49;">:.2f</span><span style="color:#005CC5;">}</span><span style="color:#032F62;">&#39;</span><span style="color:#24292E;">.format(cost_history[</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">]))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">theta_table </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> pd.DataFrame({</span><span style="color:#032F62;">&#39;Model Parameters&#39;</span><span style="color:#24292E;">: theta.flatten()})</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.plot(</span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(num_iterations), cost_history)</span></span>
<span class="line"><span style="color:#24292E;">plt.xlabel(</span><span style="color:#032F62;">&#39;Iterations&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.ylabel(</span><span style="color:#032F62;">&#39;Cost&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.title(</span><span style="color:#032F62;">&#39;Gradient Descent Progress&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">predictions_num </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1000</span></span>
<span class="line"><span style="color:#24292E;">x_predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.linspace(x.min(), x.max(), predictions_num).reshape(predictions_num, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span><span style="color:#B31D28;font-style:italic;">;</span></span>
<span class="line"><span style="color:#24292E;">y_predictions </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> linear_regression.predict(x_predictions)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.scatter(x, y, </span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Training Dataset&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(x_predictions, y_predictions, </span><span style="color:#032F62;">&#39;r&#39;</span><span style="color:#24292E;">, </span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;Prediction&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><h2 id="_3-线性回归实验分析" tabindex="-1">3. 线性回归实验分析 <a class="header-anchor" href="#_3-线性回归实验分析" aria-label="Permalink to &quot;3. 线性回归实验分析&quot;">​</a></h2><h3 id="回归方程" tabindex="-1">回归方程 <a class="header-anchor" href="#回归方程" aria-label="Permalink to &quot;回归方程&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> numpy </span><span style="color:#F47067;">as</span><span style="color:#ADBAC7;"> np</span></span>
<span class="line"><span style="color:#ADBAC7;">X </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">2</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">np.random.rand(</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">y </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">4</span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">3</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">X </span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;">np.random.randn(</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">X_b </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.c_[np.ones((</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)),X]</span></span>
<span class="line"><span style="color:#768390;"># array([[1.        , 0.74908024],</span></span>
<span class="line"></span>
<span class="line"><span style="color:#768390;"># linalg.inv 1求逆</span></span>
<span class="line"><span style="color:#ADBAC7;">theta_best </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)</span></span>
<span class="line"><span style="color:#ADBAC7;">theta_best</span></span>
<span class="line"><span style="color:#ADBAC7;">array([[</span><span style="color:#6CB6FF;">4.21509616</span><span style="color:#ADBAC7;">],</span></span>
<span class="line"><span style="color:#ADBAC7;">       [</span><span style="color:#6CB6FF;">2.77011339</span><span style="color:#ADBAC7;">]])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">X_new </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.array([[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">],[</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">]])</span></span>
<span class="line"><span style="color:#ADBAC7;">X_new_b </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.c_[np.ones((</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)),X_new]</span></span>
<span class="line"><span style="color:#ADBAC7;">y_predict </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> X_new_b.dot(theta_best)</span></span>
<span class="line"><span style="color:#ADBAC7;">y_predict</span></span>
<span class="line"><span style="color:#ADBAC7;">array([[</span><span style="color:#6CB6FF;">4.21509616</span><span style="color:#ADBAC7;">],</span></span>
<span class="line"><span style="color:#ADBAC7;">       [</span><span style="color:#6CB6FF;">9.75532293</span><span style="color:#ADBAC7;">]])</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> numpy </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> np</span></span>
<span class="line"><span style="color:#24292E;">X </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">np.random.rand(</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">y </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">4</span><span style="color:#D73A49;">+</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">3</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">X </span><span style="color:#D73A49;">+</span><span style="color:#24292E;">np.random.randn(</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">X_b </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.c_[np.ones((</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)),X]</span></span>
<span class="line"><span style="color:#6A737D;"># array([[1.        , 0.74908024],</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># linalg.inv 1求逆</span></span>
<span class="line"><span style="color:#24292E;">theta_best </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)</span></span>
<span class="line"><span style="color:#24292E;">theta_best</span></span>
<span class="line"><span style="color:#24292E;">array([[</span><span style="color:#005CC5;">4.21509616</span><span style="color:#24292E;">],</span></span>
<span class="line"><span style="color:#24292E;">       [</span><span style="color:#005CC5;">2.77011339</span><span style="color:#24292E;">]])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">X_new </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.array([[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">],[</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">]])</span></span>
<span class="line"><span style="color:#24292E;">X_new_b </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.c_[np.ones((</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)),X_new]</span></span>
<span class="line"><span style="color:#24292E;">y_predict </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> X_new_b.dot(theta_best)</span></span>
<span class="line"><span style="color:#24292E;">y_predict</span></span>
<span class="line"><span style="color:#24292E;">array([[</span><span style="color:#005CC5;">4.21509616</span><span style="color:#24292E;">],</span></span>
<span class="line"><span style="color:#24292E;">       [</span><span style="color:#005CC5;">9.75532293</span><span style="color:#24292E;">]])</span></span></code></pre></div><h3 id="梯度下降" tabindex="-1">梯度下降 <a class="header-anchor" href="#梯度下降" aria-label="Permalink to &quot;梯度下降&quot;">​</a></h3><h4 id="批量梯度下降计算公式" tabindex="-1">批量梯度下降计算公式 <a class="header-anchor" href="#批量梯度下降计算公式" aria-label="Permalink to &quot;批量梯度下降计算公式&quot;">​</a></h4><p><img src="https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%902.png" alt=""></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#ADBAC7;">eta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.1</span><span style="color:#ADBAC7;"> </span><span style="color:#768390;"># 学习率</span></span>
<span class="line"><span style="color:#ADBAC7;">n_iterations </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">1000</span></span>
<span class="line"><span style="color:#ADBAC7;">m </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;"> </span><span style="color:#768390;"># 样本个数</span></span>
<span class="line"><span style="color:#ADBAC7;">theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.random.randn(</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> iteration </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(n_iterations):</span></span>
<span class="line"><span style="color:#ADBAC7;">    gradients </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">2</span><span style="color:#F47067;">/</span><span style="color:#ADBAC7;">m</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;"> X_b.T.dot(X_b.dot(theta)</span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;">y)</span></span>
<span class="line"><span style="color:#ADBAC7;">    theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> theta </span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;"> eta</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">gradients</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">theta</span></span>
<span class="line"><span style="color:#ADBAC7;">array([[</span><span style="color:#6CB6FF;">4.21509616</span><span style="color:#ADBAC7;">],</span></span>
<span class="line"><span style="color:#ADBAC7;">       [</span><span style="color:#6CB6FF;">2.77011339</span><span style="color:#ADBAC7;">]])</span></span>
<span class="line"><span style="color:#ADBAC7;">theta_path_bgd </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> []</span></span>
<span class="line"><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">plot_gradient_descent</span><span style="color:#ADBAC7;">(theta,eta,theta_path </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">None</span><span style="color:#ADBAC7;">):</span></span>
<span class="line"><span style="color:#ADBAC7;">    m </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">len</span><span style="color:#ADBAC7;">(X_b)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.plot(X,y,</span><span style="color:#96D0FF;">&#39;b.&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    n_iterations </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">1000</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> iteration </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(n_iterations): </span></span>
<span class="line"><span style="color:#ADBAC7;">        y_predict </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> X_new_b.dot(theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">        plt.plot(X_new,y_predict,</span><span style="color:#96D0FF;">&#39;b-&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">        gradients </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">2</span><span style="color:#F47067;">/</span><span style="color:#ADBAC7;">m</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;"> X_b.T.dot(X_b.dot(theta)</span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;">y)</span></span>
<span class="line"><span style="color:#ADBAC7;">        theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> theta </span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;"> eta</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">gradients</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">if</span><span style="color:#ADBAC7;"> theta_path </span><span style="color:#F47067;">is</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">not</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">None</span><span style="color:#ADBAC7;">:</span></span>
<span class="line"><span style="color:#ADBAC7;">            theta_path.append(theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.xlabel(</span><span style="color:#96D0FF;">&#39;X_1&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.axis([</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">15</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.title(</span><span style="color:#96D0FF;">&#39;eta = </span><span style="color:#F47067;">{}</span><span style="color:#96D0FF;">&#39;</span><span style="color:#ADBAC7;">.format(eta))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.random.randn(</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.figure(</span><span style="color:#F69D50;">figsize</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">(</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">4</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.subplot(</span><span style="color:#6CB6FF;">131</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_gradient_descent(theta,</span><span style="color:#F69D50;">eta</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.02</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.subplot(</span><span style="color:#6CB6FF;">132</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_gradient_descent(theta,</span><span style="color:#F69D50;">eta</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.1</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">theta_path</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">theta_path_bgd)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.subplot(</span><span style="color:#6CB6FF;">133</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_gradient_descent(theta,</span><span style="color:#F69D50;">eta</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.5</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">eta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.1</span><span style="color:#24292E;"> </span><span style="color:#6A737D;"># 学习率</span></span>
<span class="line"><span style="color:#24292E;">n_iterations </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1000</span></span>
<span class="line"><span style="color:#24292E;">m </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">100</span><span style="color:#24292E;"> </span><span style="color:#6A737D;"># 样本个数</span></span>
<span class="line"><span style="color:#24292E;">theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.random.randn(</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> iteration </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(n_iterations):</span></span>
<span class="line"><span style="color:#24292E;">    gradients </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">m</span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> X_b.T.dot(X_b.dot(theta)</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">y)</span></span>
<span class="line"><span style="color:#24292E;">    theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> theta </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> eta</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">gradients</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">theta</span></span>
<span class="line"><span style="color:#24292E;">array([[</span><span style="color:#005CC5;">4.21509616</span><span style="color:#24292E;">],</span></span>
<span class="line"><span style="color:#24292E;">       [</span><span style="color:#005CC5;">2.77011339</span><span style="color:#24292E;">]])</span></span>
<span class="line"><span style="color:#24292E;">theta_path_bgd </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> []</span></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">plot_gradient_descent</span><span style="color:#24292E;">(theta,eta,theta_path </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">None</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    m </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">len</span><span style="color:#24292E;">(X_b)</span></span>
<span class="line"><span style="color:#24292E;">    plt.plot(X,y,</span><span style="color:#032F62;">&#39;b.&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    n_iterations </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1000</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> iteration </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(n_iterations): </span></span>
<span class="line"><span style="color:#24292E;">        y_predict </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> X_new_b.dot(theta)</span></span>
<span class="line"><span style="color:#24292E;">        plt.plot(X_new,y_predict,</span><span style="color:#032F62;">&#39;b-&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        gradients </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">m</span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> X_b.T.dot(X_b.dot(theta)</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">y)</span></span>
<span class="line"><span style="color:#24292E;">        theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> theta </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> eta</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">gradients</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> theta_path </span><span style="color:#D73A49;">is</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">not</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">None</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">            theta_path.append(theta)</span></span>
<span class="line"><span style="color:#24292E;">    plt.xlabel(</span><span style="color:#032F62;">&#39;X_1&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    plt.axis([</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">15</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#24292E;">    plt.title(</span><span style="color:#032F62;">&#39;eta = </span><span style="color:#005CC5;">{}</span><span style="color:#032F62;">&#39;</span><span style="color:#24292E;">.format(eta))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.random.randn(</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.figure(</span><span style="color:#E36209;">figsize</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">4</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.subplot(</span><span style="color:#005CC5;">131</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plot_gradient_descent(theta,</span><span style="color:#E36209;">eta</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.02</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.subplot(</span><span style="color:#005CC5;">132</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plot_gradient_descent(theta,</span><span style="color:#E36209;">eta</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.1</span><span style="color:#24292E;">,</span><span style="color:#E36209;">theta_path</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">theta_path_bgd)</span></span>
<span class="line"><span style="color:#24292E;">plt.subplot(</span><span style="color:#005CC5;">133</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plot_gradient_descent(theta,</span><span style="color:#E36209;">eta</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.5</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%903.png" alt=""></p><h4 id="随机梯度下降" tabindex="-1">随机梯度下降 <a class="header-anchor" href="#随机梯度下降" aria-label="Permalink to &quot;随机梯度下降&quot;">​</a></h4><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#ADBAC7;">theta_path_sgd</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">[]</span></span>
<span class="line"><span style="color:#ADBAC7;">m </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">len</span><span style="color:#ADBAC7;">(X_b)</span></span>
<span class="line"><span style="color:#ADBAC7;">np.random.seed(</span><span style="color:#6CB6FF;">42</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">n_epochs </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">50</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">t0 </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">5</span></span>
<span class="line"><span style="color:#ADBAC7;">t1 </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">50</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">learning_schedule</span><span style="color:#ADBAC7;">(t):</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">return</span><span style="color:#ADBAC7;"> t0</span><span style="color:#F47067;">/</span><span style="color:#ADBAC7;">(t1</span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;">t)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.random.randn(</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> epoch </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(n_epochs):</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> i </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(m):</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">if</span><span style="color:#ADBAC7;"> epoch </span><span style="color:#F47067;">&lt;</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">and</span><span style="color:#ADBAC7;"> i</span><span style="color:#F47067;">&lt;</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">:</span></span>
<span class="line"><span style="color:#ADBAC7;">            y_predict </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> X_new_b.dot(theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">            plt.plot(X_new,y_predict,</span><span style="color:#96D0FF;">&#39;r-&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">        random_index </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.random.randint(m)</span></span>
<span class="line"><span style="color:#ADBAC7;">        xi </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> X_b[random_index:random_index</span><span style="color:#F47067;">+</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">        yi </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> y[random_index:random_index</span><span style="color:#F47067;">+</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">        gradients </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">2</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;"> xi.T.dot(xi.dot(theta)</span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;">yi)</span></span>
<span class="line"><span style="color:#ADBAC7;">        eta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> learning_schedule(epoch</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">m</span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;">i)</span></span>
<span class="line"><span style="color:#ADBAC7;">        theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> theta</span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;">eta</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">gradients</span></span>
<span class="line"><span style="color:#ADBAC7;">        theta_path_sgd.append(theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(X,y,</span><span style="color:#96D0FF;">&#39;b.&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.axis([</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">15</span><span style="color:#ADBAC7;">])   </span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">theta_path_sgd</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">[]</span></span>
<span class="line"><span style="color:#24292E;">m </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">len</span><span style="color:#24292E;">(X_b)</span></span>
<span class="line"><span style="color:#24292E;">np.random.seed(</span><span style="color:#005CC5;">42</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">n_epochs </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">50</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">t0 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">5</span></span>
<span class="line"><span style="color:#24292E;">t1 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">50</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">learning_schedule</span><span style="color:#24292E;">(t):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> t0</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">(t1</span><span style="color:#D73A49;">+</span><span style="color:#24292E;">t)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.random.randn(</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> epoch </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(n_epochs):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> i </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(m):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> epoch </span><span style="color:#D73A49;">&lt;</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">10</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">and</span><span style="color:#24292E;"> i</span><span style="color:#D73A49;">&lt;</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">            y_predict </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> X_new_b.dot(theta)</span></span>
<span class="line"><span style="color:#24292E;">            plt.plot(X_new,y_predict,</span><span style="color:#032F62;">&#39;r-&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        random_index </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.random.randint(m)</span></span>
<span class="line"><span style="color:#24292E;">        xi </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> X_b[random_index:random_index</span><span style="color:#D73A49;">+</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">        yi </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> y[random_index:random_index</span><span style="color:#D73A49;">+</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">        gradients </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> xi.T.dot(xi.dot(theta)</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">yi)</span></span>
<span class="line"><span style="color:#24292E;">        eta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> learning_schedule(epoch</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">m</span><span style="color:#D73A49;">+</span><span style="color:#24292E;">i)</span></span>
<span class="line"><span style="color:#24292E;">        theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> theta</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">eta</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">gradients</span></span>
<span class="line"><span style="color:#24292E;">        theta_path_sgd.append(theta)</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"><span style="color:#24292E;">plt.plot(X,y,</span><span style="color:#032F62;">&#39;b.&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.axis([</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">15</span><span style="color:#24292E;">])   </span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%904.png" alt=""></p><h4 id="minibatch梯度下降" tabindex="-1">MiniBatch梯度下降 <a class="header-anchor" href="#minibatch梯度下降" aria-label="Permalink to &quot;MiniBatch梯度下降&quot;">​</a></h4><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#ADBAC7;">theta_path_mgd</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">[]</span></span>
<span class="line"><span style="color:#ADBAC7;">n_epochs </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">50</span></span>
<span class="line"><span style="color:#ADBAC7;">minibatch </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">16</span></span>
<span class="line"><span style="color:#ADBAC7;">theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.random.randn(</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">t0, t1 </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">200</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">1000</span></span>
<span class="line"><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">learning_schedule</span><span style="color:#ADBAC7;">(t):</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">return</span><span style="color:#ADBAC7;"> t0 </span><span style="color:#F47067;">/</span><span style="color:#ADBAC7;"> (t </span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;"> t1)</span></span>
<span class="line"><span style="color:#ADBAC7;">np.random.seed(</span><span style="color:#6CB6FF;">42</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">t </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0</span></span>
<span class="line"><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> epoch </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(n_epochs):</span></span>
<span class="line"><span style="color:#ADBAC7;">    shuffled_indices </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.random.permutation(m)</span></span>
<span class="line"><span style="color:#ADBAC7;">    X_b_shuffled </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> X_b[shuffled_indices]</span></span>
<span class="line"><span style="color:#ADBAC7;">    y_shuffled </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> y[shuffled_indices]</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> i </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,m,minibatch):</span></span>
<span class="line"><span style="color:#ADBAC7;">        t</span><span style="color:#F47067;">+=</span><span style="color:#6CB6FF;">1</span></span>
<span class="line"><span style="color:#ADBAC7;">        xi </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> X_b_shuffled[i:i</span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;">minibatch]</span></span>
<span class="line"><span style="color:#ADBAC7;">        yi </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> y_shuffled[i:i</span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;">minibatch]</span></span>
<span class="line"><span style="color:#ADBAC7;">        gradients </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">2</span><span style="color:#F47067;">/</span><span style="color:#ADBAC7;">minibatch</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;"> xi.T.dot(xi.dot(theta)</span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;">yi)</span></span>
<span class="line"><span style="color:#ADBAC7;">        eta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> learning_schedule(t)</span></span>
<span class="line"><span style="color:#ADBAC7;">        theta </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> theta</span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;">eta</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">gradients</span></span>
<span class="line"><span style="color:#ADBAC7;">        theta_path_mgd.append(theta)</span></span>
<span class="line"><span style="color:#ADBAC7;">theta</span></span>
<span class="line"><span style="color:#ADBAC7;">array([[</span><span style="color:#6CB6FF;">4.25490684</span><span style="color:#ADBAC7;">],</span></span>
<span class="line"><span style="color:#ADBAC7;">       [</span><span style="color:#6CB6FF;">2.80388785</span><span style="color:#ADBAC7;">]])</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">theta_path_mgd</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">[]</span></span>
<span class="line"><span style="color:#24292E;">n_epochs </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">50</span></span>
<span class="line"><span style="color:#24292E;">minibatch </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">16</span></span>
<span class="line"><span style="color:#24292E;">theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.random.randn(</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">t0, t1 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">200</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1000</span></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">learning_schedule</span><span style="color:#24292E;">(t):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> t0 </span><span style="color:#D73A49;">/</span><span style="color:#24292E;"> (t </span><span style="color:#D73A49;">+</span><span style="color:#24292E;"> t1)</span></span>
<span class="line"><span style="color:#24292E;">np.random.seed(</span><span style="color:#005CC5;">42</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">t </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> epoch </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(n_epochs):</span></span>
<span class="line"><span style="color:#24292E;">    shuffled_indices </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.random.permutation(m)</span></span>
<span class="line"><span style="color:#24292E;">    X_b_shuffled </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> X_b[shuffled_indices]</span></span>
<span class="line"><span style="color:#24292E;">    y_shuffled </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> y[shuffled_indices]</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> i </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,m,minibatch):</span></span>
<span class="line"><span style="color:#24292E;">        t</span><span style="color:#D73A49;">+=</span><span style="color:#005CC5;">1</span></span>
<span class="line"><span style="color:#24292E;">        xi </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> X_b_shuffled[i:i</span><span style="color:#D73A49;">+</span><span style="color:#24292E;">minibatch]</span></span>
<span class="line"><span style="color:#24292E;">        yi </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> y_shuffled[i:i</span><span style="color:#D73A49;">+</span><span style="color:#24292E;">minibatch]</span></span>
<span class="line"><span style="color:#24292E;">        gradients </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">minibatch</span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> xi.T.dot(xi.dot(theta)</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">yi)</span></span>
<span class="line"><span style="color:#24292E;">        eta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> learning_schedule(t)</span></span>
<span class="line"><span style="color:#24292E;">        theta </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> theta</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">eta</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">gradients</span></span>
<span class="line"><span style="color:#24292E;">        theta_path_mgd.append(theta)</span></span>
<span class="line"><span style="color:#24292E;">theta</span></span>
<span class="line"><span style="color:#24292E;">array([[</span><span style="color:#005CC5;">4.25490684</span><span style="color:#24292E;">],</span></span>
<span class="line"><span style="color:#24292E;">       [</span><span style="color:#005CC5;">2.80388785</span><span style="color:#24292E;">]])</span></span></code></pre></div><h4 id="_3种策略的对比实验" tabindex="-1">3种策略的对比实验 <a class="header-anchor" href="#_3种策略的对比实验" aria-label="Permalink to &quot;3种策略的对比实验&quot;">​</a></h4><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#768390;"># 实际当中用minibatch比较多，一般情况下选择batch数量应当越大越好。</span></span>
<span class="line"><span style="color:#768390;"># 批量梯度下降</span></span>
<span class="line"><span style="color:#ADBAC7;">theta_path_bgd </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.array(theta_path_bgd)</span></span>
<span class="line"><span style="color:#768390;"># 随机梯度下降</span></span>
<span class="line"><span style="color:#ADBAC7;">theta_path_sgd </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.array(theta_path_sgd)</span></span>
<span class="line"><span style="color:#768390;"># MiniBatch梯度下降</span></span>
<span class="line"><span style="color:#ADBAC7;">theta_path_mgd </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.array(theta_path_mgd)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.figure(</span><span style="color:#F69D50;">figsize</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">(</span><span style="color:#6CB6FF;">12</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">6</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(theta_path_sgd[:,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">],theta_path_sgd[:,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">],</span><span style="color:#96D0FF;">&#39;r-s&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">linewidth</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;SGD&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(theta_path_mgd[:,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">],theta_path_mgd[:,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">],</span><span style="color:#96D0FF;">&#39;g-+&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">linewidth</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;MINIGD&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(theta_path_bgd[:,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">],theta_path_bgd[:,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">],</span><span style="color:#96D0FF;">&#39;b-o&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">linewidth</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;BGD&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.legend(</span><span style="color:#F69D50;">loc</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;upper left&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.axis([</span><span style="color:#6CB6FF;">3.5</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">4.5</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">2.0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">4.0</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># 实际当中用minibatch比较多，一般情况下选择batch数量应当越大越好。</span></span>
<span class="line"><span style="color:#6A737D;"># 批量梯度下降</span></span>
<span class="line"><span style="color:#24292E;">theta_path_bgd </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.array(theta_path_bgd)</span></span>
<span class="line"><span style="color:#6A737D;"># 随机梯度下降</span></span>
<span class="line"><span style="color:#24292E;">theta_path_sgd </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.array(theta_path_sgd)</span></span>
<span class="line"><span style="color:#6A737D;"># MiniBatch梯度下降</span></span>
<span class="line"><span style="color:#24292E;">theta_path_mgd </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.array(theta_path_mgd)</span></span>
<span class="line"><span style="color:#24292E;">plt.figure(</span><span style="color:#E36209;">figsize</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">12</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">6</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(theta_path_sgd[:,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">],theta_path_sgd[:,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">],</span><span style="color:#032F62;">&#39;r-s&#39;</span><span style="color:#24292E;">,</span><span style="color:#E36209;">linewidth</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;SGD&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(theta_path_mgd[:,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">],theta_path_mgd[:,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">],</span><span style="color:#032F62;">&#39;g-+&#39;</span><span style="color:#24292E;">,</span><span style="color:#E36209;">linewidth</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;MINIGD&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(theta_path_bgd[:,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">],theta_path_bgd[:,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">],</span><span style="color:#032F62;">&#39;b-o&#39;</span><span style="color:#24292E;">,</span><span style="color:#E36209;">linewidth</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;BGD&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.legend(</span><span style="color:#E36209;">loc</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;upper left&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.axis([</span><span style="color:#005CC5;">3.5</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">4.5</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">2.0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">4.0</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%905.png" alt=""></p><h3 id="多项式回归" tabindex="-1">多项式回归 <a class="header-anchor" href="#多项式回归" aria-label="Permalink to &quot;多项式回归&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#ADBAC7;">m </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">100</span></span>
<span class="line"><span style="color:#ADBAC7;">X </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">6</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">np.random.rand(m,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">) </span><span style="color:#F47067;">-</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">3</span></span>
<span class="line"><span style="color:#ADBAC7;">y </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.5</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">X</span><span style="color:#F47067;">**</span><span style="color:#6CB6FF;">2</span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;">X</span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;">np.random.randn(m,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> sklearn.preprocessing </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> PolynomialFeatures</span></span>
<span class="line"><span style="color:#ADBAC7;">poly_features </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> PolynomialFeatures(</span><span style="color:#F69D50;">degree</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">include_bias</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">False</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">X_poly </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> poly_features.fit_transform(X)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">X_poly[</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"><span style="color:#ADBAC7;">array([</span><span style="color:#6CB6FF;">2.82919615</span><span style="color:#ADBAC7;">, </span><span style="color:#6CB6FF;">8.00435083</span><span style="color:#ADBAC7;">]) </span><span style="color:#768390;"># x x^2</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> sklearn.linear_model </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> LinearRegression</span></span>
<span class="line"><span style="color:#ADBAC7;">lin_reg </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression()</span></span>
<span class="line"><span style="color:#ADBAC7;">lin_reg.fit(X_poly,y)</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (lin_reg.coef_)</span></span>
<span class="line"><span style="color:#6CB6FF;">print</span><span style="color:#ADBAC7;"> (lin_reg.intercept_)</span></span>
<span class="line"><span style="color:#ADBAC7;">[[</span><span style="color:#6CB6FF;">1.10879671</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.53435287</span><span style="color:#ADBAC7;">]]</span></span>
<span class="line"><span style="color:#ADBAC7;">[</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">0.03765461</span><span style="color:#ADBAC7;">]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">X_new </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.linspace(</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">).reshape(</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">X_new_poly </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> poly_features.transform(X_new)</span></span>
<span class="line"><span style="color:#ADBAC7;">y_new </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> lin_reg.predict(X_new_poly)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(X,y,</span><span style="color:#96D0FF;">&#39;b.&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(X_new,y_new,</span><span style="color:#96D0FF;">&#39;r--&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">label</span><span style="color:#F47067;">=</span><span style="color:#96D0FF;">&#39;prediction&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.axis([</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">5</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.legend()</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">m </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">100</span></span>
<span class="line"><span style="color:#24292E;">X </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">6</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">np.random.rand(m,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">) </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">3</span></span>
<span class="line"><span style="color:#24292E;">y </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.5</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">X</span><span style="color:#D73A49;">**</span><span style="color:#005CC5;">2</span><span style="color:#D73A49;">+</span><span style="color:#24292E;">X</span><span style="color:#D73A49;">+</span><span style="color:#24292E;">np.random.randn(m,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> sklearn.preprocessing </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> PolynomialFeatures</span></span>
<span class="line"><span style="color:#24292E;">poly_features </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> PolynomialFeatures(</span><span style="color:#E36209;">degree</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#E36209;">include_bias</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">X_poly </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> poly_features.fit_transform(X)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">X_poly[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">array([</span><span style="color:#005CC5;">2.82919615</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">8.00435083</span><span style="color:#24292E;">]) </span><span style="color:#6A737D;"># x x^2</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> sklearn.linear_model </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> LinearRegression</span></span>
<span class="line"><span style="color:#24292E;">lin_reg </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression()</span></span>
<span class="line"><span style="color:#24292E;">lin_reg.fit(X_poly,y)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (lin_reg.coef_)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;"> (lin_reg.intercept_)</span></span>
<span class="line"><span style="color:#24292E;">[[</span><span style="color:#005CC5;">1.10879671</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.53435287</span><span style="color:#24292E;">]]</span></span>
<span class="line"><span style="color:#24292E;">[</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">0.03765461</span><span style="color:#24292E;">]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">X_new </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.linspace(</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">).reshape(</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">X_new_poly </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> poly_features.transform(X_new)</span></span>
<span class="line"><span style="color:#24292E;">y_new </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> lin_reg.predict(X_new_poly)</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(X,y,</span><span style="color:#032F62;">&#39;b.&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(X_new,y_new,</span><span style="color:#032F62;">&#39;r--&#39;</span><span style="color:#24292E;">,</span><span style="color:#E36209;">label</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;prediction&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.axis([</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">5</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#24292E;">plt.legend()</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%906.png" alt=""></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#768390;"># 特征变换的越复杂，得到的结果过拟合风险越高，不建议做的特别复杂。</span></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> sklearn.pipeline </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> Pipeline</span></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> sklearn.preprocessing </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> StandardScaler</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.figure(</span><span style="color:#F69D50;">figsize</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">(</span><span style="color:#6CB6FF;">12</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">6</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> style,width,degree </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> ((</span><span style="color:#96D0FF;">&#39;g-&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">),(</span><span style="color:#96D0FF;">&#39;b--&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">),(</span><span style="color:#96D0FF;">&#39;r-+&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)):</span></span>
<span class="line"><span style="color:#ADBAC7;">    poly_features </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> PolynomialFeatures(</span><span style="color:#F69D50;">degree</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> degree,</span><span style="color:#F69D50;">include_bias</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">False</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    std </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> StandardScaler()</span></span>
<span class="line"><span style="color:#ADBAC7;">    lin_reg </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression()</span></span>
<span class="line"><span style="color:#ADBAC7;">    polynomial_reg </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> Pipeline([(</span><span style="color:#96D0FF;">&#39;poly_features&#39;</span><span style="color:#ADBAC7;">,poly_features),</span></span>
<span class="line"><span style="color:#ADBAC7;">             (</span><span style="color:#96D0FF;">&#39;StandardScaler&#39;</span><span style="color:#ADBAC7;">,std),</span></span>
<span class="line"><span style="color:#ADBAC7;">             (</span><span style="color:#96D0FF;">&#39;lin_reg&#39;</span><span style="color:#ADBAC7;">,lin_reg)])</span></span>
<span class="line"><span style="color:#ADBAC7;">    polynomial_reg.fit(X,y)</span></span>
<span class="line"><span style="color:#ADBAC7;">    y_new_2 </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> polynomial_reg.predict(X_new)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.plot(X_new,y_new_2,style,</span><span style="color:#F69D50;">label</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;degree   &#39;</span><span style="color:#F47067;">+</span><span style="color:#6CB6FF;">str</span><span style="color:#ADBAC7;">(degree),</span><span style="color:#F69D50;">linewidth</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> width)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.plot(X,y,</span><span style="color:#96D0FF;">&#39;b.&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.axis([</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#F47067;">-</span><span style="color:#6CB6FF;">5</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.legend()</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># 特征变换的越复杂，得到的结果过拟合风险越高，不建议做的特别复杂。</span></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> sklearn.pipeline </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> Pipeline</span></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> sklearn.preprocessing </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> StandardScaler</span></span>
<span class="line"><span style="color:#24292E;">plt.figure(</span><span style="color:#E36209;">figsize</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">12</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">6</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> style,width,degree </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> ((</span><span style="color:#032F62;">&#39;g-&#39;</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">),(</span><span style="color:#032F62;">&#39;b--&#39;</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">),(</span><span style="color:#032F62;">&#39;r-+&#39;</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)):</span></span>
<span class="line"><span style="color:#24292E;">    poly_features </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> PolynomialFeatures(</span><span style="color:#E36209;">degree</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> degree,</span><span style="color:#E36209;">include_bias</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    std </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> StandardScaler()</span></span>
<span class="line"><span style="color:#24292E;">    lin_reg </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression()</span></span>
<span class="line"><span style="color:#24292E;">    polynomial_reg </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> Pipeline([(</span><span style="color:#032F62;">&#39;poly_features&#39;</span><span style="color:#24292E;">,poly_features),</span></span>
<span class="line"><span style="color:#24292E;">             (</span><span style="color:#032F62;">&#39;StandardScaler&#39;</span><span style="color:#24292E;">,std),</span></span>
<span class="line"><span style="color:#24292E;">             (</span><span style="color:#032F62;">&#39;lin_reg&#39;</span><span style="color:#24292E;">,lin_reg)])</span></span>
<span class="line"><span style="color:#24292E;">    polynomial_reg.fit(X,y)</span></span>
<span class="line"><span style="color:#24292E;">    y_new_2 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> polynomial_reg.predict(X_new)</span></span>
<span class="line"><span style="color:#24292E;">    plt.plot(X_new,y_new_2,style,</span><span style="color:#E36209;">label</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;degree   &#39;</span><span style="color:#D73A49;">+</span><span style="color:#005CC5;">str</span><span style="color:#24292E;">(degree),</span><span style="color:#E36209;">linewidth</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> width)</span></span>
<span class="line"><span style="color:#24292E;">plt.plot(X,y,</span><span style="color:#032F62;">&#39;b.&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plt.axis([</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">5</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#24292E;">plt.legend()</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%907.png" alt=""></p><h3 id="数据样本数量对结果的影响" tabindex="-1">数据样本数量对结果的影响 <a class="header-anchor" href="#数据样本数量对结果的影响" aria-label="Permalink to &quot;数据样本数量对结果的影响&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> sklearn.metrics </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> mean_squared_error</span></span>
<span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> sklearn.model_selection </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> train_test_split</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">plot_learning_curves</span><span style="color:#ADBAC7;">(model,X,y):</span></span>
<span class="line"><span style="color:#ADBAC7;">    X_train, X_val, y_train, y_val </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> train_test_split(X,y,</span><span style="color:#F69D50;">test_size</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.2</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">random_state</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    train_errors,val_errors </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> [],[]</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> m </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">range</span><span style="color:#ADBAC7;">(</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">len</span><span style="color:#ADBAC7;">(X_train)):</span></span>
<span class="line"><span style="color:#ADBAC7;">        model.fit(X_train[:m],y_train[:m])</span></span>
<span class="line"><span style="color:#ADBAC7;">        y_train_predict </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> model.predict(X_train[:m])</span></span>
<span class="line"><span style="color:#ADBAC7;">        y_val_predict </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> model.predict(X_val)</span></span>
<span class="line"><span style="color:#ADBAC7;">        train_errors.append(mean_squared_error(y_train[:m],y_train_predict[:m]))</span></span>
<span class="line"><span style="color:#ADBAC7;">        val_errors.append(mean_squared_error(y_val,y_val_predict))</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.plot(np.sqrt(train_errors),</span><span style="color:#96D0FF;">&#39;r-+&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">linewidth</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">label</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;train_error&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.plot(np.sqrt(val_errors),</span><span style="color:#96D0FF;">&#39;b-&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">linewidth</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">label</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;val_error&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.xlabel(</span><span style="color:#96D0FF;">&#39;Trainsing set size&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.ylabel(</span><span style="color:#96D0FF;">&#39;RMSE&#39;</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.legend()</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span></span>
<span class="line"><span style="color:#768390;"># 数据量越少，训练集的效果会越好，但是实际测试效果很一般。实际做模型的时候需要参考测试集和验证集的效果。</span></span>
<span class="line"><span style="color:#ADBAC7;">lin_reg </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> LinearRegression()</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_learning_curves(lin_reg,X,y)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.axis([</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">80</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">3.3</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> sklearn.metrics </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> mean_squared_error</span></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> sklearn.model_selection </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> train_test_split</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">plot_learning_curves</span><span style="color:#24292E;">(model,X,y):</span></span>
<span class="line"><span style="color:#24292E;">    X_train, X_val, y_train, y_val </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> train_test_split(X,y,</span><span style="color:#E36209;">test_size</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.2</span><span style="color:#24292E;">,</span><span style="color:#E36209;">random_state</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    train_errors,val_errors </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [],[]</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> m </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">len</span><span style="color:#24292E;">(X_train)):</span></span>
<span class="line"><span style="color:#24292E;">        model.fit(X_train[:m],y_train[:m])</span></span>
<span class="line"><span style="color:#24292E;">        y_train_predict </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> model.predict(X_train[:m])</span></span>
<span class="line"><span style="color:#24292E;">        y_val_predict </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> model.predict(X_val)</span></span>
<span class="line"><span style="color:#24292E;">        train_errors.append(mean_squared_error(y_train[:m],y_train_predict[:m]))</span></span>
<span class="line"><span style="color:#24292E;">        val_errors.append(mean_squared_error(y_val,y_val_predict))</span></span>
<span class="line"><span style="color:#24292E;">    plt.plot(np.sqrt(train_errors),</span><span style="color:#032F62;">&#39;r-+&#39;</span><span style="color:#24292E;">,</span><span style="color:#E36209;">linewidth</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span><span style="color:#E36209;">label</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;train_error&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    plt.plot(np.sqrt(val_errors),</span><span style="color:#032F62;">&#39;b-&#39;</span><span style="color:#24292E;">,</span><span style="color:#E36209;">linewidth</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#E36209;">label</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;val_error&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    plt.xlabel(</span><span style="color:#032F62;">&#39;Trainsing set size&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    plt.ylabel(</span><span style="color:#032F62;">&#39;RMSE&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    plt.legend()</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#6A737D;"># 数据量越少，训练集的效果会越好，但是实际测试效果很一般。实际做模型的时候需要参考测试集和验证集的效果。</span></span>
<span class="line"><span style="color:#24292E;">lin_reg </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LinearRegression()</span></span>
<span class="line"><span style="color:#24292E;">plot_learning_curves(lin_reg,X,y)</span></span>
<span class="line"><span style="color:#24292E;">plt.axis([</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">80</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">3.3</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%908.png" alt=""></p><h3 id="多项式回归的过拟合风险" tabindex="-1">多项式回归的过拟合风险 <a class="header-anchor" href="#多项式回归的过拟合风险" aria-label="Permalink to &quot;多项式回归的过拟合风险&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#768390;"># 越复杂 越拟合</span></span>
<span class="line"><span style="color:#ADBAC7;">polynomial_reg </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> Pipeline([(</span><span style="color:#96D0FF;">&#39;poly_features&#39;</span><span style="color:#ADBAC7;">,PolynomialFeatures(</span><span style="color:#F69D50;">degree</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">25</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">include_bias</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">False</span><span style="color:#ADBAC7;">)),</span></span>
<span class="line"><span style="color:#ADBAC7;">             (</span><span style="color:#96D0FF;">&#39;lin_reg&#39;</span><span style="color:#ADBAC7;">,LinearRegression())])</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_learning_curves(polynomial_reg,X,y)</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.axis([</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">80</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">5</span><span style="color:#ADBAC7;">])</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># 越复杂 越拟合</span></span>
<span class="line"><span style="color:#24292E;">polynomial_reg </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> Pipeline([(</span><span style="color:#032F62;">&#39;poly_features&#39;</span><span style="color:#24292E;">,PolynomialFeatures(</span><span style="color:#E36209;">degree</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">25</span><span style="color:#24292E;">,</span><span style="color:#E36209;">include_bias</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)),</span></span>
<span class="line"><span style="color:#24292E;">             (</span><span style="color:#032F62;">&#39;lin_reg&#39;</span><span style="color:#24292E;">,LinearRegression())])</span></span>
<span class="line"><span style="color:#24292E;">plot_learning_curves(polynomial_reg,X,y)</span></span>
<span class="line"><span style="color:#24292E;">plt.axis([</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">80</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">5</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%909.png" alt=""></p><h3 id="正则化" tabindex="-1">正则化 <a class="header-anchor" href="#正则化" aria-label="Permalink to &quot;正则化&quot;">​</a></h3><p>对权重参数进行惩罚，让权重参数尽可能平滑一些，有两种不同的方法来进行正则化惩罚:</p><p><img src="https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%9010.png" alt=""></p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> sklearn.linear_model </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> Ridge</span></span>
<span class="line"><span style="color:#ADBAC7;">np.random.seed(</span><span style="color:#6CB6FF;">42</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">m </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">20</span></span>
<span class="line"><span style="color:#ADBAC7;">X </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">3</span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;">np.random.rand(m,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">y </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0.5</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">*</span><span style="color:#ADBAC7;"> X </span><span style="color:#F47067;">+</span><span style="color:#ADBAC7;">np.random.randn(m,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span><span style="color:#F47067;">/</span><span style="color:#6CB6FF;">1.5</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">+</span><span style="color:#6CB6FF;">1</span></span>
<span class="line"><span style="color:#ADBAC7;">X_new </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> np.linspace(</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">).reshape(</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F47067;">def</span><span style="color:#ADBAC7;"> </span><span style="color:#DCBDFB;">plot_model</span><span style="color:#ADBAC7;">(model_calss,polynomial,alphas,</span><span style="color:#F47067;">**</span><span style="color:#ADBAC7;">model_kargs):</span></span>
<span class="line"><span style="color:#ADBAC7;">    </span><span style="color:#F47067;">for</span><span style="color:#ADBAC7;"> alpha,style </span><span style="color:#F47067;">in</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">zip</span><span style="color:#ADBAC7;">(alphas,(</span><span style="color:#96D0FF;">&#39;b-&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#96D0FF;">&#39;g--&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#96D0FF;">&#39;r:&#39;</span><span style="color:#ADBAC7;">)):</span></span>
<span class="line"><span style="color:#ADBAC7;">        model </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> model_calss(alpha,</span><span style="color:#F47067;">**</span><span style="color:#ADBAC7;">model_kargs)</span></span>
<span class="line"><span style="color:#ADBAC7;">        </span><span style="color:#F47067;">if</span><span style="color:#ADBAC7;"> polynomial:</span></span>
<span class="line"><span style="color:#ADBAC7;">            model </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> Pipeline([(</span><span style="color:#96D0FF;">&#39;poly_features&#39;</span><span style="color:#ADBAC7;">,PolynomialFeatures(</span><span style="color:#F69D50;">degree</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">include_bias</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">False</span><span style="color:#ADBAC7;">)),</span></span>
<span class="line"><span style="color:#ADBAC7;">             (</span><span style="color:#96D0FF;">&#39;StandardScaler&#39;</span><span style="color:#ADBAC7;">,StandardScaler()),</span></span>
<span class="line"><span style="color:#ADBAC7;">             (</span><span style="color:#96D0FF;">&#39;lin_reg&#39;</span><span style="color:#ADBAC7;">,model)])</span></span>
<span class="line"><span style="color:#ADBAC7;">        model.fit(X,y)</span></span>
<span class="line"><span style="color:#ADBAC7;">        y_new_regul </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> model.predict(X_new)</span></span>
<span class="line"><span style="color:#ADBAC7;">        lw </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">2</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">if</span><span style="color:#ADBAC7;"> alpha </span><span style="color:#F47067;">&gt;</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">else</span><span style="color:#ADBAC7;"> </span><span style="color:#6CB6FF;">1</span></span>
<span class="line"><span style="color:#ADBAC7;">        plt.plot(X_new,y_new_regul,style,</span><span style="color:#F69D50;">linewidth</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> lw,</span><span style="color:#F69D50;">label</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> </span><span style="color:#96D0FF;">&#39;alpha = </span><span style="color:#F47067;">{}</span><span style="color:#96D0FF;">&#39;</span><span style="color:#ADBAC7;">.format(alpha))</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.plot(X,y,</span><span style="color:#96D0FF;">&#39;b.&#39;</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">linewidth</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">3</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">    plt.legend()</span></span>
<span class="line"><span style="color:#ADBAC7;"> </span></span>
<span class="line"><span style="color:#ADBAC7;">plt.figure(</span><span style="color:#F69D50;">figsize</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">(</span><span style="color:#6CB6FF;">14</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">6</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.subplot(</span><span style="color:#6CB6FF;">121</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_model(Ridge,</span><span style="color:#F69D50;">polynomial</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">False</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">alphas</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> (</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">10</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">100</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.subplot(</span><span style="color:#6CB6FF;">122</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_model(Ridge,</span><span style="color:#F69D50;">polynomial</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">True</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">alphas</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> (</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">10</span><span style="color:#F47067;">**-</span><span style="color:#6CB6FF;">5</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> sklearn.linear_model </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> Ridge</span></span>
<span class="line"><span style="color:#24292E;">np.random.seed(</span><span style="color:#005CC5;">42</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">m </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">20</span></span>
<span class="line"><span style="color:#24292E;">X </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">3</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">np.random.rand(m,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">y </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0.5</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> X </span><span style="color:#D73A49;">+</span><span style="color:#24292E;">np.random.randn(m,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span><span style="color:#D73A49;">/</span><span style="color:#005CC5;">1.5</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">+</span><span style="color:#005CC5;">1</span></span>
<span class="line"><span style="color:#24292E;">X_new </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> np.linspace(</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">).reshape(</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">plot_model</span><span style="color:#24292E;">(model_calss,polynomial,alphas,</span><span style="color:#D73A49;">**</span><span style="color:#24292E;">model_kargs):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> alpha,style </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">zip</span><span style="color:#24292E;">(alphas,(</span><span style="color:#032F62;">&#39;b-&#39;</span><span style="color:#24292E;">,</span><span style="color:#032F62;">&#39;g--&#39;</span><span style="color:#24292E;">,</span><span style="color:#032F62;">&#39;r:&#39;</span><span style="color:#24292E;">)):</span></span>
<span class="line"><span style="color:#24292E;">        model </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> model_calss(alpha,</span><span style="color:#D73A49;">**</span><span style="color:#24292E;">model_kargs)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> polynomial:</span></span>
<span class="line"><span style="color:#24292E;">            model </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> Pipeline([(</span><span style="color:#032F62;">&#39;poly_features&#39;</span><span style="color:#24292E;">,PolynomialFeatures(</span><span style="color:#E36209;">degree</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">,</span><span style="color:#E36209;">include_bias</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)),</span></span>
<span class="line"><span style="color:#24292E;">             (</span><span style="color:#032F62;">&#39;StandardScaler&#39;</span><span style="color:#24292E;">,StandardScaler()),</span></span>
<span class="line"><span style="color:#24292E;">             (</span><span style="color:#032F62;">&#39;lin_reg&#39;</span><span style="color:#24292E;">,model)])</span></span>
<span class="line"><span style="color:#24292E;">        model.fit(X,y)</span></span>
<span class="line"><span style="color:#24292E;">        y_new_regul </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> model.predict(X_new)</span></span>
<span class="line"><span style="color:#24292E;">        lw </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">2</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> alpha </span><span style="color:#D73A49;">&gt;</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">0</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">else</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1</span></span>
<span class="line"><span style="color:#24292E;">        plt.plot(X_new,y_new_regul,style,</span><span style="color:#E36209;">linewidth</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> lw,</span><span style="color:#E36209;">label</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;alpha = </span><span style="color:#005CC5;">{}</span><span style="color:#032F62;">&#39;</span><span style="color:#24292E;">.format(alpha))</span></span>
<span class="line"><span style="color:#24292E;">    plt.plot(X,y,</span><span style="color:#032F62;">&#39;b.&#39;</span><span style="color:#24292E;">,</span><span style="color:#E36209;">linewidth</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    plt.legend()</span></span>
<span class="line"><span style="color:#24292E;"> </span></span>
<span class="line"><span style="color:#24292E;">plt.figure(</span><span style="color:#E36209;">figsize</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">14</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">6</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.subplot(</span><span style="color:#005CC5;">121</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plot_model(Ridge,</span><span style="color:#E36209;">polynomial</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">,</span><span style="color:#E36209;">alphas</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> (</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">100</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.subplot(</span><span style="color:#005CC5;">122</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plot_model(Ridge,</span><span style="color:#E36209;">polynomial</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">,</span><span style="color:#E36209;">alphas</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> (</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">10</span><span style="color:#D73A49;">**-</span><span style="color:#005CC5;">5</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%9011.png" alt=""></p><p>惩罚力度越大，alpha值越大的时候，得到的决策方程越平稳。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark-dimmed vp-code-dark"><code><span class="line"><span style="color:#F47067;">from</span><span style="color:#ADBAC7;"> sklearn.linear_model </span><span style="color:#F47067;">import</span><span style="color:#ADBAC7;"> Lasso</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ADBAC7;">plt.figure(</span><span style="color:#F69D50;">figsize</span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;">(</span><span style="color:#6CB6FF;">14</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">6</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.subplot(</span><span style="color:#6CB6FF;">121</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_model(Lasso,</span><span style="color:#F69D50;">polynomial</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">False</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">alphas</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> (</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">0.1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.subplot(</span><span style="color:#6CB6FF;">122</span><span style="color:#ADBAC7;">)</span></span>
<span class="line"><span style="color:#ADBAC7;">plot_model(Lasso,</span><span style="color:#F69D50;">polynomial</span><span style="color:#F47067;">=</span><span style="color:#6CB6FF;">True</span><span style="color:#ADBAC7;">,</span><span style="color:#F69D50;">alphas</span><span style="color:#ADBAC7;"> </span><span style="color:#F47067;">=</span><span style="color:#ADBAC7;"> (</span><span style="color:#6CB6FF;">0</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">10</span><span style="color:#F47067;">**-</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">,</span><span style="color:#6CB6FF;">1</span><span style="color:#ADBAC7;">))</span></span>
<span class="line"><span style="color:#ADBAC7;">plt.show()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> sklearn.linear_model </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> Lasso</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">plt.figure(</span><span style="color:#E36209;">figsize</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">14</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">6</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.subplot(</span><span style="color:#005CC5;">121</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plot_model(Lasso,</span><span style="color:#E36209;">polynomial</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">,</span><span style="color:#E36209;">alphas</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> (</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">0.1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.subplot(</span><span style="color:#005CC5;">122</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">plot_model(Lasso,</span><span style="color:#E36209;">polynomial</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">,</span><span style="color:#E36209;">alphas</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> (</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">10</span><span style="color:#D73A49;">**-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))</span></span>
<span class="line"><span style="color:#24292E;">plt.show()</span></span></code></pre></div><p><img src="https://cdn.staticaly.com/gh/clint-sfy/blogcdn@master/python/ML/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%9012.png" alt=""></p></div></div></main><footer class="VPDocFooter" data-v-48b5bc29 data-v-1b7f98f6><!--[--><!--[--><!--[--><!--[--><!----><!--]--><!--]--><!--]--><!--]--><div class="edit-info" data-v-1b7f98f6><div class="edit-link" data-v-1b7f98f6><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/clint-sfy/clintsfy.github.io/edit/main/docs/courses/tangyudi/02-机器学习篇/01-线性回归.md" target="_blank" rel="noreferrer" data-v-1b7f98f6><!--[--><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" class="edit-link-icon" aria-label="edit icon" data-v-1b7f98f6><path d="M18,23H4c-1.7,0-3-1.3-3-3V6c0-1.7,1.3-3,3-3h7c0.6,0,1,0.4,1,1s-0.4,1-1,1H4C3.4,5,3,5.4,3,6v14c0,0.6,0.4,1,1,1h14c0.6,0,1-0.4,1-1v-7c0-0.6,0.4-1,1-1s1,0.4,1,1v7C21,21.7,19.7,23,18,23z"></path><path d="M8,17c-0.3,0-0.5-0.1-0.7-0.3C7,16.5,6.9,16.1,7,15.8l1-4c0-0.2,0.1-0.3,0.3-0.5l9.5-9.5c1.2-1.2,3.2-1.2,4.4,0c1.2,1.2,1.2,3.2,0,4.4l-9.5,9.5c-0.1,0.1-0.3,0.2-0.5,0.3l-4,1C8.2,17,8.1,17,8,17zM9.9,12.5l-0.5,2.1l2.1-0.5l9.3-9.3c0.4-0.4,0.4-1.1,0-1.6c-0.4-0.4-1.2-0.4-1.6,0l0,0L9.9,12.5z M18.5,2.5L18.5,2.5L18.5,2.5z"></path></svg> 不妥之处，敬请雅正<!--]--></a></div><div class="last-updated" data-v-1b7f98f6><p class="VPLastUpdated" data-v-1b7f98f6 data-v-d84b8284>最后更新: <time datetime="2023-08-06T13:08:54.000Z" data-v-d84b8284></time></p></div></div><nav class="prev-next" data-v-1b7f98f6><div class="pager" data-v-1b7f98f6><a class="pager-link prev" href="/courses/tangyudi/01-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%AF%87/16-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E6%9E%90" data-v-1b7f98f6><span class="desc" data-v-1b7f98f6>上一篇</span><span class="title" data-v-1b7f98f6><div class="text-color-gray mr-[6px]" style="font-weight: 550; display: inline-block;">16</div>贝叶斯分析</span></a></div><div class="pager" data-v-1b7f98f6><a class="pager-link next" href="/courses/tangyudi/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AF%87/02-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95" data-v-1b7f98f6><span class="desc" data-v-1b7f98f6>下一篇</span><span class="title" data-v-1b7f98f6><div class="text-color-orange mr-[6px]" style="font-weight: 550; display: inline-block;">2</div>模型评估方法</span></a></div></nav></footer><!--[--><!--[--><!--[--><div id="comment-container"></div><!--]--><!--]--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"about_donate.md\":\"c9422694\",\"about_archives.md\":\"6de7a81d\",\"about_index.md\":\"10805d55\",\"archives.md\":\"92a42cb0\",\"about_see.md\":\"261cfb5b\",\"about_me.md\":\"29b053c1\",\"categories_chatgpt_02-chatgpt_03-ai做ppt.md\":\"d16f43d8\",\"categories_chatgpt_01-chatgpt开源项目_01-gpt项目.md\":\"90ae0368\",\"categories_chatgpt_02-chatgpt_01-角色扮演.md\":\"76940585\",\"categories_chatgpt_02-chatgpt_02-学术提示词.md\":\"a281fb08\",\"categories_issues_2021_12_08_for循环中删除集合元素隐藏的陷阱.md\":\"d112429d\",\"categories_chatgpt_02-chatgpt_04-ai编写java项目.md\":\"4f8d18cd\",\"categories_issues_2021_12_01_f盘上的回收站已损坏。是否清空该驱动器上的回收站.md\":\"da0fee6c\",\"categories_chatgpt_01-chatgpt开源项目_02-gpt学术项目.md\":\"78c61d95\",\"categories_issues_2021_12_13_无法访问f盘。文件或目录损坏且无法读取.md\":\"30e246a5\",\"categories_issues_2021_12_10_command line is too long. shorten command line for xxx or also for spring boot default configuration.md\":\"0a4c5964\",\"categories_issues_2022_08_11_执行shell脚本，报java command not found.md\":\"52ee5f37\",\"categories_issues_2022_03_24_创建一个自身类的静态对象变量，究竟会如何执行？.md\":\"01c94983\",\"categories_issues_2021_12_11_sql 注入攻击风险.md\":\"256fae1e\",\"categories_issues_2022_01_26_javascript 无法存储 java  long 类型数据问题.md\":\"c006d47d\",\"categories_issues_2022_09_05_nginx转发请求，报13：permission denied错误.md\":\"0a9a98cc\",\"categories_issues_2022_08_31_springboot项目引入openfeign后无法启动.md\":\"2b432f80\",\"categories_issues_2022_10_25_解决centos8执行yum安装报错.md\":\"001fb639\",\"categories_issues_2022_10_15_解决windows桌面部分快捷方式图标变为空白的问题.md\":\"8b2db978\",\"categories_issues_2022_11_06_解决dotnet安装后报错的问题.md\":\"54c4e042\",\"categories_issues_2022_10_29_docker设置网络代理.md\":\"7b600694\",\"categories_issues_2022_11_04_解决docker安装prometheus启动报错的问题.md\":\"217a006f\",\"categories_issues_2022_09_23_解决无法重复读取请求体和响应体的问题.md\":\"e4d80235\",\"courses_c_01-c语言基础_02-数组.md\":\"03535c16\",\"categories_issues_index.md\":\"0d504811\",\"courses_c_01-c语言基础_01-c语言基础概述.md\":\"d676a58a\",\"categories_issues_2022_11_23_解决maven传递依赖污染的问题.md\":\"04ea7db1\",\"courses_c_01-c语言基础_06-动态内存申请.md\":\"a0b786bc\",\"courses_c_01-c语言基础_03-函数.md\":\"ab9c55e0\",\"courses_c_01-c语言基础_05-指针.md\":\"ff5aa88c\",\"courses_c_01-c语言基础_04-预处理.md\":\"a864e152\",\"courses_c_01-c语言基础_07-字符串处理函数.md\":\"4622284c\",\"courses_c_01-c语言基础_08-结构体.md\":\"a2ddb074\",\"courses_c_index.md\":\"3544ddc6\",\"courses_c_01-c语言基础_10-文件.md\":\"c1317cd8\",\"courses_c_01-c语言基础_11-makefile.md\":\"4fb3f5e8\",\"courses_c_plus_01-c__的基础_01-c__对c的扩展.md\":\"5ca6700f\",\"courses_c_01-c语言基础_09-链表.md\":\"ae312288\",\"courses_c_plus_01-c__的基础_02-c__类和对象.md\":\"5fedb2f2\",\"courses_c_plus_01-c__的基础_04-c__类型转换.md\":\"0a4ba8f2\",\"courses_c_plus_01-c__的基础_05-c__异常.md\":\"88ef74cf\",\"courses_c_plus_02-c__的stl_01-c__stl.md\":\"fcd57999\",\"courses_c_plus_02-c__的stl_02-string容器.md\":\"01557fa9\",\"courses_c_plus_02-c__的stl_07-list容器.md\":\"5ff94548\",\"courses_c_plus_02-c__的stl_05-stack容器.md\":\"4a4a2a52\",\"courses_c_plus_02-c__的stl_06-queue容器.md\":\"218947f1\",\"courses_tangyudi_01-数学基础篇_02-微积分.md\":\"01797136\",\"courses_tangyudi_01-数学基础篇_03-泰勒公式和拉格朗日.md\":\"2dfdd977\",\"courses_tangyudi_01-数学基础篇_04-线性代数基础.md\":\"29657563\",\"courses_tangyudi_01-数学基础篇_05-特征值与矩阵分解.md\":\"6be6232f\",\"courses_tangyudi_01-数学基础篇_06-随机变量.md\":\"2c29e274\",\"courses_tangyudi_01-数学基础篇_07-概率论基础.md\":\"75a635e6\",\"courses_tangyudi_01-数学基础篇_09-核函数变换.md\":\"b9546e20\",\"courses_yuanzi_03-qt应用开发和部署_02-按钮.md\":\"7b74d15e\",\"courses_yuanzi_03-qt应用开发和部署_03-输入窗口部件.md\":\"4828f333\",\"courses_yuanzi_03-qt应用开发和部署_04-显示窗口部件.md\":\"1828d015\",\"courses_yuanzi_03-qt应用开发和部署_05-布局管理.md\":\"3e8dfa3f\",\"index.md\":\"4c6b84cd\",\"introduction.md\":\"bdb48f22\",\"my_project_01-project_01-项目1_01-介绍.md\":\"297b1e3b\",\"courses_tangyudi_03-深度学习篇_04-yolo.md\":\"d1a0718f\",\"courses_python_01-python基础篇_01-python基础.md\":\"27d99404\",\"courses_tangyudi_03-深度学习篇_03-opencv.md\":\"cdb7c57f\",\"courses_tangyudi_01-数学基础篇_10-熵与激活函数.md\":\"fe2a3ec9\",\"courses_tangyudi_01-数学基础篇_13-相关分析.md\":\"133dffd2\",\"courses_c_plus_02-c__的stl_09-map容器.md\":\"23fe4b54\",\"courses_tangyudi_01-数学基础篇_16-贝叶斯分析.md\":\"39c53b59\",\"courses_tangyudi_01-数学基础篇_14-方差分析.md\":\"df819225\",\"courses_tangyudi_02-机器学习篇_04-聚类算法.md\":\"f4c15bba\",\"courses_tangyudi_01-数学基础篇_15-聚类分析.md\":\"94ea83a4\",\"courses_c_plus_02-c__的stl_04-deque容器.md\":\"350f8c3e\",\"courses_c_plus_index.md\":\"ab462b93\",\"courses_tangyudi_02-机器学习篇_02-模型评估方法.md\":\"87c1fb6c\",\"courses_tangyudi_02-机器学习篇_05-决策树.md\":\"af3bc8ba\",\"courses_tangyudi_01-数学基础篇_11-回归分析.md\":\"8dec020c\",\"courses_c_plus_02-c__的stl_08-set容器.md\":\"947b4983\",\"courses_c_plus_02-c__的stl_03-vector容器.md\":\"ae12ed1f\",\"my_project_01-project_02-项目2_02-介绍.md\":\"d8f34795\",\"courses_tangyudi_02-机器学习篇_08-神经网络.md\":\"d21d441c\",\"courses_tangyudi_02-机器学习篇_10-关联规则.md\":\"9e382d0f\",\"my_project_01-project_03-项目3_03-介绍.md\":\"02aed625\",\"courses_tangyudi_02-机器学习篇_07-支持向量机.md\":\"2b1ec0b3\",\"courses_python_02-python进阶篇_01-numpy.md\":\"4ce77612\",\"courses_c_plus_02-c__的stl_10-其他补充.md\":\"1372c656\",\"courses_tangyudi_01-数学基础篇_08-几种分布.md\":\"3014eea9\",\"courses_tangyudi_02-机器学习篇_11-词向量.md\":\"cdba8cba\",\"courses_python_02-python进阶篇_02-pandas.md\":\"e7762c38\",\"courses_tangyudi_03-深度学习篇_02-mmlab实战.md\":\"373bc6f6\",\"courses_tangyudi_02-机器学习篇_01-线性回归.md\":\"6dffb065\",\"courses_yuanzi_03-qt应用开发和部署_07-项目式视图组（基于模型）.md\":\"4eeff5e4\",\"courses_yuanzi_03-qt应用开发和部署_08-项目控制组（基于项）.md\":\"faa33769\",\"courses_yuanzi_03-qt应用开发和部署_09-文本读写.md\":\"8a75a832\",\"courses_tangyudi_01-数学基础篇_01-高等数学基础.md\":\"9a2d2863\",\"courses_yuanzi_03-qt应用开发和部署_10-绘图与图表.md\":\"5d4c9dff\",\"courses_c_plus_01-c__的基础_03-c__模板.md\":\"6c569931\",\"courses_tangyudi_02-机器学习篇_06-集成算法.md\":\"5369c526\",\"courses_yuanzi_03-qt应用开发和部署_11-多线程.md\":\"8e1e2213\",\"courses_tangyudi_02-机器学习篇_09-贝叶斯.md\":\"2ba3440c\",\"courses_yuanzi_03-qt应用开发和部署_06-容器.md\":\"b7372cbe\",\"courses_python_02-python进阶篇_03-matplotlib.md\":\"f8148578\",\"courses_tangyudi_02-机器学习篇_03-逻辑回归.md\":\"9fb0c385\",\"courses_yuanzi_03-qt应用开发和部署_01-linux安装qt.md\":\"be7620f9\",\"courses_python_02-python进阶篇_04-seaborn.md\":\"3d5eed21\",\"courses_tangyudi_02-机器学习篇_12-降维.md\":\"329c2246\",\"courses_yuanzi_03-qt应用开发和部署_13-udp通信.md\":\"3f0bbf13\",\"courses_c_plus_02-c__的stl_11-常见算法.md\":\"a50202be\",\"courses_tangyudi_01-数学基础篇_12-假设检验.md\":\"279ba430\",\"courses_yuanzi_03-qt应用开发和部署_12-tcp通信.md\":\"24501abe\",\"courses_tangyudi_03-深度学习篇_01-pytorch.md\":\"504c4e5e\",\"tags.md\":\"26fef91a\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh-CN\",\"dir\":\"ltr\",\"title\":\"阿源的知识库\",\"description\":\"个人技术知识库，记录 & 分享个人碎片化、结构化、体系化的技术知识内容。\",\"base\":\"/\",\"head\":[],\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"首页\",\"link\":\"/introduction\",\"activeMatch\":\"/introduction\"},{\"text\":\"项目文档\",\"link\":\"/my_project/01-project/01-项目1/01-介绍.md\",\"activeMatch\":\"/my_project/\"},{\"text\":\"前沿 & 工作\",\"items\":[{\"text\":\"Bug万象集\",\"link\":\"/categories/issues/index\",\"activeMatch\":\"/categories/issues/\"},{\"text\":\"ChatGPT\",\"link\":\"/categories/chatgpt/01-ChatGPT开源项目/01-GPT项目\",\"activeMatch\":\"/categories/chatgpt/\"}],\"activeMatch\":\"/categories/\"},{\"text\":\"学习笔记\",\"items\":[{\"text\":\"C语言基础快速入门\",\"link\":\"/courses/c/index\",\"activeMatch\":\"/courses/c/\"},{\"text\":\"C++基础快速入门\",\"link\":\"/courses/c_plus/01-C++的基础/01-c++对c的扩展\",\"activeMatch\":\"/courses/c_plus/\"},{\"text\":\"Python基础快速入门\",\"link\":\"/courses/python/01-python基础篇/01-python基础\",\"activeMatch\":\"/courses/python/\"},{\"text\":\"唐宇迪AI课程\",\"link\":\"/courses/tangyudi/02-机器学习篇/01-线性回归\",\"activeMatch\":\"/courses/tangyudi/\"},{\"text\":\"正点原子Linux课程\",\"link\":\"/courses/yuanzi/03-QT应用开发和部署/01-linux安装qt.md\",\"activeMatch\":\"/courses/yuanzi/\"}],\"activeMatch\":\"/courses/\"},{\"text\":\"我的标签\",\"link\":\"/tags\",\"activeMatch\":\"/tags\"},{\"text\":\"关于\",\"items\":[{\"text\":\"关于知识库\",\"link\":\"/about/index\",\"activeMatch\":\"/about/index\"},{\"text\":\"关于我\",\"link\":\"/about/me\",\"activeMatch\":\"/about/me\"},{\"text\":\"赞助\",\"link\":\"/about/donate\",\"activeMatch\":\"/about/donate\"},{\"text\":\"在线体验\",\"link\":\"/about/see\",\"activeMatch\":\"/about/see\"},{\"text\":\"我的归档\",\"link\":\"/archives\",\"activeMatch\":\"/archives\"}],\"activeMatch\":\"/about/\"}],\"sidebar\":{\"/my_project/01-project/\":[{\"text\":\"项目1 (1篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>项目1\",\"link\":\"/my_project/01-project/01-项目1/01-介绍\"}],\"collapsed\":true},{\"text\":\"项目2 (1篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>项目2\",\"link\":\"/my_project/01-project/02-项目2/02-介绍\"}],\"collapsed\":true},{\"text\":\"项目3 (1篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>项目3\",\"link\":\"/my_project/01-project/03-项目3/03-介绍\"}],\"collapsed\":true}],\"/categories/issues/\":[{\"text\":\"<img class=\\\"chinese-zodiac\\\" style=\\\"position: static; vertical-align: middle; padding-bottom: 3px;\\\" src=\\\"/img/svg/chinese-zodiac/tiger.svg\\\" title=\\\"虎年\\\" alt=\\\"生肖\\\">\\n            2022年 (12篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>解决 Maven 传递依赖污染的问题\",\"link\":\"/categories/issues/2022/11/23/解决Maven传递依赖污染的问题\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>解决 DotNet 安装完，报错\",\"link\":\"/categories/issues/2022/11/06/解决DotNET安装后报错的问题\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>解决 Docker 安装 Prometheus 启动报 permission denied 的问题\",\"link\":\"/categories/issues/2022/11/04/解决Docker安装Prometheus启动报错的问题\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>Docker 设置网络代理\",\"link\":\"/categories/issues/2022/10/29/Docker设置网络代理\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>解决 CentOS 8 执行 yum install 报 Error\",\"link\":\"/categories/issues/2022/10/25/解决CentOS8执行yum安装报错\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">6</div>解决 Windows 桌面部分快捷方式图标变为空白的问题\",\"link\":\"/categories/issues/2022/10/15/解决Windows桌面部分快捷方式图标变为空白的问题\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">7</div>解决无法重复读取请求体和响应体的问题\",\"link\":\"/categories/issues/2022/09/23/解决无法重复读取请求体和响应体的问题\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">8</div>Nginx转发请求，报13：Permission denied错误\",\"link\":\"/categories/issues/2022/09/05/Nginx转发请求，报13：Permission denied错误\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">9</div>SpringBoot项目引入OpenFeign后无法启动\",\"link\":\"/categories/issues/2022/08/31/SpringBoot项目引入OpenFeign后无法启动\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">10</div>执行Shell脚本，报java: command not found\",\"link\":\"/categories/issues/2022/08/11/执行Shell脚本，报java command not found\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">11</div>创建一个自身类的静态对象变量，究竟会如何执行？\",\"link\":\"/categories/issues/2022/03/24/创建一个自身类的静态对象变量，究竟会如何执行？\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">12</div>JavaScript 无法存储 Java Long 类型数据问题\",\"link\":\"/categories/issues/2022/01/26/JavaScript 无法存储 Java  Long 类型数据问题\"}],\"collapsed\":false},{\"text\":\"<img class=\\\"chinese-zodiac\\\" style=\\\"position: static; vertical-align: middle; padding-bottom: 3px;\\\" src=\\\"/img/svg/chinese-zodiac/ox.svg\\\" title=\\\"牛年\\\" alt=\\\"生肖\\\">\\n            2021年 (5篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>无法访问 F:\\\\。文件或目录损坏且无法读取。\",\"link\":\"/categories/issues/2021/12/13/无法访问F盘。文件或目录损坏且无法读取\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>SQL 注入攻击风险\",\"link\":\"/categories/issues/2021/12/11/SQL 注入攻击风险\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>Command line is too long. Shorten command line for XXX or also for Spring Boot default configuration？\",\"link\":\"/categories/issues/2021/12/10/Command line is too long. Shorten command line for XXX or also for Spring Boot default configuration\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>for循环中删除集合元素隐藏的陷阱\",\"link\":\"/categories/issues/2021/12/08/for循环中删除集合元素隐藏的陷阱\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>F:\\\\ 上的回收站已损坏。是否清空该驱动器上的\\\"回收站\\\"?\",\"link\":\"/categories/issues/2021/12/01/F盘上的回收站已损坏。是否清空该驱动器上的回收站\"}],\"collapsed\":true}],\"/categories/chatgpt/\":[{\"text\":\"ChatGPT开源项目 (2篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>Gpt项目\",\"link\":\"/categories/chatgpt/01-ChatGPT开源项目/01-GPT项目\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>Gpt学术版项目\",\"link\":\"/categories/chatgpt/01-ChatGPT开源项目/02-GPT学术项目\"}],\"collapsed\":false},{\"text\":\"ChatGPT (4篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>gpt角色扮演\",\"link\":\"/categories/chatgpt/02-ChatGPT/01-角色扮演\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>gpt学术提示词\",\"link\":\"/categories/chatgpt/02-ChatGPT/02-学术提示词\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>AI_PPT\",\"link\":\"/categories/chatgpt/02-ChatGPT/03-AI做PPT\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>AI编写Java项目\",\"link\":\"/categories/chatgpt/02-ChatGPT/04-AI编写Java项目\"}],\"collapsed\":false}],\"/courses/c/\":[{\"text\":\"C语言基础 (11篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>C语言基础概述\",\"link\":\"/courses/c/01-C语言基础/01-C语言基础概述\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>C语言数组\",\"link\":\"/courses/c/01-C语言基础/02-数组\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>C语言函数\",\"link\":\"/courses/c/01-C语言基础/03-函数\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>C语言预处理\",\"link\":\"/courses/c/01-C语言基础/04-预处理\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>C语言指针\",\"link\":\"/courses/c/01-C语言基础/05-指针\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">6</div>C语言动态内存申请\",\"link\":\"/courses/c/01-C语言基础/06-动态内存申请\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">7</div>C语言字符串处理函数\",\"link\":\"/courses/c/01-C语言基础/07-字符串处理函数\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">8</div>C语言结构体\",\"link\":\"/courses/c/01-C语言基础/08-结构体\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">9</div>C语言链表\",\"link\":\"/courses/c/01-C语言基础/09-链表\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">10</div>C语言文件\",\"link\":\"/courses/c/01-C语言基础/10-文件\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">11</div>C语言makefile\",\"link\":\"/courses/c/01-C语言基础/11-makefile\"}],\"collapsed\":false}],\"/courses/c_plus/\":[{\"text\":\"C++的基础 (5篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>C++对C的扩展\",\"link\":\"/courses/c_plus/01-C++的基础/01-c++对c的扩展\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>C++类和对象\",\"link\":\"/courses/c_plus/01-C++的基础/02-c++类和对象\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>C++模板\",\"link\":\"/courses/c_plus/01-C++的基础/03-c++模板\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>C++类型转换\",\"link\":\"/courses/c_plus/01-C++的基础/04-c++类型转换\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>C++异常\",\"link\":\"/courses/c_plus/01-C++的基础/05-c++异常\"}],\"collapsed\":false},{\"text\":\"C++的STL (11篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>C++的STL概述\",\"link\":\"/courses/c_plus/02-C++的STL/01-c++STL\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>C++的string容器\",\"link\":\"/courses/c_plus/02-C++的STL/02-String容器\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>C++的vector容器\",\"link\":\"/courses/c_plus/02-C++的STL/03-vector容器\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>C++的deque容器\",\"link\":\"/courses/c_plus/02-C++的STL/04-deque容器\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>C++的stack容器\",\"link\":\"/courses/c_plus/02-C++的STL/05-stack容器\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">6</div>C++的queue容器\",\"link\":\"/courses/c_plus/02-C++的STL/06-queue容器\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">7</div>C++的list容器\",\"link\":\"/courses/c_plus/02-C++的STL/07-list容器\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">8</div>C++的set容器\",\"link\":\"/courses/c_plus/02-C++的STL/08-set容器\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">9</div>C++的map容器\",\"link\":\"/courses/c_plus/02-C++的STL/09-map容器\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">10</div>C++的STL补充\",\"link\":\"/courses/c_plus/02-C++的STL/10-其他补充\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">11</div>C++的常见算法\",\"link\":\"/courses/c_plus/02-C++的STL/11-常见算法\"}],\"collapsed\":false}],\"/courses/python/\":[{\"text\":\"python基础篇 (1篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>Python基础\",\"link\":\"/courses/python/01-python基础篇/01-python基础\"}],\"collapsed\":true},{\"text\":\"python进阶篇 (4篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>numpy基础\",\"link\":\"/courses/python/02-python进阶篇/01-numpy\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>pandas基础\",\"link\":\"/courses/python/02-python进阶篇/02-pandas\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>matplotlib基础\",\"link\":\"/courses/python/02-python进阶篇/03-matplotlib\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>seaborn基础\",\"link\":\"/courses/python/02-python进阶篇/04-seaborn\"}],\"collapsed\":false}],\"/courses/tangyudi/\":[{\"text\":\"数学基础篇 (16篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>高等数学基础\",\"link\":\"/courses/tangyudi/01-数学基础篇/01-高等数学基础\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>微积分\",\"link\":\"/courses/tangyudi/01-数学基础篇/02-微积分\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>泰勒公式和拉格朗日\",\"link\":\"/courses/tangyudi/01-数学基础篇/03-泰勒公式和拉格朗日\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>线性代数基础\",\"link\":\"/courses/tangyudi/01-数学基础篇/04-线性代数基础\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>特征值与矩阵分解\",\"link\":\"/courses/tangyudi/01-数学基础篇/05-特征值与矩阵分解\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">6</div>随机变量\",\"link\":\"/courses/tangyudi/01-数学基础篇/06-随机变量\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">7</div>概率论基础\",\"link\":\"/courses/tangyudi/01-数学基础篇/07-概率论基础\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">8</div>几种分布\",\"link\":\"/courses/tangyudi/01-数学基础篇/08-几种分布\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">9</div>核函数变换\",\"link\":\"/courses/tangyudi/01-数学基础篇/09-核函数变换\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">10</div>熵与激活函数\",\"link\":\"/courses/tangyudi/01-数学基础篇/10-熵与激活函数\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">11</div>回归分析\",\"link\":\"/courses/tangyudi/01-数学基础篇/11-回归分析\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">12</div>假设检验\",\"link\":\"/courses/tangyudi/01-数学基础篇/12-假设检验\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">13</div>相关分析\",\"link\":\"/courses/tangyudi/01-数学基础篇/13-相关分析\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">14</div>方差分析\",\"link\":\"/courses/tangyudi/01-数学基础篇/14-方差分析\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">15</div>聚类分析\",\"link\":\"/courses/tangyudi/01-数学基础篇/15-聚类分析\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">16</div>贝叶斯分析\",\"link\":\"/courses/tangyudi/01-数学基础篇/16-贝叶斯分析\"}],\"collapsed\":false},{\"text\":\"机器学习篇 (12篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>线性回归\",\"link\":\"/courses/tangyudi/02-机器学习篇/01-线性回归\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>模型评估方法\",\"link\":\"/courses/tangyudi/02-机器学习篇/02-模型评估方法\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>逻辑回归\",\"link\":\"/courses/tangyudi/02-机器学习篇/03-逻辑回归\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>聚类算法\",\"link\":\"/courses/tangyudi/02-机器学习篇/04-聚类算法\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>决策树\",\"link\":\"/courses/tangyudi/02-机器学习篇/05-决策树\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">6</div>集成算法\",\"link\":\"/courses/tangyudi/02-机器学习篇/06-集成算法\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">7</div>支持向量机\",\"link\":\"/courses/tangyudi/02-机器学习篇/07-支持向量机\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">8</div>神经网络\",\"link\":\"/courses/tangyudi/02-机器学习篇/08-神经网络\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">9</div>贝叶斯\",\"link\":\"/courses/tangyudi/02-机器学习篇/09-贝叶斯\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">10</div>关联规则\",\"link\":\"/courses/tangyudi/02-机器学习篇/10-关联规则\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">11</div>词向量\",\"link\":\"/courses/tangyudi/02-机器学习篇/11-词向量\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">12</div>降维\",\"link\":\"/courses/tangyudi/02-机器学习篇/12-降维\"}],\"collapsed\":true},{\"text\":\"深度学习篇 (4篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>Pytorch\",\"link\":\"/courses/tangyudi/03-深度学习篇/01-Pytorch\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>MMLAB\",\"link\":\"/courses/tangyudi/03-深度学习篇/02-MMLAB实战\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>OpenCV\",\"link\":\"/courses/tangyudi/03-深度学习篇/03-OpenCV\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>YOLO\",\"link\":\"/courses/tangyudi/03-深度学习篇/04-YOLO\"}],\"collapsed\":true}],\"/courses/yuanzi/\":[{\"text\":\"QT应用开发和部署 (13篇)\",\"items\":[{\"text\":\"<div class=\\\"text-color-red mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">1</div>正电原子QT教程速查\",\"link\":\"/courses/yuanzi/03-QT应用开发和部署/01-linux安装qt\"},{\"text\":\"<div class=\\\"text-color-orange mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">2</div>按钮\",\"link\":\"/courses/yuanzi/03-QT应用开发和部署/02-按钮\"},{\"text\":\"<div class=\\\"text-color-yellow mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">3</div>输入窗口部件\",\"link\":\"/courses/yuanzi/03-QT应用开发和部署/03-输入窗口部件\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">4</div>显示窗口部件\",\"link\":\"/courses/yuanzi/03-QT应用开发和部署/04-显示窗口部件\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">5</div>布局管理\",\"link\":\"/courses/yuanzi/03-QT应用开发和部署/05-布局管理\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">6</div>容器\",\"link\":\"/courses/yuanzi/03-QT应用开发和部署/06-容器\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">7</div>项目式视图组（基于模型）\",\"link\":\"/courses/yuanzi/03-QT应用开发和部署/07-项目式视图组（基于模型）\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">8</div>项目控制组（基于项）\",\"link\":\"/courses/yuanzi/03-QT应用开发和部署/08-项目控制组（基于项）\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">9</div>文本读写\",\"link\":\"/courses/yuanzi/03-QT应用开发和部署/09-文本读写\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">10</div>绘图与图表\",\"link\":\"/courses/yuanzi/03-QT应用开发和部署/10-绘图与图表\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">11</div>多线程\",\"link\":\"/courses/yuanzi/03-QT应用开发和部署/11-多线程\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">12</div>TCP通信\",\"link\":\"/courses/yuanzi/03-QT应用开发和部署/12-TCP通信\"},{\"text\":\"<div class=\\\"text-color-gray mr-[6px]\\\" style=\\\"font-weight: 550; display: inline-block;\\\">13</div>UDP通信\",\"link\":\"/courses/yuanzi/03-QT应用开发和部署/13-UDP通信\"}],\"collapsed\":false}]},\"logo\":\"/logo.png\",\"outline\":{\"level\":\"deep\",\"label\":\"目录\"},\"darkModeSwitchLabel\":\"切换日光/暗黑模式\",\"sidebarMenuLabel\":\"文章\",\"returnToTopLabel\":\"返回顶部\",\"lastUpdatedText\":\"最后更新\",\"docFooter\":{\"prev\":\"上一篇\",\"next\":\"下一篇\"},\"editLink\":{\"pattern\":\"https://github.com/clint-sfy/clintsfy.github.io/edit/main/docs/:path\",\"text\":\"不妥之处，敬请雅正\"},\"search\":{\"provider\":\"local\",\"options\":{\"locales\":{\"root\":{\"translations\":{\"button\":{\"buttonText\":\"搜索文档\",\"buttonAriaLabel\":\"搜索文档\"},\"modal\":{\"noResultsText\":\"无法找到相关结果\",\"resetButtonTitle\":\"清除查询条件\",\"footer\":{\"selectText\":\"选择\",\"navigateText\":\"切换\"}}}}}}},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/clint-sfy\"},{\"icon\":{\"svg\":\"<svg role=\\\"img\\\" viewBox=\\\"0 0 24 24\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\"><title>码云</title><path d=\\\"M11.984 0A12 12 0 0 0 0 12a12 12 0 0 0 12 12 12 12 0 0 0 12-12A12 12 0 0 0 12 0a12 12 0 0 0-.016 0zm6.09 5.333c.328 0 .593.266.592.593v1.482a.594.594 0 0 1-.593.592H9.777c-.982 0-1.778.796-1.778 1.778v5.63c0 .327.266.592.593.592h5.63c.982 0 1.778-.796 1.778-1.778v-.296a.593.593 0 0 0-.592-.593h-4.15a.592.592 0 0 1-.592-.592v-1.482a.593.593 0 0 1 .593-.592h6.815c.327 0 .593.265.593.592v3.408a4 4 0 0 1-4 4H5.926a.593.593 0 0 1-.593-.593V9.778a4.444 4.444 0 0 1 4.445-4.444h8.296Z\\\"/></svg>\"},\"link\":\"https://gitee.com/clint_sfy\"}],\"articleMetadataConfig\":{\"author\":\"阿源\",\"authorLink\":\"/about/me\",\"showViewCount\":false},\"copyrightConfig\":{\"license\":\"署名-相同方式共享 4.0 国际 (CC BY-SA 4.0)\",\"licenseLink\":\"http://creativecommons.org/licenses/by-sa/4.0/\"},\"commentConfig\":{\"type\":\"gitalk\",\"showComment\":true},\"footerConfig\":{\"showFooter\":true,\"icpRecordCode\":\"蜀ICP备2023001686号-1\",\"copyright\":\"Copyright © 2019-2023 clint-sfy\"}},\"locales\":{},\"scrollOffset\":90,\"cleanUrls\":true}");</script>
    
  </body>
</html>